{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261  MIDS Machine Learning at Scale  \n",
    "## End of Term exam  \n",
    "\n",
    "Fall, 2017  \n",
    "__Student Name__:  Victoria Baker\n",
    "\n",
    "__Student ID:__   3032501083\n",
    "\n",
    "__Email:__   victoria.baker@ischool.berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Schedule  (All times are in California Time)\n",
    "\n",
    "One week starting 1:00AM PST, Thursday, December 7th, 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for exam \n",
    "\n",
    "\n",
    "* Please keep all your work and responses in ONE (1) notebook only (and submit to your github repository in a directory named FINAL)\n",
    "\n",
    "* Please submit your solutions and notebook via ISVC. Go to: Coursework -> Assignments & Grading -> End of Term Exam\n",
    "\n",
    "* **As for question types:** \n",
    "*    Knowledge test Programmatic/doodle (take photos; embed the photos in your notebook) and put them on GitHub\n",
    "*    All programmatic questions can be run locally on your laptop (using Apache Spark only)\n",
    "\n",
    "* This is an open book exam meaning you can consult webpages and textbooks, class notes, slides etc. but you can not discuss with each other or any other person/group until after December 19, 2017 \n",
    "\n",
    "* If there is any collusion, then this will result in a zero grade and will be grounds for dismissal from the entire program for those involved. Please complete this exam by yourself within the time limit.\n",
    "\n",
    "7. For markdown help in iPython Notebooks please see:\n",
    "https://sourceforge.net/p/ipython/discussion/markdown_syntax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam helper functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions requiring a SINGLE numeric response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# for two decimal places; \n",
    "# change this to the desired precision as needed\n",
    "ans=3.145  #replace with your answer\n",
    "print(\"%.2f\"%np.round(ans, 2))\n",
    "#prints 3.14\n",
    "#if this was your response then paste 3.14 (no spaces before or after; no extra characters; just 4 character: 3, ., 1, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions requiring a MULTIPLE numeric responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14,2.44,3.44\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# for two decimal places; \n",
    "# change this to the desired precision as needed\n",
    "ans1=1.145  #replace with your answer\n",
    "ans2=2.44333\n",
    "ans3=3.444443\n",
    "print(\"%.2f,%.2f,%.2f\" %(np.round(ans1, 2), np.round(ans2, 2), np.round(ans3, 2)))\n",
    "#prints 1.14,2.44,3.44\n",
    "#if this was your response then paste this string 1.14,2.44,3.44 (no spaces before or after; no extra characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.13 (default, Dec 20 2016 23:09:15)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ['SPARK_HOME'] = '/usr/lib/spark'\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.9-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam questions begins here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:1\n",
    "Calculate the signed normalizaed perpendicular distance from hyperplane $4x + 3y = 2$ to the point $(1, 3)$\n",
    "Please provide a response  within two decimal digits of precision in your notebook the submission form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5012fed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = np.arange(-2, 5)\n",
    "plt.plot(x, (2. - 4. * x) / 3.)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter([1],[3], c=\"r\", s=40)\n",
    "plt.xlim([-2, 4])\n",
    "plt.ylim([-2, 4])\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20\n"
     ]
    }
   ],
   "source": [
    "plane = [4,3,-2]\n",
    "point = [1,3]\n",
    "\n",
    "normalVector = plane[:-1]\n",
    "normalVector_magnitude = np.sqrt(np.dot(normalVector, normalVector))\n",
    "normalUnitVector = normalVector / normalVector_magnitude\n",
    "\n",
    "shortestDistance = np.abs(np.dot(plane, point + [1])) / normalVector_magnitude\n",
    "signed_shortestDistance = np.dot(plane, point + [1]) / normalVector_magnitude\n",
    "\n",
    "print(\"%.2f\"%np.round(signed_shortestDistance, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 2.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET:2\n",
    "Consider a three-class classification problem with the following separating hyperplanes:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "4x + 3y - 9 = 0 & & 1^{\\text{st}} \\text{ class}\\\\\n",
    "-4x + 3y - 11 = 0 & & 2^{\\text{nd}} \\text{ class}\\\\\n",
    "-x - 3y - 1 = 0 & & 3^{\\text{rd}} \\text{ class}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Calculate the score (signed unnormalized perpendicular distance) for each class and the point (0, 1).\n",
    "\n",
    "As a response provide all class scores within two decimal digits precision.   \n",
    "Provide your response in your notebook here and in the submission form.   \n",
    "Use the above provided helper functions to format your answers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wsrsKkfqHwr1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a75221650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(-3, 5)\n",
    "plt.plot(x, (9. - 4. * x) / 3., label=\"1st\")\n",
    "plt.plot(x, (11. + 4. * x) / 3., label=\"2nd\")\n",
    "plt.plot(x, (-1. - 1. * x) / 3., label=\"3rd\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter([0], [1], c=\"k\", s=40)\n",
    "plt.xlim([-3, 4])\n",
    "plt.ylim([-3, 4])\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20,1.60,1.26\n"
     ]
    }
   ],
   "source": [
    "plane1 = [4,3,-9]\n",
    "plane2 = [-4,3,-11]\n",
    "plane3 = [-1,-3,-1]\n",
    "point = [0,1]\n",
    "\n",
    "v1 = plane1[:-1]\n",
    "v1_mag = np.sqrt(np.dot(v1, v1))\n",
    "v2 = plane2[:-1]\n",
    "v2_mag = np.sqrt(np.dot(v2, v2))\n",
    "v3 = plane3[:-1]\n",
    "v3_mag = np.sqrt(np.dot(v3, v3))\n",
    "\n",
    "shortestDistance1 = abs(np.dot(plane1, point + [1]) / v1_mag)\n",
    "shortestDistance2 = abs(np.dot(plane2, point + [1]) / v2_mag)\n",
    "shortestDistance3 = abs(np.dot(plane3, point + [1]) / v3_mag)\n",
    "\n",
    "print(\"%.2f,%.2f,%.2f\" %(np.round(shortestDistance1, 2), np.round(shortestDistance2, 2), np.round(shortestDistance3, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 1.20, 1.60, 1.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:3\n",
    "Take the data from question ET2  above and calculate the class conditional probabilities for the point (0, 1) with respect to each class in this multinomial logistic regression model.\n",
    "\n",
    "\n",
    "As a response provide all class conditional probabilities within **five** decimal digits precision.   \n",
    "Use the helper functions above to format your answer. Make sure to adjust it to produce 5 decimal precision digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28099,0.41918,0.29983\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "e1 = math.exp(shortestDistance1)\n",
    "e2 = math.exp(shortestDistance2)\n",
    "e3 = math.exp(shortestDistance3)\n",
    "\n",
    "eSum = e1 + e2 + e3\n",
    "\n",
    "prob1 = e1 / eSum\n",
    "prob2 = e2 / eSum\n",
    "prob3 = e3 / eSum\n",
    "print(\"%.5f,%.5f,%.5f\" %(np.round(prob1, 5), np.round(prob2, 5), np.round(prob3, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 0.28099, 0.41918, 0.29983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:4\n",
    "Take the data from question ET3 above and predict the right class using the above multinomial logistic regression model.\n",
    "\n",
    "Select the correct response from the following.\n",
    "\n",
    "\n",
    "(a) Class 1     \n",
    "(b) Class 2     \n",
    "(c) Class 3     \n",
    "(d) all classes are equally likely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:5\n",
    "In the following (and also referring to HW12: http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/1wb2rdqbet54y1h/MIDS-MLS-Project-Criteo-CTR.ipynb) we have hashed the three sample points using numBuckets=4 and numBuckets=100. Complete the  statement below about these hashed features summarized in the following table using each answer once.\n",
    "\n",
    "|Name|Raw Features|4 Buckets|100 Buckets|\n",
    "|--|--|--|--|\n",
    "|sampleOne|[(0, 'mouse'), (1, 'black')]|{2: 1.0, 3: 1.0}|{14: 1.0, 31: 1.0}|\n",
    "|sampleTwo|[(0, 'cat'), (1, 'tabby'), (2, 'mouse')]|{0: 2.0, 2: 1.0}|{40: 1.0, 16: 1.0, 62: 1.0}|\n",
    "|sampleThree|[(0, 'bear'), (1, 'black'), (2, 'salmon')|{0: 1.0, 1: 1.0, 2: 1.0}|{72: 1.0, 5: 1.0, 14: 1.0}|\n",
    "\n",
    "With 4 buckets, sampleTwo and sampleThree both contain index 0 due to __________.\n",
    "\n",
    "(a) A hash collision  \n",
    "(b) Underlying properties of the data  \n",
    "(c) The fact that we use 4 buckets  \n",
    "(d) none of the above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:6  \n",
    "When applying numerical machine learning approaches (and for non-numerical approaches if required) to big data problems which of the following steps are could be used during modeling and are recommended:\n",
    "\n",
    "Select one:   \n",
    "(a) Convert categorical features to numerical features via one-hot-encoding and store in a dense representation  \n",
    "(b) Transform  categorical features using hashing regardless of how many unique categorical values exist in training and test data  \n",
    "(c) Use matrix factorization to remap your input vectors to latent concepts  \n",
    "(d) none of the above  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:7\n",
    "When dealing with numercial data which of the following are ways to deal with missing data:\n",
    "\n",
    "Select one:   \n",
    "(a) Delete records that have missing input values  \n",
    "(b) Standardize the data and set all missing values to 1 (one)  \n",
    "(c) Use K-nearest neighbours based on the test set to fill in missing values in the training set  \n",
    "(d) none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:8\n",
    "In the Criteo project, we're trying to predict what:\n",
    "\n",
    "Select one:   \n",
    "(a) Revenue from click events  \n",
    "(b) Click-through vs not click event  \n",
    "(c) Probability of a purchase  \n",
    "(d) none of the above  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:9\n",
    "Which of the following are true about the purpose of a loss function?\n",
    "\n",
    "Select one or more:   \n",
    "(a) It’s a way to penalize a model for incorrect predictions  \n",
    "(b) It precisely defines the optimization problem to be solved for a particular learning model  \n",
    "(c) Loss functions can be used for modeling both classification and regression problems  \n",
    "(d) none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: A, B, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:10\n",
    "Many standard machine learning methods can be formulated as a convex optimization problem, i.e. the task of finding a minimizer of a convex function _f_ that depends on a variable vector __w__ (called weights in the code), which has _d_ entries. Formally, we can write this as the optimization problem min<sub>w∈ℝ<sup>d</sup></sub>f(w), where the objective function is of the form  (JGS)\n",
    "\n",
    "\\begin{equation*}\n",
    "minimize   \\left(f(w):= λR(w) + \\sum_{k=1}^n \\left(w;w_i,y_i \\right) \\right) \n",
    "\\end{equation*}\n",
    "\n",
    "Here the vectors x<sub>i</sub>∈ℝ<sup>d</sup> are the training data examples, for 1≤i≤n, and y<sub>i</sub>∈ℝ are their corresponding labels, which we want to predict. We call the method linear if _L(w;x,y)_ can be expressed as a function of _ __w<sup>T</sup>__x _ and y. Several of spark.mllib’s classification and regression algorithms fall into this category.\n",
    "\n",
    "The objective function __f__ has two parts: the regularizer that controls the complexity of the model, and the loss that measures the error of the model on the training data. The loss function _L(w;.)_ is typically a convex function in __w__. The fixed regularization parameter λ≥0λ≥0 (regParam in the code) defines the trade-off between the two goals of minimizing the loss (i.e., training error) and minimizing model complexity (i.e., to avoid overfitting).\n",
    "\n",
    "\n",
    "When implementing Logistic (or linear) Regression with Regularization in Spark which of the following apply when using the above cost functions (mulitple options may apply): \n",
    "\n",
    "(I)   When lambda equals one, it provides the same result as standard logistic/linear regression   \n",
    "(II)  One only needs to modify the standard logistic (linear) regression (i.e., with no regularization term) by adding some code after the map-reduce (loss) gradient steps    \n",
    "(III) When lambda equals zero, it provides the same result as standard logistic (linear) regression \n",
    "(IV)  None of the above\n",
    "\n",
    "Select the most correct from the following:\n",
    "\n",
    "* (a) I, II, III\n",
    "* (b) II, III\n",
    "* (c) III\n",
    "* (d) IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: C -- III is definitely true, but I don't think that II is. I think the regularization term needs to be defined & broadcasted before the gradient steps-- more like in the mapping phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:11\n",
    "In the context of ecommerce you have just deployed a new conversion rate prediction model to production. This model (aka treatment model) will challenge the control nodel (i.e., the current model) in AB Test manner to see if it can be produce better revenue. Here is the data that was taken from this live AB Test. \n",
    "\n",
    "```\n",
    "CONTROL MODEL (our new CTR model)\n",
    "Impression ID   Revenue  \n",
    "1                $0.50\n",
    "2                $0.50\n",
    "3                $3.00\n",
    "......               \n",
    "20000            $3.00\n",
    "20001            $3.00\n",
    "20002            $3.00\n",
    "20003            $3.00\n",
    "......\n",
    "50,001           $3.00\n",
    ".....\n",
    "100,000          $4.00\n",
    "```\n",
    "\n",
    "All other impressions in this 100,000 sample resulted in zero transactions and therefore zero revenue. \n",
    "\n",
    "```\n",
    "TREATMENT MODEL (our new CTR model)\n",
    "Impression ID   Revenue  \n",
    "1                $1.50\n",
    "2                $0.50\n",
    "3                $0.00\n",
    "......\n",
    "50,001           $3.00\n",
    ".....\n",
    "100,000          $4.00\n",
    "```\n",
    "All other impressions in this 100,000 sample resulted in zero transactions and therefore zero revenue. \n",
    "\n",
    "\n",
    "P-values are a common way to determine the statistical significance of a test. The smaller it is, the more confident you can be that the test results are due to something other than random chance.\n",
    "A common p-value of .05 is a 5% significance level. Similarly, a p-value of .01 is a 1% significance level. A p-value of .20 is a 20% significance level. For this problem set the p-value to 0.01\n",
    "\n",
    "\n",
    "Which of the following are true:\n",
    "\n",
    "(a) Based on revenue there is no statistical significant difference between the Control and the Treatment at p-value of 0.05 for a one-sided t-test  \n",
    "(b) Based on transaction rates (tranactions that generated revenue versus not) there is no statistical significant difference between the Control and the Treatment at p-value of 0.05 for a one-sided t-test  \n",
    "(c) AB testing using differences in revenue for this problem is a  useful means of determining if the Treatment conversion rate prediction model is better than the control model.  \n",
    "(d) none of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=1.4142505069117979, pvalue=0.15728991985619109),\n",
       " Ttest_indResult(statistic=1.3867952958906298, pvalue=0.1655057375790788))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy.stats\n",
    "\n",
    "control=[.5, .5, 3, 3, 3, 3, 3, 3, 4]\n",
    "control.extend([0]*(100000-len(control)))\n",
    "control=np.asarray(control)\n",
    "\n",
    "treatment=[ 1.5, .5, 3, 4]\n",
    "treatment.extend([0]*(100000-len(treatment)))\n",
    "treatment=np.asarray(treatment)\n",
    "\n",
    "#nb 2-sided test\n",
    "scipy.stats.ttest_ind(control, treatment), scipy.stats.ttest_ind(control.astype(bool), treatment.astype(bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:  D -- The image shown in the online exam does not match the results of the code I am seeing in this notebook, so I am electing to answer based on the information in this notebook. The scipy.stats.ttest library runs a two sided t-test, not one-sided. The p values are higher than 0.05, so I can't certainly say there is any statistical significance. It would also lead me to believe that this kind of testing might not be the best way since all we can say is that we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:12\n",
    "Given this graph expressed in the form of an adjacency list,\n",
    "\n",
    "```\n",
    "Node  adjacentNode:weightAssociatedWithEdge\n",
    "N1    N6:10,  N2:2\n",
    "N2    N3:1\n",
    "N3    N4:1\n",
    "N4    N5:1\n",
    "N5    N6:1\n",
    "N6    N7:1\n",
    "N7    N8:1\n",
    "N8    N9:1\n",
    "```\n",
    "\n",
    "Using the parallel breadth-first search algorithm for determining the shortest path from a single source, how many iterations are required to discover the shortest distances to all nodes from Node 1 \n",
    "\n",
    "A 7   \n",
    "B 8    \n",
    "C 13  \n",
    "D None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:13 \n",
    "Many standard machine learning methods can be formulated as a convex optimization problem, i.e. the task of finding a minimizer of a convex function f that depends on a variable vector w (called weights in the code), which has d entries. Formally, we can write this as the optimization problem where the objective function is of the form\n",
    " <img src=\"softSVM.png\"/>\n",
    " \n",
    "$$\n",
    "f(w):= λR(w) + \\frac{1}{n}\\sum_{i=1}^n L\\left(w;w_i,y_i \\right) \n",
    "$$\n",
    " \n",
    " \n",
    "Here the vectors $x_i \\in ℝ_d$ are the training data examples, for $1≤i≤n$, and $y_i \\in ℝ$ are their corresponding labels, which we want to predict.    \n",
    "\n",
    "We call the method linear if $L(w;x,y)$ can be expressed as a function of $wTx$ and $y$. (where $wT$ denotes the transpose of the weight vector or matrix w )   \n",
    "\n",
    "By default, linear SVMs are trained with an L2 regularization with a hinge loss that is defined as follows:  $max\\{0,1−ywTx\\},y \\in \\{−1,+1\\}$\n",
    "\n",
    "Given the a softSVM as defined above select the most correct combination of statements from the following:   \n",
    "\n",
    "(I) When λ is super small (e.g., 0.000001), then the above Langrangian will yield a Hard SVM approximately   \n",
    "(II) In the context of support vector machines, linear kernels can be readily parallelized in map reduce frameworks such as Spark   \n",
    "(III) Sequential learning via algorithms such as perceptron can take advantage of map-reduce frameworks and yield   exactly the same results as a single core implementation with significant reductions in training time   \n",
    "(IV) When λ is 1.0, then the above Langrangian will yield a Soft SVM    \n",
    "\n",
    "Select one:\n",
    "\n",
    "(a) I, II, III   \n",
    "(b) I, III, IV   \n",
    "(c) I, II, IV   \n",
    "(d) none of the above statements are correct   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: C -- I & II are true. I'm hesitant to say that III is true because I don't think it's guaranteed to reduce training time, much less significantly reduce it. That's a pretty strong statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:14 \n",
    "Given the following paired RDDs \n",
    "RDD1 = {(1, 2), (3, 4), (3, 6)}\n",
    "RDD2 = {(3, 9) (3, 6)}\n",
    "\n",
    "Using PySpark, write code to perform an inner join of these paired RDDs. What is the resulting RDD? Make your Spark available in your notebook:\n",
    "\n",
    "A: [(3, (4, 9)), (3, (6, 9))]  \n",
    "B: [(3, (4, 9)), (3, (4, 6)), (3, (6, 9)), (3, (6, 6))]  \n",
    "C: [(3, (4, 9)), (3, (4, 6)), (3, (6, 9)), (3, (6, 9))]  \n",
    "D: None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, (4, 9)), (3, (4, 6)), (3, (6, 9)), (3, (6, 6))]\n"
     ]
    }
   ],
   "source": [
    "RDD1 = sc.parallelize([(1, 2), (3, 4), (3, 6)])\n",
    "RDD2 = sc.parallelize([(3, 9), (3, 6)])\n",
    "print RDD1.join(RDD2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:15  \n",
    "You have been tasked to build a predictive model to forecast beer sales for a chain of stores.\n",
    "After doing basic exploratory analysis on the data, what is the first thing you do regarding modeling?\n",
    "\n",
    "Select one:   \n",
    "(a) Construct a baseline model  \n",
    "(b) Determine a metric to evaluate your machine learnt models  \n",
    "(c) Split your data into training, validation and test subsets (or split using cross fold validatation)  \n",
    "(d) All of the  of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:16 \n",
    "Use Spark and the following notebook to answer this question:\n",
    "\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb\n",
    "* https://www.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb?dl=0 \n",
    "\n",
    "The mean absolute percentage error (MAPE), also known as mean absolute percentage deviation (MAPD), is a measure of prediction accuracy of a model for say a forecasting method in statistics, \n",
    "for example in trend estimation. It usually expresses accuracy as a percentage, and is defined by the formula:\n",
    "\n",
    "MAPE = average over all examples (100*Abs(Actual - Predicted) / Actual)) \n",
    "\n",
    "Note when Actual is zero that test row is dropped from the evaluation.\n",
    "\n",
    "Construct a mean model for target variable `CASES18PK`. Calculate the MAPE for the mean model over the training set. Select the closest answer.\n",
    "\n",
    "Select one:   \n",
    "(a) 200%  \n",
    "(b) 250%  \n",
    "(c) 20%  \n",
    "(d) 180%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing beerSales.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile beerSales.txt\n",
    "Week\tPRICE12PK\tPRICE18PK\tPRICE30PK\tCASES12PK\tCASES18PK\tCASES30PK\n",
    "1\t19.98\t14.10\t15.19\t223.5\t439\t55.00\n",
    "2\t19.98\t18.65\t15.19\t215.0\t98\t66.75\n",
    "3\t19.98\t18.65\t13.87\t227.5\t70\t242.00\n",
    "4\t19.98\t18.65\t12.83\t244.5\t52\t488.50\n",
    "5\t19.98\t18.65\t13.16\t313.5\t64\t308.75\n",
    "6\t19.98\t18.65\t15.19\t279.0\t72\t111.75\n",
    "7\t19.98\t18.65\t13.92\t238.0\t47\t252.50\n",
    "8\t20.10\t18.73\t14.42\t315.5\t85\t221.25\n",
    "9\t20.12\t18.75\t13.83\t217.0\t59\t245.25\n",
    "10\t20.13\t18.75\t14.50\t209.5\t63\t148.50\n",
    "11\t20.14\t18.75\t13.87\t227.0\t57\t229.75\n",
    "12\t20.12\t18.75\t13.64\t216.5\t54\t312.00\n",
    "13\t20.12\t13.87\t14.31\t169.0\t404\t96.75\n",
    "14\t20.13\t14.27\t13.85\t178.0\t380\t123.25\n",
    "15\t20.14\t18.76\t14.20\t301.5\t65\t200.50\n",
    "16\t20.14\t18.77\t13.64\t266.5\t40\t359.75\n",
    "17\t20.13\t13.87\t14.33\t182.5\t456\t113.50\n",
    "18\t20.13\t14.14\t13.14\t159.0\t176\t136.50\n",
    "19\t20.13\t18.76\t13.81\t285.5\t61\t225.50\n",
    "20\t20.13\t18.72\t15.19\t360.0\t91\t122.25\n",
    "21\t20.13\t18.76\t13.13\t263.0\t59\t443.75\n",
    "22\t19.18\t18.76\t13.63\t443.5\t83\t322.75\n",
    "23\t14.78\t18.74\t15.19\t1101.5\t41\t53.00\n",
    "24\t16.04\t18.75\t13.89\t814.0\t47\t140.75\n",
    "25\t20.12\t18.75\t14.28\t365.0\t84\t210.75\n",
    "26\t19.75\t18.75\t15.19\t510.0\t85\t110.50\n",
    "27\t19.65\t18.75\t13.12\t580.5\t116\t568.25\n",
    "28\t19.69\t13.79\t13.78\t251.0\t544\t115.50\n",
    "29\t20.12\t13.49\t15.19\t237.0\t890\t58.75\n",
    "30\t20.12\t14.89\t15.19\t302.5\t371\t77.25\n",
    "31\t20.13\t13.94\t15.19\t229.5\t557\t66.25\n",
    "32\t20.14\t13.67\t15.19\t188.5\t775\t50.00\n",
    "33\t15.14\t14.43\t15.19\t795.5\t236\t46.50\n",
    "34\t14.33\t18.75\t15.19\t1556.5\t43\t65.75\n",
    "35\t16.24\t18.22\t13.14\t807.5\t63\t252.75\n",
    "36\t19.93\t14.06\t13.45\t243.0\t469\t179.00\n",
    "37\t21.06\t14.43\t13.00\t201.5\t335\t226.25\n",
    "38\t21.19\t19.48\t13.60\t294.0\t75\t288.50\n",
    "39\t21.23\t15.15\t14.46\t220.5\t461\t114.25\n",
    "40\t20.12\t13.79\t14.94\t255.5\t817\t70.00\n",
    "41\t14.73\t14.31\t15.19\t920.5\t200\t47.75\n",
    "42\t14.57\t19.50\t15.19\t730.0\t32\t98.75\n",
    "43\t15.94\t13.85\t15.19\t262.5\t460\t77.00\n",
    "44\t20.70\t14.23\t13.43\t209.5\t751\t160.50\n",
    "45\t19.57\t19.31\t14.37\t283.0\t70\t143.50\n",
    "46\t19.60\t19.29\t15.19\t262.5\t80\t133.00\n",
    "47\t19.94\t13.76\t15.19\t310.0\t523\t68.75\n",
    "48\t21.28\t13.45\t15.19\t278.5\t741\t81.75\n",
    "49\t14.56\t15.13\t15.19\t741.5\t130\t56.25\n",
    "50\t14.39\t19.43\t15.19\t1316.0\t69\t68.75\n",
    "51\t16.81\t13.26\t15.19\t449.0\t493\t49.25\n",
    "52\t19.86\t13.92\t15.19\t505.0\t814\t76.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sc.textFile(\"beerSales.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal beerSales.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.44422333\n"
     ]
    }
   ],
   "source": [
    "cases18pk = sc.textFile(\"beerSales.txt\") \\\n",
    "            .filter(lambda x: not x.startswith(\"Week\")) \\\n",
    "            .map(lambda x: int(x.split(\"\\t\")[5])) \\\n",
    "            .cache()\n",
    "\n",
    "mean_model = cases18pk.mean()\n",
    "mape = cases18pk.map(lambda x: 100*abs(x-mean_model)/x).mean()\n",
    "print mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer**: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:17\n",
    "Use Spark and the following notebook to answer this question:\n",
    "\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb\n",
    "* https://www.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb?dl=0 \n",
    "\n",
    "The target variable `CASES18P`K is skewed, so take the log of it (and make it more normally distributed) and compute the MAPE of the mean model for `CASES18PK`. Select the closest answer to your calculated MAPE.\n",
    "\n",
    "(a) 200%  \n",
    "(b) 30%  \n",
    "(c) 20%  \n",
    "(d) 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5849342896\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "log18pk = cases18pk.map(lambda x: log(x)).cache()\n",
    "\n",
    "mean_model = log18pk.mean()\n",
    "mape = log18pk.map(lambda x: 100*abs(x-mean_model)/x).mean()\n",
    "print mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ET:18\n",
    "Use Spark and the following notebook to answer this question:\n",
    "\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb\n",
    "* https://www.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb?dl=0 \n",
    "\n",
    "\n",
    "Build a linear regression model using the following variables:\n",
    "\n",
    "Log(CASES18PK)  ~  log(PRICE12PK), \tlog(PRICE18PK),\tlog(PRICE30PK)\n",
    "\n",
    "Please train the model on the full data and calculate  the MAPE over the same dataset and select a response from the following options that is closest this MAPE\". \n",
    "\n",
    "Select one:   \n",
    "(a) 4.3%  \n",
    "(b) 4.6%  \n",
    "(c) 3.5%  \n",
    "(d) 3.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2150866635659208"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header = ['Week',\n",
    "          'PRICE12PK',\n",
    "          'PRICE18PK',\n",
    "          'PRICE30PK',\n",
    "          'CASES12PK',\n",
    "          'CASES18PK',\n",
    "          'CASES30PK']\n",
    "\n",
    "xTemp = sc.textFile(\"beerSales.txt\") \\\n",
    "             .map(lambda x: x.split(\"\\t\")) \\\n",
    "             .filter(lambda x: x[0] != \"Week\") \\\n",
    "             .map(lambda x: [float(val) for val in x])\n",
    "\n",
    "x = np.log(pd.DataFrame(xTemp.collect(), columns=header))\n",
    "y = x.pop(\"CASES18PK\")\n",
    "x.drop([\"CASES12PK\", \"CASES30PK\", \"Week\"], axis=1, inplace=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "y_hat = model.predict(x)\n",
    "\n",
    "(100*(y - y_hat).abs()/y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET:19\n",
    "Recall that Spark automatically sends all variables referenced in your closures to the\n",
    "worker nodes. While this is convenient, it can also be inefficient because (1) the\n",
    "default task launching mechanism is optimized for small task sizes, and (2) you\n",
    "might, in fact, use the same variable in multiple parallel operations, but Spark will\n",
    "send it separately for each operation. As an example, say that we wanted to write a\n",
    "Spark program that looks up countries by their call signs (e.g., the call sign for Ireland is EJZ) by prefix matching in an\n",
    "table. In the following the \"signPrefixes\" variable is essentially a table with two columns \"Sign\" and \"Country Name\". The goal is \n",
    "to join the following tables:\n",
    "\n",
    "`signPrefixes` table with columns \"Sign\" and \"Country Name\"  \n",
    "`contactCounts` table with columns \"Sign\" and \"count\"\n",
    "\n",
    "to yield  a new table:\n",
    "\n",
    "`countryContactCounts` with the following columns \"Country Name\" and \"count\"\n",
    "\n",
    "Use Spark and the following notebook to answer this question:\n",
    "\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb\n",
    "* https://www.dropbox.com/s/6s5ph41h74bggwi/Linear-Regression-on-Beer-Data.ipynb?dl=0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we modfify this code to make it more efficient? Choose one response only\n",
    "\n",
    "(a) modify line 18 with `sc.broadcast(loadCallSignTable())`\n",
    "(b) Use accumulators to store the counts for each country  \n",
    "(c) The code is already optimal  \n",
    "(d) none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: A     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "454px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
