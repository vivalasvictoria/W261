{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#MIDS---w261-Machine-Learning-At-Scale\" data-toc-modified-id=\"MIDS---w261-Machine-Learning-At-Scale-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MIDS - w261 Machine Learning At Scale</a></div><div class=\"lev2 toc-item\"><a href=\"#Assignment---HW1\" data-toc-modified-id=\"Assignment---HW1-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Assignment - HW1</a></div><div class=\"lev2 toc-item\"><a href=\"#INSTRUCTIONS-for-SUBMISSION\" data-toc-modified-id=\"INSTRUCTIONS-for-SUBMISSION-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>INSTRUCTIONS for SUBMISSION</a></div><div class=\"lev2 toc-item\"><a href=\"#CONFIGURATION\" data-toc-modified-id=\"CONFIGURATION-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>CONFIGURATION</a></div><div class=\"lev1 toc-item\"><a href=\"#HW-1---Questions\" data-toc-modified-id=\"HW-1---Questions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>HW 1 - Questions</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.0\" data-toc-modified-id=\"HW1.0-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>HW1.0</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.1--Self-Introduction\" data-toc-modified-id=\"HW1.0.1--Self-Introduction-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>HW1.0.1  Self-Introduction</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.2.-Big-data\" data-toc-modified-id=\"HW1.0.2.-Big-data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>HW1.0.2. Big data</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.3.--Bias-Variance\" data-toc-modified-id=\"HW1.0.3.--Bias-Variance-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>HW1.0.3.  Bias Variance</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.1-WordCount-using-a-single-thread\" data-toc-modified-id=\"HW1.1-WordCount-using-a-single-thread-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>HW1.1 WordCount using a single thread</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.1.1-How-many-times-does-the-word-alice-occur-in-the-book?\" data-toc-modified-id=\"HW1.1.1-How-many-times-does-the-word-alice-occur-in-the-book?-221\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>HW1.1.1 How many times does the word alice occur in the book?</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.2-Command-Line-Map-Reduce-Framework\" data-toc-modified-id=\"HW1.2-Command-Line-Map-Reduce-Framework-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>HW1.2 Command Line Map Reduce Framework</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.3-WordCount-via-Command-Line-Map-Reduce-Framework\" data-toc-modified-id=\"HW1.3-WordCount-via-Command-Line-Map-Reduce-Framework-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>HW1.3 WordCount via Command Line Map Reduce Framework</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.4-(OPTIONAL)---Count-words-staring-with-uppercase-and-words-starting-with-lowercase\" data-toc-modified-id=\"HW1.4-(OPTIONAL)---Count-words-staring-with-uppercase-and-words-starting-with-lowercase-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>HW1.4 (OPTIONAL) - Count words staring with uppercase and words starting with lowercase</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.5-(OPTIONAL)---Bias-Variance\" data-toc-modified-id=\"HW1.5-(OPTIONAL)---Bias-Variance-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>HW1.5 (OPTIONAL) - Bias-Variance</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale \n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW1\n",
    "Version 2017-08-30 \n",
    "\n",
    "---\n",
    "__Name:__  Victoria Baker   \n",
    "__Class:__ MIDS w261 (Section 002, e.g., Fall 2017 Group 2)     \n",
    "__Email:__  victoria.baker@iSchool.Berkeley.edu     \n",
    "__StudentId__  3032501083    __End of StudentId__     \n",
    "__Week:__   1\n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "\n",
    "## INSTRUCTIONS for SUBMISSION\n",
    "\n",
    "HW1 can be completed locally on your computer. __Please submit your notebook to your classroom github repository 24 hours prior to the next live session.__ Your submission should follow the naming and file structure conventions described in the `README.md` for HW1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION \n",
    "Before starting your homework run the following cells to confirm your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "# make sure you are in HW1 directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.13 :: Continuum Analytics, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "# confirm your version of python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.0\n",
    "\n",
    "### HW1.0.1  Self-Introduction\n",
    "W1.0.0 Prepare your bio and include it in this HW submission. Please limit to 100 words. Count the words in your bio and print the length of your bio (in terms of words) in a separate cell.\n",
    "\n",
    "Fill in the following information [Optional]\n",
    "* Your Location \n",
    "* When did you start MIDS  and what is your target finish date\n",
    "* What you want to get out of w261?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My name is Victoria Baker. I reside in Chattanooga, Tennessee. I started the MIDS program in Fall 2016 and I plan to finish at the end of next year. I developed a very strong interest in machine learning in W207, so I would like to deepen and broaden my machine learning experience in W261. Specifically, I would like to learn more about building well-fitted models that can handle larger amounts of data than what we used in W207. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for bio:  68\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = 'My name is Victoria Baker. I reside in Chattanooga, Tennessee. I started the MIDS program in Fall 2016 and I plan to finish at the end of next year. I developed a very strong interest in machine learning in W207, so I would like to deepen and broaden my machine learning experience in W261. Specifically, I would like to learn more about building well-fitted models that can handle larger amounts of data than what we used in W207.'\n",
    "count = 0\n",
    "for word in re.findall(r'[a-z]+', text):\n",
    "    count += 1\n",
    "    \n",
    "print 'Word count for bio: ', count\n",
    "# END STUDENT SOLUTION HW1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.2. Big data\n",
    "Define big data. Provide an example of a big data problem in your domain of expertise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Big Data is the name attributed to the drastic increase in the amount of data stored, processed, and analyzed in our society today. Big Data is too large and/or complex for traditional data processing methods to adequately handle. \n",
    "\n",
    "I have the very unique position of being in a marriage of two very old industries: government and energy. Most of our business is highly regulated and most power generating plants and supporting equipment were built anywhere from 20 to 50 years ago, which results in a very rigid system that is difficult and costly to optimize or upgrade. This has presented many challenges surrounding data analytics in our industry.\n",
    "The value of the kind of data that my company could benefit from is tremendous, but the biggest obstacle preventing this kind of innovation for us is the complexity of the processes and the sparsity and distribution of data (or lack thereof). \n",
    "\n",
    "For example, one innovation with a lot of big data opportunity is predicting the need for maintenance or failure on plant and transmission equipment. A lot of progress has been made in this regard, but the biggest obstacle for us (and other federal entities, I am to understand) is that the processes are such that good data is often siloed, sparse, or not being collected; and it is a slow and difficult process to change those processes. A lot of the problems we often face are still in the beginning stages of building a data driven business model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.3.  Bias Variance\n",
    "What is  bias-variance decomposition in the context machine learning? How is it used in machine learning? Please use mathematical equations and/or diagrams to support your explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prediction errors can be broken down into two components: error due to bias and error due to variance. Both types of error strongly affect the model fitting process, so understanding the effects of both is imperative. \n",
    "\n",
    "Error due to bias is the difference between the expected (or average) prediction of a model and the correct value. Error due to variance is the variability of a model's prediction for a given data point. So, if we could repeat the entire model building process multiple times, the bias measures how far off the predicted values are from the correct values, and variance is how much the predictions for a given point vary between each iteration of the model.\n",
    "\n",
    "My favorite graphical representation of this relationship uses a target as an example of the differences between variance and bias:\n",
    "\n",
    "![title](BiasVariance.PNG)\n",
    "\n",
    "_image ref: http://scott.fortmann-roe.com/docs/BiasVariance.html _\n",
    "\n",
    "As illustrated in this graphical representation, bias dictates how far away from the bullseye the points are, whereas variance dictates how closely clustered the data points are. It is most desirable to have Low Variance and Low Bias--this results in a close cluster of points nearest to the bullseye. If the bias is raised from there, then the points stay close together, but stray farther away from the desired target. If instead the variance is raised, then the points are still loosely centered on the bullseye, but they are more spread out which results in fewer points hitting the desired target. The worst scenario is to have high variance and high bias. This results in points scattered far away from the center of the target. \n",
    "\n",
    "Bias-variance decomposition is used in machine learning to reduce error and build a better model. The error term can be broken down as:\n",
    "\n",
    "$$Error = Bias^2 + Variance + \\sigma_e^2$$\n",
    "\n",
    "where $\\sigma_e^2$ is the irreducible error inherent in any model that cannot be reduced. To be more specific:\n",
    "\n",
    "$${\\begin{aligned}{\\mathrm {E}}{\\Big [}{\\big (}y-{\\hat {f}}(x){\\big )}^{2}{\\Big ]}&=\\mathrm {E} {\\big [}{\\hat {f}}(x)-f(x){\\big ]}^{2}+(\\mathrm {E} [{\\hat {f}}(x)^{2}]-\\mathrm {E} [{\\hat {f}}(x)]^{2})+\\sigma ^{2}\\\\\\end{aligned}}$$\n",
    "\n",
    "So, if bias and/or variance can be decreased then the error will be minimized and the model will perform better. \n",
    "\n",
    "Commonly, methods to reduce one component will often introduce the possibility of increasing the other. For instance, dimensionality reduction by feature selection is a common way to decrease variance by simplifying the model; however, doing the opposite (adding features) tends to decrease bias at the expense of introducing variance. To mitigate this properly, a data scientist needs to examine each error term carefully and weigh the pros and cons of the bias-variance tradeoff in order to make the best decision on how to optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.1 WordCount using a single thread  \n",
    "\n",
    "For this homework problem you will write a program called alice_words.py that creates a text file named __alice_words.txt__ containing an alphabetical tab separated listing of all the words and the number of times each occurs, in the text version of Alice’s Adventures in Wonderland. The cells below will guide you though the following steps...\n",
    "* Download the free plain text version of the book from Project Gutenberg([linked here](http://www.gutenberg.org/cache/epub/11/pg11.txt)) \n",
    "* Read through the provided code examples of the `re` module and `defaultDict` python class.\n",
    "* Add your own code to complete the `hw11` function defined inside the file `alice_words.py` which will compute word counts for all the words in the book.\n",
    "* Use the provided code to run your program, save and print your results.The first 10 lines of your output file should look something like this (the counts are not totally precise):\n",
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>\n",
    "\n",
    "* Finally, in __HW 1.1.1__ you will add your own code to complete the `hw111` function defined inside the file `hw111.py` which will extract the number of occurances of a specific word from a provided word counts file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  169k  100  169k    0     0   424k      0 --:--:-- --:--:-- --:--:--  504k\n"
     ]
    }
   ],
   "source": [
    "# !curl 'http://www.gutenberg.org/cache/epub/11/pg11.txt' -o alicesTExtFilename.txt\n",
    "# sometimes the above link produces junk characters. However, the direct link works as expected:\n",
    "!curl 'http://www.gutenberg.org/files/11/11-0.txt' -o alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "���Project Gutenberg���s Alice���s Adventures in Wonderland, by Lewis Carroll\r",
      "\r\n",
      "\r",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r",
      "\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r",
      "\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r",
      "\r\n",
      "with this eBook or online at www.gutenberg.org\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "Title: Alice���s Adventures in Wonderland\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#display the first few lines\n",
    "!head alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CODE TIP #1:__ run the cell below to see an example of using regular expressions to extract words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beck',\n",
       " 'global',\n",
       " 'risk',\n",
       " 'management',\n",
       " 'operations',\n",
       " 'congratulations',\n",
       " 'sally',\n",
       " 'kk',\n",
       " 'forwarded',\n",
       " 'by']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of a regular expression to detect words in a string. \n",
    "import re\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "re.findall(r'[a-z]+', line.lower()) [0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CODE TIP #2:__ run the cell below to see an example of using `defaultDict` to count words.\n",
    "\n",
    "> Dictionaries (e.g. `wordCounts={}`) are one way to do word counting but can be annoying to work with.  A defaultdict is like a regular dictionary, except that when you try to look up a key it doesn’t contain, it first adds a value for it using a zero-argument function you provided when you created it. In order to use defaultdicts, you have to import them from the `collections` module. Run the code below to see it in action & refer to the python documentation for more help if you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 7)\n",
      "('accounting', 1)\n",
      "('activities', 3)\n",
      "('additional', 1)\n",
      "('administration', 1)\n",
      "('all', 3)\n",
      "('allocation', 1)\n",
      "('also', 3)\n",
      "('america', 2)\n",
      "('among', 1)\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of wordcounting with a defaultdict (dictionary structure with a nice \n",
    "# default behaviours when a key does not exist in the dictionary\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "wordCounts=defaultdict(int)\n",
    "for word in re.findall(r'[a-z]+', line.lower()):\n",
    "    wordCounts[word] += 1\n",
    "for key in sorted(wordCounts)[0:10]:\n",
    "    print (key, wordCounts[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fill in the code block below, then execute the cell as well as the cell below it.__    \n",
    "\n",
    "<i>This will write a file named alice_words.py and run it.</i>\n",
    "\n",
    "__The output per line should be a tab separated key-value pair with the following format WORD TAB count:__\n",
    "<pre>\n",
    "a          2333333\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting alice_words.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile alice_words.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "pathToFile = sys.argv[1]\n",
    "wordCounts = defaultdict(int)\n",
    "\n",
    "\n",
    "def hw11(pathToFile):\n",
    "    # takes the path to the file as command line argument\n",
    "    # prints sorted tab separated list of words and counts\n",
    "    # ex) print word,'\\t',count\n",
    "    # returns sorted list of tuples of words and counts: wordList\n",
    "    # ex) wordList = [('a', 690),('abide', 2),...]\n",
    "  \n",
    "    wordList = {}\n",
    "\n",
    "    # START STUDENT CODE HW1.1\n",
    "    text_file = open(pathToFile, 'r')\n",
    "    text_string = text_file.read().lower()\n",
    "    \n",
    "    for word in re.findall(r'[a-z]+', text_string):\n",
    "        wordCounts[word] += 1\n",
    "        \n",
    "    for key in sorted(wordCounts):\n",
    "        print key,'\\t', wordCounts[key]\n",
    "\n",
    "    # END STUDENT CODE HW1.1\n",
    "  \n",
    "    return wordList\n",
    "\n",
    "hw11(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python alice_words.py 'alicesTExtFilename.txt' > alice_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pretty print top 10 results from alice_words.txt__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Count\n",
      "====================\n",
      "a                690\n",
      "abide              2\n",
      "able               1\n",
      "about            102\n",
      "above              3\n",
      "absence            1\n",
      "absurd             2\n",
      "accept             1\n",
      "acceptance         1\n",
      "accepted           2\n"
     ]
    }
   ],
   "source": [
    "#str.format() is a handy funcion for human friendly pretty printing:\n",
    "#Examples: https://docs.python.org/2/library/string.html#format-examples\n",
    "print '{:15}{}'.format('Word', 'Count')\n",
    "print '='*20\n",
    "\n",
    "with open(\"alice_words.txt\") as f:\n",
    "    idx = 0\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        word, count = line.split('\\t')\n",
    "        # print the top 10 lines\n",
    "        if idx < 10:\n",
    "            print '{:17}{:3d}'.format(word, int(count))\n",
    "        idx += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.1.1 How many times does the word alice occur in the book?\n",
    "_ HINT: read the file with python, or use subprocess to access the commandline from within the python function_\n",
    "\n",
    "__ As before, fill in the code block below, then execute the cell as well as the cell below it. This will write a file named hw111.py and run it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hw111.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw111.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "word = sys.argv[1]\n",
    "pathToFile = sys.argv[2]\n",
    "\n",
    "def hw111(word,pathToFile):\n",
    "    #takes a word and the path to the file as arguments\n",
    "    # returns the line containing the word and count\n",
    "\n",
    "    # START STUDENT CODE HW1.1.1\n",
    "    wordCounts = defaultdict(int)\n",
    "    text_file = open(pathToFile, 'r')\n",
    "    #text_string = text_file.read().lower()\n",
    "    \n",
    "    for line in text_file:\n",
    "        for w in re.findall(r'[a-z]+', line):\n",
    "            if(w.lower() == word):\n",
    "                print line\n",
    "\n",
    "    # END STUDENT CODE HW1.1.1\n",
    "\n",
    "print hw111(word,pathToFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice \t403\r\n",
      "\r\n",
      "None\r\n"
     ]
    }
   ],
   "source": [
    "!python hw111.py 'alice' 'alice_words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW1.2 Command Line Map Reduce Framework\n",
    "\n",
    "For this HW question:\n",
    "* Read through the provided mapreduce shell script (pWordCount.sh) provided below and all of its comments. When you are comfortable with their purpose and function, respond to the remaining homework questions below. \n",
    "* Run all the code blocks.\n",
    "* No need to modify anything in `pWordCount.sh` until you get to HW 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pWordCount.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile pWordCount.sh\n",
    "#!/bin/bash\n",
    "## pWordCount.sh\n",
    "## Author: James G. Shanahan\n",
    "## Usage: pWordCount.sh m wordlist testFile.txt\n",
    "## Input:\n",
    "##       m = number of processes (maps), e.g., 4\n",
    "##       word = a word in quotes, e.g., \"alice\"\n",
    "##       inputFile = a text input file\n",
    "##\n",
    "###----------------------------------------------------------------------------------------\n",
    "## HW1.2 INSTRUCTIONS: \n",
    "##          Make no changes, just read this script and its comments closely.\n",
    "##          Do your best to understand the purpose of each command, and\n",
    "##          focus on how arguments are supplied to mapper.py/reducer.py,\n",
    "##          as this will determine how the python scripts take input.\n",
    "##\n",
    "## HW1.3 INSTRUCTIONS: \n",
    "##          Modify this script to include shuffle/sort/merge phase, which\n",
    "##          will collate wordCount records with the same key (i.e. word).\n",
    "##          run: man sort to learn more about the linux sort command\n",
    "##          Mark and comment your modifications clearly (eg. ## CHANGE 1 )\n",
    "##\n",
    "###----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "usage()\n",
    "{\n",
    "    echo ERROR: No arguments supplied\n",
    "    echo\n",
    "    echo To run use\n",
    "    echo \"pWordCount.sh m word inputFile\"\n",
    "    echo Input:\n",
    "    echo \"number of processes/maps, EG, 4\"\n",
    "    echo \"word = a word in quotes, e.g., 'alice'\"\n",
    "    echo \"inputFile = a text input file\"\n",
    "}\n",
    "\n",
    "if [ $# -eq 0 ]\n",
    "  then\n",
    "    usage  \n",
    "    exit 1\n",
    "fi\n",
    "    \n",
    "## collect user input\n",
    "m=$1 ## the number of parallel processes (maps) to run\n",
    "word=$2 ## if set to \"*\", then all words are used (HW 1.3)\n",
    "data=$3 ## a text file \n",
    "\n",
    "    \n",
    "## 'wc' determines the number of lines in the data\n",
    "## 'perl -pe' regex strips the piped wc output to a number\n",
    "linesindata=`wc -l $data | perl -pe 's/^.*?(\\d+).*?$/$1/'`\n",
    "\n",
    "## determine the lines per chunk for the desired number of processes\n",
    "linesinchunk=`echo \"$linesindata/$m+1\" | bc`\n",
    "\n",
    "## split the original file into chunks by line\n",
    "split -l $linesinchunk $data $data.chunk.\n",
    "\n",
    "\n",
    "############# ADD HW 1.3 STUDENT MODIFICATIONS BELOW ##############\n",
    "    \n",
    "## assign python mappers (mapper.py) to the chunks of data\n",
    "## and emit their output to temporary files\n",
    "for datachunk in $data.chunk.*; do\n",
    "    ## feed word list to the python mapper here and redirect STDOUT to a temporary file on disk\n",
    "    ./mapper.py  \"$word\" < $datachunk > $datachunk.counts &\n",
    "done\n",
    "## wait for the mappers to finish their work\n",
    "wait\n",
    "\n",
    "    \n",
    "## 'ls' makes a list of the temporary count files\n",
    "## 'perl -pe' regex replaces line breaks with spaces\n",
    "countfiles=`\\ls $data.chunk.*.counts | perl -pe 's/\\n/ /'`\n",
    "\n",
    "## feed the list of countfiles to the python reducer and redirect STDOUT to disk\n",
    "cat $countfiles | sort -k1 | ./reducer.py  > $data.output\n",
    "\n",
    "## clean up the data chunks and temporary count files\n",
    "\\rm $data.chunk.*\n",
    "    \n",
    "## display the content of the output file:\n",
    "cat $data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "## pWordCount.sh\r\n",
      "## Author: James G. Shanahan\r\n",
      "## Usage: pWordCount.sh m wordlist testFile.txt\r\n",
      "## Input:\r\n",
      "##       m = number of processes (maps), e.g., 4\r\n",
      "##       word = a word in quotes, e.g., \"alice\"\r\n",
      "##       inputFile = a text input file\r\n",
      "##\r\n",
      "###----------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!head pWordCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the execution priviledges to make the shell script executable by all\n",
    "!chmod a+x pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test the framework without parameters:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No arguments supplied\r\n",
      "\r\n",
      "To run use\r\n",
      "pWordCount.sh m word inputFile\r\n",
      "Input:\r\n",
      "number of processes/maps, EG, 4\r\n",
      "word = a word in quotes, e.g., 'alice'\r\n",
      "inputFile = a text input file\r\n"
     ]
    }
   ],
   "source": [
    "! ./pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run the following two cells to generate mapper and reducer files, then run the shell script again with arguments.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "findword = sys.argv[1]\n",
    "for line in sys.stdin:\n",
    "    # count all occurances of the word in each line:\n",
    "    count = count + line.lower().count(findword)\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## Description: reducer code for HW1.2\n",
    "import sys\n",
    "import re\n",
    "sum = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    sum += int(line)\n",
    "\n",
    "print sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make the files executable:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mapper.py\n",
    "!chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test the framework with parameters:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice  \t403\r\n"
     ]
    }
   ],
   "source": [
    "!./pWordCount.sh 4 'alice' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW1.3 WordCount via Command Line Map Reduce Framework\n",
    "\n",
    "_Think about what would happen if you replaced `'alice'` with `'*'` in the call to `pWordCount.sh` above? Does this behavior make sense for a word counting application?_ For HW1.3 you'll modify the `pWordCount.sh` script in HW1.2 and write a new `mapper.py` & `reducer.py` so that your modified script can perform WordCount on multiple words at a time. Passing `'*'` to your modified script should yield a tab separatated list of all words and their counts. When designing your modifications, __don't forget to add a sort component to your MapReduce framework and leverage the sort order in your reducer (i.e., there will be no need for a sort in reducer.py).__ You may wish to refer to this [notebook](http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/5zq0faibmvtjlbr/DivideAndConquer2-python-Plus-CmdLine.ipynb), or video section 1.12.1 1.12.1 Poor Man's MapReduce Using Command Line (Part 2) located at: \n",
    "https://learn.datascience.berkeley.edu/mod/page/view.php?id=10961\n",
    "\n",
    "To complete this question, make sure of the following:\n",
    "   \n",
    "* Your new mapper.py counts all occurrences of each word in the line.\n",
    "* In the `pWordCount.sh`, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts.\n",
    "* Your new reducer.py sums the count value from the collated records for each  word. There should be no sort in the reducer.py\n",
    "\n",
    "Your final output should match the output from __HW1.1.1__ (may vary a bit from the sample below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW1.3 MAPPER\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "count = 0\n",
    "\n",
    "findword = sys.argv[1]\n",
    "\n",
    "if(findword == \"*\"):\n",
    "    #for line in sys.stdin:\n",
    "        #for each word in the line\n",
    "        #for w in line.split():\n",
    "            #count occurrences of the word in the line\n",
    "            #count = count + line.lower().count(w)\n",
    "            #print count\n",
    "    wordCounts = defaultdict(int)\n",
    "    \n",
    "    for line in sys.stdin:\n",
    "        for word in re.findall(r'[a-z]+', line.lower()):\n",
    "            wordCounts[word] += 1\n",
    "        \n",
    "    for key in sorted(wordCounts):\n",
    "        print key,'\\t', wordCounts[key]\n",
    "else:\n",
    "    for line in sys.stdin:\n",
    "        # count all occurances of the word in each line:\n",
    "        count = count + line.lower().count(findword)\n",
    "    print findword,'\\t', count\n",
    "\n",
    "# END STUDENT CODE HW1.3 MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW1.3 REDUCER\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "sum = 0\n",
    "prevword = None\n",
    "\n",
    "#findword = sys.argv[1]\n",
    "\n",
    "#if(findword == \"*\"):\n",
    "wordCounts = defaultdict(int)\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    #print line\n",
    "    word, count = line.split('\\t')\n",
    "    #if(word == prevword or prevword == None):\n",
    "    wordCounts[word] += int(count)\n",
    "    prevword = word\n",
    "    # print the top 10 lines\n",
    "    #if idx < 10:\n",
    "    #print '{:17}{:3d}'.format(word, int(count))\n",
    "    #idx += 1  \n",
    "\n",
    "for key in sorted(wordCounts):\n",
    "        print key,'\\t', wordCounts[key]\n",
    "    \n",
    "#else:\n",
    " #   for line in sys.stdin:\n",
    "        #sum += int(line)\n",
    "\n",
    "    #print sum\n",
    "# END STUDENT CODE HW1.3 REDUCER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell use the Unix chmod command to change the permissions of the mapper/reducer using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mapper.py; \n",
    "!chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run the command below with 4 mappers. You should get the same result as in HW1.1.1__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  \t690\r\n",
      "abide  \t2\r\n",
      "able  \t1\r\n",
      "about  \t102\r\n",
      "above  \t3\r\n",
      "absence  \t1\r\n",
      "absurd  \t2\r\n",
      "accept  \t1\r\n",
      "acceptance  \t1\r\n",
      "accepted  \t2\r\n",
      "accepting  \t1\r\n",
      "access  \t10\r\n",
      "accessed  \t1\r\n",
      "accessible  \t1\r\n",
      "accident  \t2\r\n",
      "accidentally  \t1\r\n",
      "accordance  \t2\r\n",
      "account  \t1\r\n",
      "accounting  \t1\r\n",
      "accounts  \t1\r\n",
      "accusation  \t1\r\n",
      "accustomed  \t1\r\n",
      "ache  \t1\r\n",
      "across  \t5\r\n",
      "act  \t1\r\n",
      "active  \t2\r\n",
      "actual  \t1\r\n",
      "actually  \t1\r\n",
      "ada  \t1\r\n",
      "added  \t23\r\n",
      "adding  \t1\r\n",
      "addition  \t1\r\n",
      "additional  \t4\r\n",
      "additions  \t1\r\n",
      "address  \t1\r\n",
      "addressed  \t2\r\n",
      "addresses  \t1\r\n",
      "addressing  \t1\r\n",
      "adjourn  \t1\r\n",
      "adoption  \t1\r\n",
      "advance  \t3\r\n",
      "advantage  \t3\r\n",
      "adventures  \t12\r\n",
      "advice  \t2\r\n",
      "advisable  \t2\r\n",
      "advise  \t1\r\n",
      "affair  \t1\r\n",
      "affectionately  \t1\r\n",
      "afford  \t1\r\n",
      "afore  \t1\r\n",
      "afraid  \t12\r\n",
      "after  \t43\r\n",
      "afterwards  \t2\r\n",
      "again  \t83\r\n",
      "against  \t10\r\n",
      "age  \t4\r\n",
      "aged  \t1\r\n",
      "agent  \t1\r\n",
      "ago  \t2\r\n",
      "agony  \t1\r\n",
      "agree  \t11\r\n",
      "agreed  \t1\r\n",
      "agreement  \t18\r\n",
      "ah  \t5\r\n",
      "ahem  \t1\r\n",
      "air  \t15\r\n",
      "airs  \t1\r\n",
      "ak  \t1\r\n",
      "alarm  \t2\r\n",
      "alarmed  \t1\r\n",
      "alas  \t4\r\n",
      "alice  \t403\r\n",
      "alive  \t3\r\n",
      "all  \t200\r\n",
      "allow  \t4\r\n",
      "almost  \t8\r\n",
      "alone  \t5\r\n",
      "along  \t6\r\n",
      "aloud  \t5\r\n",
      "already  \t3\r\n",
      "also  \t4\r\n",
      "alteration  \t1\r\n",
      "altered  \t1\r\n",
      "alternate  \t1\r\n",
      "alternately  \t1\r\n",
      "altogether  \t5\r\n",
      "always  \t13\r\n",
      "am  \t16\r\n",
      "ambition  \t1\r\n",
      "among  \t12\r\n",
      "an  \t61\r\n",
      "ancient  \t1\r\n",
      "and  \t940\r\n",
      "anger  \t2\r\n",
      "angrily  \t9\r\n",
      "angry  \t5\r\n",
      "animal  \t2\r\n",
      "animals  \t4\r\n",
      "ann  \t4\r\n",
      "annoy  \t1\r\n",
      "annoyed  \t1\r\n",
      "another  \t22\r\n",
      "answer  \t9\r\n",
      "answered  \t4\r\n",
      "answers  \t1\r\n",
      "antipathies  \t1\r\n",
      "anxious  \t3\r\n",
      "anxiously  \t14\r\n",
      "any  \t76\r\n",
      "anyone  \t5\r\n",
      "anything  \t22\r\n",
      "anywhere  \t3\r\n",
      "appealed  \t1\r\n",
      "appear  \t3\r\n",
      "appearance  \t1\r\n",
      "appeared  \t8\r\n",
      "appearing  \t2\r\n",
      "appears  \t1\r\n",
      "applause  \t1\r\n",
      "apple  \t1\r\n",
      "apples  \t2\r\n",
      "applicable  \t3\r\n",
      "apply  \t1\r\n",
      "approach  \t1\r\n",
      "arch  \t1\r\n",
      "archbishop  \t2\r\n",
      "arches  \t4\r\n",
      "archive  \t13\r\n",
      "are  \t73\r\n",
      "argue  \t1\r\n",
      "argued  \t1\r\n",
      "argument  \t4\r\n",
      "arguments  \t1\r\n",
      "arise  \t1\r\n",
      "arithmetic  \t1\r\n",
      "arm  \t15\r\n",
      "arms  \t6\r\n",
      "around  \t3\r\n",
      "arranged  \t1\r\n",
      "array  \t1\r\n",
      "arrived  \t1\r\n",
      "arrow  \t1\r\n",
      "arrum  \t1\r\n",
      "as  \t274\r\n",
      "ascii  \t2\r\n",
      "ashamed  \t2\r\n",
      "ask  \t11\r\n",
      "askance  \t1\r\n",
      "asked  \t17\r\n",
      "asking  \t5\r\n",
      "asleep  \t8\r\n",
      "assembled  \t2\r\n",
      "assistance  \t1\r\n",
      "associated  \t8\r\n",
      "at  \t227\r\n",
      "ate  \t1\r\n",
      "atheling  \t1\r\n",
      "atom  \t2\r\n",
      "attached  \t1\r\n",
      "attempt  \t1\r\n",
      "attempted  \t1\r\n",
      "attempts  \t1\r\n",
      "attended  \t1\r\n",
      "attending  \t3\r\n",
      "attends  \t1\r\n",
      "audibly  \t1\r\n",
      "australia  \t1\r\n",
      "author  \t1\r\n",
      "authority  \t2\r\n",
      "available  \t2\r\n",
      "avoid  \t1\r\n",
      "away  \t28\r\n",
      "awfully  \t1\r\n",
      "axes  \t1\r\n",
      "axis  \t1\r\n",
      "b  \t3\r\n",
      "baby  \t14\r\n",
      "back  \t39\r\n",
      "backs  \t1\r\n",
      "bad  \t2\r\n",
      "bag  \t1\r\n",
      "baked  \t1\r\n",
      "balanced  \t1\r\n",
      "balls  \t1\r\n",
      "bank  \t3\r\n",
      "banks  \t1\r\n",
      "banquet  \t1\r\n",
      "bark  \t2\r\n",
      "barking  \t1\r\n",
      "barley  \t1\r\n",
      "barrowful  \t2\r\n",
      "based  \t2\r\n",
      "bat  \t3\r\n",
      "bathing  \t1\r\n",
      "bats  \t4\r\n",
      "bawled  \t1\r\n",
      "be  \t167\r\n",
      "beak  \t1\r\n",
      "bear  \t2\r\n",
      "beast  \t1\r\n",
      "beasts  \t2\r\n",
      "beat  \t4\r\n",
      "beating  \t2\r\n",
      "beau  \t4\r\n",
      "beauti  \t1\r\n",
      "beautiful  \t13\r\n",
      "beautifully  \t2\r\n",
      "beautify  \t1\r\n",
      "became  \t2\r\n",
      "because  \t16\r\n",
      "become  \t5\r\n",
      "becoming  \t1\r\n",
      "bed  \t1\r\n",
      "beds  \t2\r\n",
      "bee  \t1\r\n",
      "been  \t38\r\n",
      "before  \t40\r\n",
      "beg  \t8\r\n",
      "began  \t58\r\n",
      "begged  \t1\r\n",
      "begin  \t13\r\n",
      "beginning  \t15\r\n",
      "begins  \t4\r\n",
      "begun  \t7\r\n",
      "behead  \t1\r\n",
      "beheaded  \t3\r\n",
      "beheading  \t1\r\n",
      "behind  \t13\r\n",
      "being  \t19\r\n",
      "believe  \t9\r\n",
      "believed  \t1\r\n",
      "bells  \t1\r\n",
      "belong  \t1\r\n",
      "belongs  \t2\r\n",
      "beloved  \t1\r\n",
      "below  \t6\r\n",
      "belt  \t1\r\n",
      "bend  \t2\r\n",
      "bent  \t1\r\n",
      "besides  \t4\r\n",
      "best  \t12\r\n",
      "better  \t14\r\n",
      "between  \t6\r\n",
      "bill  \t17\r\n",
      "binary  \t1\r\n",
      "bird  \t2\r\n",
      "birds  \t10\r\n",
      "birthday  \t1\r\n",
      "bit  \t16\r\n",
      "bite  \t2\r\n",
      "bitter  \t1\r\n",
      "blacking  \t1\r\n",
      "blades  \t1\r\n",
      "blame  \t1\r\n",
      "blasts  \t2\r\n",
      "bleeds  \t1\r\n",
      "blew  \t2\r\n",
      "blow  \t2\r\n",
      "blown  \t1\r\n",
      "blows  \t1\r\n",
      "body  \t2\r\n",
      "boldly  \t1\r\n",
      "bone  \t1\r\n",
      "bones  \t1\r\n",
      "book  \t11\r\n",
      "books  \t2\r\n",
      "boon  \t1\r\n",
      "boots  \t4\r\n",
      "bore  \t1\r\n",
      "both  \t16\r\n",
      "bother  \t1\r\n",
      "bottle  \t10\r\n",
      "bottom  \t4\r\n",
      "bough  \t1\r\n",
      "bound  \t3\r\n",
      "bowed  \t4\r\n",
      "bowing  \t1\r\n",
      "box  \t10\r\n",
      "boxed  \t1\r\n",
      "boy  \t3\r\n",
      "brain  \t1\r\n",
      "branch  \t1\r\n",
      "branches  \t2\r\n",
      "brandy  \t1\r\n",
      "brass  \t1\r\n",
      "brave  \t1\r\n",
      "breach  \t2\r\n",
      "bread  \t7\r\n",
      "break  \t2\r\n",
      "breath  \t4\r\n",
      "breathe  \t3\r\n",
      "breeze  \t1\r\n",
      "bright  \t8\r\n",
      "brightened  \t2\r\n",
      "bring  \t3\r\n",
      "bringing  \t3\r\n",
      "bristling  \t1\r\n",
      "broke  \t2\r\n",
      "broken  \t6\r\n",
      "brother  \t1\r\n",
      "brought  \t3\r\n",
      "brown  \t2\r\n",
      "brush  \t1\r\n",
      "brushing  \t1\r\n",
      "burn  \t2\r\n",
      "burning  \t1\r\n",
      "burnt  \t1\r\n",
      "burst  \t1\r\n",
      "bursting  \t1\r\n",
      "busily  \t4\r\n",
      "business  \t9\r\n",
      "busy  \t2\r\n",
      "but  \t175\r\n",
      "butter  \t9\r\n",
      "buttercup  \t1\r\n",
      "buttered  \t1\r\n",
      "butterfly  \t1\r\n",
      "buttons  \t1\r\n",
      "by  \t78\r\n",
      "bye  \t2\r\n",
      "c  \t6\r\n",
      "cackled  \t1\r\n",
      "cake  \t3\r\n",
      "cakes  \t3\r\n",
      "calculate  \t1\r\n",
      "calculated  \t1\r\n",
      "call  \t9\r\n",
      "called  \t15\r\n",
      "calling  \t1\r\n",
      "calmly  \t1\r\n",
      "came  \t40\r\n",
      "camomile  \t1\r\n",
      "can  \t73\r\n",
      "canary  \t1\r\n",
      "candle  \t3\r\n",
      "cannot  \t5\r\n",
      "canterbury  \t1\r\n",
      "canvas  \t1\r\n",
      "capering  \t1\r\n",
      "capital  \t4\r\n",
      "card  \t1\r\n",
      "cardboard  \t1\r\n",
      "cards  \t3\r\n",
      "care  \t4\r\n",
      "carefully  \t3\r\n",
      "cares  \t2\r\n",
      "carried  \t4\r\n",
      "carrier  \t1\r\n",
      "carroll  \t4\r\n",
      "carry  \t2\r\n",
      "carrying  \t2\r\n",
      "cart  \t1\r\n",
      "cartwheels  \t1\r\n",
      "case  \t5\r\n",
      "cat  \t37\r\n",
      "catch  \t4\r\n",
      "catching  \t2\r\n",
      "caterpillar  \t28\r\n",
      "cats  \t13\r\n",
      "cattle  \t1\r\n",
      "caucus  \t3\r\n",
      "caught  \t3\r\n",
      "cauldron  \t2\r\n",
      "cause  \t5\r\n",
      "caused  \t2\r\n",
      "cautiously  \t3\r\n",
      "cease  \t1\r\n",
      "ceiling  \t1\r\n",
      "centre  \t1\r\n",
      "certain  \t5\r\n",
      "certainly  \t14\r\n",
      "chain  \t1\r\n",
      "chains  \t1\r\n",
      "chair  \t1\r\n",
      "chance  \t4\r\n",
      "chanced  \t1\r\n",
      "change  \t15\r\n",
      "changed  \t8\r\n",
      "changes  \t2\r\n",
      "changing  \t2\r\n",
      "chapter  \t12\r\n",
      "character  \t2\r\n",
      "charge  \t6\r\n",
      "charges  \t2\r\n",
      "charitable  \t1\r\n",
      "charities  \t1\r\n",
      "chatte  \t1\r\n",
      "cheap  \t1\r\n",
      "cheated  \t1\r\n",
      "check  \t2\r\n",
      "checked  \t3\r\n",
      "checks  \t1\r\n",
      "cheeks  \t1\r\n",
      "cheered  \t3\r\n",
      "cheerfully  \t1\r\n",
      "cherry  \t1\r\n",
      "cheshire  \t7\r\n",
      "chief  \t2\r\n",
      "child  \t11\r\n",
      "childhood  \t1\r\n",
      "children  \t10\r\n",
      "chimney  \t6\r\n",
      "chimneys  \t1\r\n",
      "chin  \t7\r\n",
      "choice  \t2\r\n",
      "choke  \t1\r\n",
      "choked  \t3\r\n",
      "choking  \t1\r\n",
      "choose  \t1\r\n",
      "choosing  \t1\r\n",
      "chop  \t1\r\n",
      "chorus  \t6\r\n",
      "chose  \t2\r\n",
      "christmas  \t1\r\n",
      "chrysalis  \t1\r\n",
      "chuckled  \t1\r\n",
      "circle  \t1\r\n",
      "circumstances  \t1\r\n",
      "city  \t1\r\n",
      "civil  \t3\r\n",
      "claim  \t1\r\n",
      "clamour  \t1\r\n",
      "clapping  \t1\r\n",
      "clasped  \t1\r\n",
      "classics  \t1\r\n",
      "claws  \t2\r\n",
      "clean  \t1\r\n",
      "clear  \t2\r\n",
      "cleared  \t1\r\n",
      "clearer  \t1\r\n",
      "clearly  \t2\r\n",
      "clever  \t2\r\n",
      "climb  \t1\r\n",
      "clinging  \t1\r\n",
      "clock  \t5\r\n",
      "close  \t13\r\n",
      "closed  \t2\r\n",
      "closely  \t1\r\n",
      "closer  \t1\r\n",
      "clubs  \t1\r\n",
      "coast  \t1\r\n",
      "coaxing  \t2\r\n",
      "codes  \t1\r\n",
      "coils  \t1\r\n",
      "cold  \t1\r\n",
      "collar  \t1\r\n",
      "collected  \t2\r\n",
      "collection  \t4\r\n",
      "come  \t47\r\n",
      "comes  \t2\r\n",
      "comfits  \t2\r\n",
      "comfort  \t1\r\n",
      "comfortable  \t1\r\n",
      "comfortably  \t1\r\n",
      "coming  \t9\r\n",
      "commercial  \t1\r\n",
      "committed  \t1\r\n",
      "common  \t1\r\n",
      "commotion  \t1\r\n",
      "company  \t1\r\n",
      "compilation  \t1\r\n",
      "complained  \t1\r\n",
      "complaining  \t1\r\n",
      "completely  \t1\r\n",
      "compliance  \t5\r\n",
      "comply  \t6\r\n",
      "complying  \t3\r\n",
      "compressed  \t1\r\n",
      "computer  \t2\r\n",
      "computers  \t2\r\n",
      "concept  \t2\r\n",
      "concerning  \t2\r\n",
      "concert  \t2\r\n",
      "concluded  \t2\r\n",
      "conclusion  \t2\r\n",
      "condemn  \t1\r\n",
      "conduct  \t1\r\n",
      "confirmation  \t1\r\n",
      "confirmed  \t1\r\n",
      "confused  \t4\r\n",
      "confusing  \t3\r\n",
      "confusion  \t5\r\n",
      "conger  \t1\r\n",
      "conqueror  \t2\r\n",
      "conquest  \t1\r\n",
      "consented  \t1\r\n",
      "consequential  \t1\r\n",
      "consider  \t4\r\n",
      "considerable  \t2\r\n",
      "considered  \t3\r\n",
      "considering  \t3\r\n",
      "constant  \t3\r\n",
      "consultation  \t1\r\n",
      "contact  \t4\r\n",
      "contain  \t2\r\n",
      "containing  \t1\r\n",
      "contempt  \t1\r\n",
      "contemptuous  \t1\r\n",
      "contemptuously  \t2\r\n",
      "content  \t1\r\n",
      "continued  \t9\r\n",
      "contract  \t1\r\n",
      "contradicted  \t1\r\n",
      "contributions  \t2\r\n",
      "conversation  \t9\r\n",
      "conversations  \t2\r\n",
      "convert  \t1\r\n",
      "cook  \t13\r\n",
      "cool  \t2\r\n",
      "copied  \t2\r\n",
      "copies  \t7\r\n",
      "copy  \t12\r\n",
      "copying  \t4\r\n",
      "copyright  \t14\r\n",
      "corner  \t4\r\n",
      "corners  \t1\r\n",
      "corporation  \t1\r\n",
      "corrupt  \t1\r\n",
      "cost  \t4\r\n",
      "costs  \t2\r\n",
      "could  \t78\r\n",
      "couldn  \t9\r\n",
      "counting  \t1\r\n",
      "countries  \t1\r\n",
      "country  \t3\r\n",
      "couple  \t1\r\n",
      "couples  \t1\r\n",
      "courage  \t3\r\n",
      "course  \t27\r\n",
      "court  \t18\r\n",
      "courtiers  \t2\r\n",
      "coward  \t1\r\n",
      "crab  \t3\r\n",
      "crash  \t3\r\n",
      "crashed  \t1\r\n",
      "crawled  \t1\r\n",
      "crawling  \t1\r\n",
      "crazy  \t1\r\n",
      "created  \t2\r\n",
      "creating  \t4\r\n",
      "creation  \t1\r\n",
      "creature  \t4\r\n",
      "creatures  \t10\r\n",
      "credit  \t1\r\n",
      "creep  \t1\r\n",
      "crept  \t1\r\n",
      "cried  \t20\r\n",
      "cries  \t1\r\n",
      "crimson  \t2\r\n",
      "critical  \t1\r\n",
      "crocodile  \t1\r\n",
      "croquet  \t9\r\n",
      "croqueted  \t1\r\n",
      "croqueting  \t1\r\n",
      "cross  \t3\r\n",
      "crossed  \t3\r\n",
      "crossly  \t1\r\n",
      "crouched  \t1\r\n",
      "crowd  \t4\r\n",
      "crowded  \t5\r\n",
      "crown  \t3\r\n",
      "crumbs  \t4\r\n",
      "crust  \t1\r\n",
      "cry  \t3\r\n",
      "crying  \t2\r\n",
      "cucumber  \t2\r\n",
      "cunning  \t1\r\n",
      "cup  \t2\r\n",
      "cupboards  \t2\r\n",
      "cur  \t1\r\n",
      "curiosity  \t5\r\n",
      "curious  \t19\r\n",
      "curiouser  \t2\r\n",
      "curled  \t2\r\n",
      "curls  \t1\r\n",
      "curly  \t1\r\n",
      "currants  \t1\r\n",
      "current  \t1\r\n",
      "curtain  \t1\r\n",
      "curtsey  \t1\r\n",
      "curtseying  \t1\r\n",
      "curving  \t1\r\n",
      "cushion  \t2\r\n",
      "custard  \t1\r\n",
      "custody  \t2\r\n",
      "cut  \t5\r\n",
      "cutting  \t1\r\n",
      "d  \t30\r\n",
      "dainties  \t1\r\n",
      "daisies  \t1\r\n",
      "daisy  \t1\r\n",
      "damage  \t2\r\n",
      "damaged  \t1\r\n",
      "damages  \t4\r\n",
      "dance  \t13\r\n",
      "dancing  \t2\r\n",
      "dare  \t5\r\n",
      "daresay  \t1\r\n",
      "dark  \t3\r\n",
      "darkness  \t1\r\n",
      "data  \t1\r\n",
      "date  \t4\r\n",
      "dates  \t1\r\n",
      "daughter  \t1\r\n",
      "day  \t29\r\n",
      "days  \t8\r\n",
      "dead  \t4\r\n",
      "deal  \t12\r\n",
      "dear  \t29\r\n",
      "dears  \t3\r\n",
      "death  \t1\r\n",
      "decided  \t3\r\n",
      "decidedly  \t4\r\n",
      "declare  \t2\r\n",
      "declared  \t1\r\n",
      "deductible  \t1\r\n",
      "deep  \t7\r\n",
      "deepest  \t1\r\n",
      "deeply  \t4\r\n",
      "defect  \t3\r\n",
      "defective  \t3\r\n",
      "defects  \t1\r\n",
      "delay  \t1\r\n",
      "deletions  \t1\r\n",
      "delight  \t3\r\n",
      "delighted  \t2\r\n",
      "delightful  \t2\r\n",
      "demand  \t1\r\n",
      "denial  \t1\r\n",
      "denied  \t2\r\n",
      "denies  \t1\r\n",
      "deny  \t2\r\n",
      "denying  \t1\r\n",
      "depends  \t2\r\n",
      "derision  \t1\r\n",
      "derivative  \t3\r\n",
      "derive  \t1\r\n",
      "derived  \t1\r\n",
      "described  \t1\r\n",
      "deserved  \t1\r\n",
      "desk  \t1\r\n",
      "desks  \t1\r\n",
      "despair  \t1\r\n",
      "desperate  \t1\r\n",
      "desperately  \t1\r\n",
      "despite  \t1\r\n",
      "destroy  \t2\r\n",
      "detach  \t1\r\n",
      "determine  \t1\r\n",
      "diamonds  \t1\r\n",
      "did  \t63\r\n",
      "didn  \t14\r\n",
      "die  \t1\r\n",
      "died  \t1\r\n",
      "different  \t10\r\n",
      "difficult  \t2\r\n",
      "difficulties  \t1\r\n",
      "difficulty  \t4\r\n",
      "dig  \t1\r\n",
      "digging  \t4\r\n",
      "diligently  \t1\r\n",
      "dinah  \t14\r\n",
      "dinn  \t2\r\n",
      "dinner  \t2\r\n",
      "dipped  \t2\r\n",
      "direct  \t1\r\n",
      "directed  \t2\r\n",
      "direction  \t5\r\n",
      "directions  \t3\r\n",
      "directly  \t3\r\n",
      "director  \t1\r\n",
      "disagree  \t1\r\n",
      "disappeared  \t2\r\n",
      "disappointment  \t1\r\n",
      "disclaim  \t1\r\n",
      "disclaimer  \t3\r\n",
      "disclaimers  \t1\r\n",
      "discontinue  \t1\r\n",
      "discover  \t1\r\n",
      "discovered  \t1\r\n",
      "disgust  \t1\r\n",
      "dish  \t4\r\n",
      "dishes  \t2\r\n",
      "disk  \t1\r\n",
      "dismay  \t1\r\n",
      "disobey  \t1\r\n",
      "display  \t1\r\n",
      "displayed  \t1\r\n",
      "displaying  \t4\r\n",
      "dispute  \t2\r\n",
      "distance  \t8\r\n",
      "distant  \t2\r\n",
      "distraction  \t1\r\n",
      "distribute  \t6\r\n",
      "distributed  \t4\r\n",
      "distributing  \t7\r\n",
      "distribution  \t6\r\n",
      "distributor  \t1\r\n",
      "dive  \t1\r\n",
      "do  \t98\r\n",
      "dodged  \t1\r\n",
      "dodo  \t13\r\n",
      "does  \t11\r\n",
      "doesn  \t16\r\n",
      "dog  \t3\r\n",
      "dogs  \t3\r\n",
      "doing  \t5\r\n",
      "domain  \t8\r\n",
      "don  \t61\r\n",
      "donate  \t4\r\n",
      "donation  \t1\r\n",
      "donations  \t15\r\n",
      "done  \t15\r\n",
      "donors  \t1\r\n",
      "door  \t30\r\n",
      "doors  \t2\r\n",
      "doorway  \t1\r\n",
      "dormouse  \t40\r\n",
      "doth  \t3\r\n",
      "double  \t1\r\n",
      "doubled  \t1\r\n",
      "doubling  \t1\r\n",
      "doubt  \t4\r\n",
      "doubtful  \t2\r\n",
      "doubtfully  \t2\r\n",
      "down  \t102\r\n",
      "downloading  \t1\r\n",
      "downward  \t1\r\n",
      "downwards  \t1\r\n",
      "doze  \t1\r\n",
      "dozing  \t1\r\n",
      "dr  \t2\r\n",
      "draggled  \t1\r\n",
      "draw  \t7\r\n",
      "drawing  \t1\r\n",
      "drawling  \t3\r\n",
      "dreadful  \t2\r\n",
      "dreadfully  \t6\r\n",
      "dream  \t7\r\n",
      "dreamed  \t1\r\n",
      "dreaming  \t1\r\n",
      "dreamy  \t1\r\n",
      "dressed  \t1\r\n",
      "drew  \t5\r\n",
      "dried  \t1\r\n",
      "driest  \t1\r\n",
      "drink  \t7\r\n",
      "drinking  \t1\r\n",
      "dripping  \t1\r\n",
      "drive  \t2\r\n",
      "drop  \t1\r\n",
      "dropped  \t5\r\n",
      "dropping  \t1\r\n",
      "drowned  \t1\r\n",
      "drunk  \t2\r\n",
      "dry  \t8\r\n",
      "duchess  \t42\r\n",
      "duck  \t4\r\n",
      "dull  \t3\r\n",
      "dunce  \t1\r\n",
      "e  \t29\r\n",
      "each  \t9\r\n",
      "eager  \t3\r\n",
      "eagerly  \t8\r\n",
      "eaglet  \t3\r\n",
      "ear  \t6\r\n",
      "earls  \t2\r\n",
      "earnestly  \t2\r\n",
      "ears  \t5\r\n",
      "earth  \t4\r\n",
      "easily  \t4\r\n",
      "easy  \t3\r\n",
      "eat  \t18\r\n",
      "eaten  \t1\r\n",
      "eating  \t1\r\n",
      "eats  \t1\r\n",
      "ebook  \t9\r\n",
      "ebooks  \t7\r\n",
      "edgar  \t1\r\n",
      "edge  \t3\r\n",
      "edition  \t2\r\n",
      "editions  \t6\r\n",
      "educational  \t1\r\n",
      "educations  \t1\r\n",
      "edwin  \t2\r\n",
      "eel  \t2\r\n",
      "eels  \t1\r\n",
      "effect  \t3\r\n",
      "effort  \t2\r\n",
      "efforts  \t3\r\n",
      "egg  \t1\r\n",
      "eggs  \t5\r\n",
      "eh  \t1\r\n",
      "ein  \t1\r\n",
      "either  \t11\r\n",
      "elbow  \t3\r\n",
      "elbows  \t1\r\n",
      "elect  \t1\r\n",
      "electronic  \t27\r\n",
      "electronically  \t2\r\n",
      "elegant  \t1\r\n",
      "eleventh  \t1\r\n",
      "else  \t12\r\n",
      "elsie  \t1\r\n",
      "em  \t3\r\n",
      "email  \t3\r\n",
      "emphasis  \t1\r\n",
      "employee  \t1\r\n",
      "employees  \t2\r\n",
      "empty  \t1\r\n",
      "encoding  \t1\r\n",
      "encourage  \t1\r\n",
      "encouraged  \t1\r\n",
      "encouraging  \t2\r\n",
      "end  \t20\r\n",
      "ending  \t2\r\n",
      "energetic  \t1\r\n",
      "engaged  \t1\r\n",
      "engine  \t1\r\n",
      "england  \t1\r\n",
      "english  \t7\r\n",
      "engraved  \t1\r\n",
      "enjoy  \t1\r\n",
      "enormous  \t1\r\n",
      "enough  \t18\r\n",
      "ensuring  \t1\r\n",
      "entangled  \t2\r\n",
      "entirely  \t2\r\n",
      "entity  \t3\r\n",
      "entrance  \t1\r\n",
      "equipment  \t3\r\n",
      "errors  \t1\r\n",
      "escape  \t4\r\n",
      "especially  \t1\r\n",
      "esq  \t1\r\n",
      "est  \t1\r\n",
      "even  \t21\r\n",
      "evening  \t5\r\n",
      "ever  \t21\r\n",
      "every  \t12\r\n",
      "everybody  \t8\r\n",
      "everything  \t14\r\n",
      "evidence  \t7\r\n",
      "evidently  \t1\r\n",
      "exact  \t1\r\n",
      "exactly  \t8\r\n",
      "examine  \t2\r\n",
      "examining  \t1\r\n",
      "excellent  \t2\r\n",
      "except  \t7\r\n",
      "exclaimed  \t6\r\n",
      "exclamation  \t1\r\n",
      "exclusion  \t1\r\n",
      "execute  \t1\r\n",
      "executed  \t6\r\n",
      "executes  \t1\r\n",
      "execution  \t3\r\n",
      "executioner  \t6\r\n",
      "executions  \t2\r\n",
      "executive  \t1\r\n",
      "exempt  \t2\r\n",
      "existence  \t1\r\n",
      "exists  \t1\r\n",
      "expected  \t1\r\n",
      "expecting  \t3\r\n",
      "expend  \t1\r\n",
      "expense  \t1\r\n",
      "expenses  \t2\r\n",
      "experiment  \t2\r\n",
      "explain  \t10\r\n",
      "explained  \t1\r\n",
      "explanation  \t4\r\n",
      "explanations  \t1\r\n",
      "exporting  \t1\r\n",
      "express  \t1\r\n",
      "expressing  \t1\r\n",
      "expression  \t1\r\n",
      "extent  \t1\r\n",
      "extra  \t1\r\n",
      "extraordinary  \t2\r\n",
      "extras  \t1\r\n",
      "extremely  \t2\r\n",
      "eye  \t7\r\n",
      "eyed  \t1\r\n",
      "eyelids  \t1\r\n",
      "eyes  \t29\r\n",
      "f  \t11\r\n",
      "face  \t15\r\n",
      "faces  \t5\r\n",
      "facility  \t1\r\n",
      "fact  \t8\r\n",
      "fading  \t1\r\n",
      "failure  \t1\r\n",
      "faint  \t1\r\n",
      "fainting  \t1\r\n",
      "faintly  \t1\r\n",
      "fair  \t1\r\n",
      "fairbanks  \t1\r\n",
      "fairly  \t1\r\n",
      "fairy  \t1\r\n",
      "fall  \t7\r\n",
      "fallen  \t4\r\n",
      "falling  \t2\r\n",
      "familiarly  \t1\r\n",
      "family  \t1\r\n",
      "fan  \t10\r\n",
      "fancied  \t2\r\n",
      "fancy  \t7\r\n",
      "fancying  \t1\r\n",
      "fanned  \t1\r\n",
      "fanning  \t1\r\n",
      "far  \t13\r\n",
      "farm  \t1\r\n",
      "farmer  \t1\r\n",
      "farther  \t1\r\n",
      "fashion  \t2\r\n",
      "fast  \t4\r\n",
      "faster  \t3\r\n",
      "fat  \t1\r\n",
      "father  \t6\r\n",
      "favoured  \t1\r\n",
      "favourite  \t1\r\n",
      "fear  \t4\r\n",
      "feared  \t1\r\n",
      "feather  \t1\r\n",
      "feathers  \t1\r\n",
      "federal  \t2\r\n",
      "fee  \t8\r\n",
      "feeble  \t2\r\n",
      "feebly  \t1\r\n",
      "feel  \t8\r\n",
      "feeling  \t7\r\n",
      "feelings  \t2\r\n",
      "fees  \t4\r\n",
      "feet  \t19\r\n",
      "fell  \t6\r\n",
      "fellow  \t4\r\n",
      "fellows  \t1\r\n",
      "felt  \t23\r\n",
      "fender  \t1\r\n",
      "ferrets  \t2\r\n",
      "fetch  \t7\r\n",
      "few  \t10\r\n",
      "fidgeted  \t1\r\n",
      "field  \t1\r\n",
      "fifteen  \t1\r\n",
      "fifteenth  \t1\r\n",
      "fifth  \t1\r\n",
      "fig  \t1\r\n",
      "fight  \t2\r\n",
      "fighting  \t1\r\n",
      "figure  \t3\r\n",
      "figures  \t1\r\n",
      "file  \t2\r\n",
      "files  \t2\r\n",
      "filled  \t3\r\n",
      "fills  \t1\r\n",
      "financial  \t1\r\n",
      "find  \t21\r\n",
      "finding  \t3\r\n",
      "finds  \t1\r\n",
      "fine  \t2\r\n",
      "finger  \t5\r\n",
      "finish  \t5\r\n",
      "finished  \t12\r\n",
      "finishing  \t1\r\n",
      "fire  \t4\r\n",
      "fireplace  \t1\r\n",
      "first  \t51\r\n",
      "fish  \t8\r\n",
      "fishes  \t1\r\n",
      "fit  \t3\r\n",
      "fitness  \t1\r\n",
      "fits  \t1\r\n",
      "fitted  \t1\r\n",
      "five  \t8\r\n",
      "fix  \t2\r\n",
      "fixed  \t1\r\n",
      "flame  \t1\r\n",
      "flamingo  \t5\r\n",
      "flamingoes  \t2\r\n",
      "flapper  \t1\r\n",
      "flappers  \t1\r\n",
      "flashed  \t1\r\n",
      "flat  \t2\r\n",
      "flavour  \t1\r\n",
      "flew  \t1\r\n",
      "flinging  \t1\r\n",
      "flock  \t1\r\n",
      "floor  \t3\r\n",
      "flower  \t2\r\n",
      "flowers  \t2\r\n",
      "flown  \t1\r\n",
      "flung  \t1\r\n",
      "flurry  \t1\r\n",
      "flustered  \t1\r\n",
      "fluttered  \t1\r\n",
      "fly  \t3\r\n",
      "flying  \t1\r\n",
      "folded  \t3\r\n",
      "folding  \t1\r\n",
      "follow  \t3\r\n",
      "followed  \t8\r\n",
      "following  \t3\r\n",
      "follows  \t3\r\n",
      "fond  \t4\r\n",
      "foolish  \t1\r\n",
      "foot  \t10\r\n",
      "footman  \t14\r\n",
      "footmen  \t1\r\n",
      "footsteps  \t2\r\n",
      "for  \t179\r\n",
      "forehead  \t2\r\n",
      "forepaws  \t1\r\n",
      "forget  \t2\r\n",
      "forgetting  \t3\r\n",
      "forgot  \t2\r\n",
      "forgotten  \t6\r\n",
      "fork  \t1\r\n",
      "form  \t5\r\n",
      "format  \t4\r\n",
      "formats  \t2\r\n",
      "forth  \t8\r\n",
      "fortunately  \t1\r\n",
      "forty  \t1\r\n",
      "forwards  \t1\r\n",
      "found  \t35\r\n",
      "foundation  \t25\r\n",
      "fountains  \t2\r\n",
      "four  \t8\r\n",
      "fourteenth  \t1\r\n",
      "fourth  \t1\r\n",
      "frame  \t1\r\n",
      "frames  \t1\r\n",
      "france  \t1\r\n",
      "free  \t8\r\n",
      "freely  \t4\r\n",
      "french  \t4\r\n",
      "friend  \t3\r\n",
      "friends  \t2\r\n",
      "fright  \t2\r\n",
      "frighten  \t1\r\n",
      "frightened  \t7\r\n",
      "frog  \t3\r\n",
      "from  \t51\r\n",
      "front  \t2\r\n",
      "frontispiece  \t1\r\n",
      "frowning  \t4\r\n",
      "frying  \t1\r\n",
      "ful  \t1\r\n",
      "fulcrum  \t1\r\n",
      "full  \t19\r\n",
      "fumbled  \t1\r\n",
      "fun  \t3\r\n",
      "fundraising  \t1\r\n",
      "funny  \t3\r\n",
      "fur  \t3\r\n",
      "furious  \t1\r\n",
      "furiously  \t1\r\n",
      "furrow  \t1\r\n",
      "furrows  \t1\r\n",
      "further  \t4\r\n",
      "fury  \t3\r\n",
      "future  \t3\r\n",
      "gained  \t1\r\n",
      "gallons  \t1\r\n",
      "game  \t13\r\n",
      "games  \t1\r\n",
      "garden  \t16\r\n",
      "gardeners  \t8\r\n",
      "gather  \t1\r\n",
      "gave  \t15\r\n",
      "gay  \t1\r\n",
      "gazing  \t1\r\n",
      "gbnewby  \t1\r\n",
      "general  \t6\r\n",
      "generally  \t7\r\n",
      "generations  \t2\r\n",
      "gently  \t3\r\n",
      "geography  \t1\r\n",
      "get  \t46\r\n",
      "getting  \t22\r\n",
      "giddy  \t2\r\n",
      "girl  \t4\r\n",
      "girls  \t3\r\n",
      "give  \t16\r\n",
      "given  \t2\r\n",
      "giving  \t2\r\n",
      "glad  \t11\r\n",
      "glanced  \t1\r\n",
      "glaring  \t1\r\n",
      "glass  \t10\r\n",
      "globe  \t1\r\n",
      "gloomily  \t1\r\n",
      "gloves  \t11\r\n",
      "go  \t50\r\n",
      "goals  \t1\r\n",
      "goes  \t7\r\n",
      "going  \t27\r\n",
      "golden  \t7\r\n",
      "goldfish  \t2\r\n",
      "gone  \t13\r\n",
      "good  \t27\r\n",
      "goose  \t2\r\n",
      "got  \t45\r\n",
      "govern  \t1\r\n",
      "graceful  \t1\r\n",
      "grammar  \t1\r\n",
      "grand  \t3\r\n",
      "grant  \t1\r\n",
      "granted  \t1\r\n",
      "grass  \t4\r\n",
      "gratefully  \t1\r\n",
      "grave  \t3\r\n",
      "gravely  \t3\r\n",
      "gravy  \t1\r\n",
      "grazed  \t1\r\n",
      "great  \t39\r\n",
      "green  \t4\r\n",
      "gregory  \t1\r\n",
      "grew  \t1\r\n",
      "grey  \t1\r\n",
      "grief  \t1\r\n",
      "grin  \t6\r\n",
      "grinned  \t3\r\n",
      "grinning  \t1\r\n",
      "grins  \t1\r\n",
      "gross  \t1\r\n",
      "ground  \t8\r\n",
      "group  \t1\r\n",
      "grow  \t13\r\n",
      "growing  \t11\r\n",
      "growl  \t3\r\n",
      "growled  \t1\r\n",
      "growling  \t1\r\n",
      "growls  \t1\r\n",
      "grown  \t7\r\n",
      "grumbled  \t1\r\n",
      "grunt  \t1\r\n",
      "grunted  \t4\r\n",
      "gryphon  \t55\r\n",
      "guard  \t1\r\n",
      "guess  \t3\r\n",
      "guessed  \t3\r\n",
      "guests  \t3\r\n",
      "guilt  \t1\r\n",
      "guinea  \t6\r\n",
      "gutenberg  \t93\r\n",
      "had  \t178\r\n",
      "hadn  \t8\r\n",
      "hair  \t7\r\n",
      "half  \t23\r\n",
      "hall  \t9\r\n",
      "hand  \t21\r\n",
      "handed  \t3\r\n",
      "hands  \t12\r\n",
      "handsome  \t1\r\n",
      "handwriting  \t1\r\n",
      "hanging  \t3\r\n",
      "happen  \t8\r\n",
      "happened  \t7\r\n",
      "happening  \t1\r\n",
      "happens  \t5\r\n",
      "happy  \t1\r\n",
      "hard  \t8\r\n",
      "hardly  \t12\r\n",
      "hare  \t31\r\n",
      "harm  \t1\r\n",
      "harmless  \t1\r\n",
      "hart  \t2\r\n",
      "has  \t9\r\n",
      "hasn  \t2\r\n",
      "haste  \t1\r\n",
      "hastily  \t16\r\n",
      "hat  \t1\r\n",
      "hatching  \t1\r\n",
      "hate  \t2\r\n",
      "hated  \t1\r\n",
      "hatter  \t56\r\n",
      "hatters  \t1\r\n",
      "have  \t85\r\n",
      "haven  \t8\r\n",
      "having  \t10\r\n",
      "he  \t128\r\n",
      "head  \t50\r\n",
      "heads  \t10\r\n",
      "heap  \t1\r\n",
      "hear  \t15\r\n",
      "heard  \t30\r\n",
      "hearing  \t4\r\n",
      "heart  \t2\r\n",
      "hearth  \t1\r\n",
      "hearthrug  \t1\r\n",
      "hearts  \t8\r\n",
      "heavy  \t2\r\n",
      "hedge  \t2\r\n",
      "hedgehog  \t7\r\n",
      "hedgehogs  \t3\r\n",
      "hedges  \t1\r\n",
      "heels  \t1\r\n",
      "height  \t5\r\n",
      "held  \t4\r\n",
      "help  \t12\r\n",
      "helped  \t1\r\n",
      "helpless  \t1\r\n",
      "her  \t248\r\n",
      "herald  \t1\r\n",
      "here  \t51\r\n",
      "hers  \t4\r\n",
      "herself  \t83\r\n",
      "hid  \t1\r\n",
      "hide  \t1\r\n",
      "high  \t16\r\n",
      "highest  \t1\r\n",
      "him  \t43\r\n",
      "himself  \t6\r\n",
      "hint  \t2\r\n",
      "hippopotamus  \t1\r\n",
      "his  \t96\r\n",
      "hiss  \t1\r\n",
      "histories  \t1\r\n",
      "history  \t7\r\n",
      "hit  \t2\r\n",
      "hjckrrh  \t1\r\n",
      "hm  \t1\r\n",
      "hoarse  \t3\r\n",
      "hoarsely  \t1\r\n",
      "hold  \t11\r\n",
      "holder  \t4\r\n",
      "holding  \t3\r\n",
      "hole  \t5\r\n",
      "holiday  \t1\r\n",
      "hollow  \t1\r\n",
      "home  \t5\r\n",
      "honest  \t1\r\n",
      "honour  \t4\r\n",
      "hookah  \t5\r\n",
      "hope  \t4\r\n",
      "hoped  \t1\r\n",
      "hopeful  \t1\r\n",
      "hopeless  \t1\r\n",
      "hoping  \t3\r\n",
      "horse  \t1\r\n",
      "hot  \t7\r\n",
      "hour  \t2\r\n",
      "hours  \t4\r\n",
      "house  \t18\r\n",
      "housemaid  \t1\r\n",
      "houses  \t1\r\n",
      "how  \t72\r\n",
      "however  \t21\r\n",
      "howled  \t1\r\n",
      "howling  \t3\r\n",
      "http  \t8\r\n",
      "humble  \t1\r\n",
      "humbly  \t2\r\n",
      "hundred  \t1\r\n",
      "hundreds  \t1\r\n",
      "hung  \t1\r\n",
      "hungry  \t3\r\n",
      "hunting  \t3\r\n",
      "hurried  \t11\r\n",
      "hurriedly  \t2\r\n",
      "hurry  \t11\r\n",
      "hurrying  \t1\r\n",
      "hurt  \t3\r\n",
      "hush  \t3\r\n",
      "hypertext  \t1\r\n",
      "i  \t545\r\n",
      "idea  \t15\r\n",
      "identification  \t1\r\n",
      "identify  \t1\r\n",
      "idiot  \t1\r\n",
      "idiotic  \t1\r\n",
      "if  \t116\r\n",
      "ignorant  \t1\r\n",
      "ii  \t1\r\n",
      "iii  \t1\r\n",
      "ill  \t2\r\n",
      "imagine  \t2\r\n",
      "imitated  \t1\r\n",
      "immediate  \t3\r\n",
      "immediately  \t3\r\n",
      "immense  \t1\r\n",
      "impatient  \t1\r\n",
      "impatiently  \t5\r\n",
      "impertinent  \t1\r\n",
      "implied  \t2\r\n",
      "important  \t8\r\n",
      "imposed  \t1\r\n",
      "impossible  \t3\r\n",
      "improve  \t1\r\n",
      "in  \t431\r\n",
      "inaccurate  \t1\r\n",
      "incessantly  \t1\r\n",
      "inches  \t6\r\n",
      "incidental  \t1\r\n",
      "inclined  \t1\r\n",
      "include  \t1\r\n",
      "included  \t3\r\n",
      "includes  \t1\r\n",
      "including  \t8\r\n",
      "incomplete  \t1\r\n",
      "increasing  \t1\r\n",
      "indeed  \t16\r\n",
      "indemnify  \t1\r\n",
      "indemnity  \t1\r\n",
      "indicate  \t1\r\n",
      "indicating  \t1\r\n",
      "indignant  \t1\r\n",
      "indignantly  \t4\r\n",
      "indirect  \t1\r\n",
      "indirectly  \t1\r\n",
      "individual  \t4\r\n",
      "information  \t8\r\n",
      "infringement  \t1\r\n",
      "injure  \t1\r\n",
      "ink  \t1\r\n",
      "inkstand  \t1\r\n",
      "inquired  \t1\r\n",
      "inquisitively  \t1\r\n",
      "inside  \t2\r\n",
      "insolence  \t1\r\n",
      "instance  \t3\r\n",
      "instantly  \t5\r\n",
      "instead  \t3\r\n",
      "insult  \t1\r\n",
      "intellectual  \t2\r\n",
      "interest  \t1\r\n",
      "interesting  \t5\r\n",
      "internal  \t1\r\n",
      "international  \t1\r\n",
      "interpreted  \t1\r\n",
      "interrupt  \t1\r\n",
      "interrupted  \t9\r\n",
      "interrupting  \t2\r\n",
      "into  \t67\r\n",
      "introduce  \t2\r\n",
      "introduced  \t1\r\n",
      "invalidity  \t1\r\n",
      "invent  \t1\r\n",
      "invented  \t1\r\n",
      "invitation  \t2\r\n",
      "invited  \t2\r\n",
      "involved  \t1\r\n",
      "inwards  \t1\r\n",
      "irons  \t1\r\n",
      "irritated  \t1\r\n",
      "irs  \t1\r\n",
      "is  \t135\r\n",
      "isn  \t7\r\n",
      "it  \t610\r\n",
      "its  \t63\r\n",
      "itself  \t14\r\n",
      "iv  \t1\r\n",
      "ix  \t1\r\n",
      "jack  \t1\r\n",
      "jar  \t2\r\n",
      "jaw  \t1\r\n",
      "jaws  \t2\r\n",
      "jelly  \t1\r\n",
      "jogged  \t1\r\n",
      "join  \t9\r\n",
      "joined  \t3\r\n",
      "journey  \t1\r\n",
      "joys  \t1\r\n",
      "judge  \t4\r\n",
      "judging  \t1\r\n",
      "jug  \t1\r\n",
      "jumped  \t6\r\n",
      "jumping  \t4\r\n",
      "june  \t1\r\n",
      "juror  \t1\r\n",
      "jurors  \t4\r\n",
      "jury  \t22\r\n",
      "jurymen  \t4\r\n",
      "just  \t52\r\n",
      "justice  \t1\r\n",
      "keep  \t13\r\n",
      "keeping  \t4\r\n",
      "kept  \t13\r\n",
      "kettle  \t1\r\n",
      "key  \t9\r\n",
      "kick  \t3\r\n",
      "kid  \t5\r\n",
      "kill  \t1\r\n",
      "killing  \t1\r\n",
      "kills  \t1\r\n",
      "kind  \t8\r\n",
      "kindly  \t2\r\n",
      "king  \t63\r\n",
      "kings  \t1\r\n",
      "kiss  \t1\r\n",
      "kissed  \t1\r\n",
      "kitchen  \t4\r\n",
      "knave  \t9\r\n",
      "knee  \t5\r\n",
      "kneel  \t1\r\n",
      "knelt  \t1\r\n",
      "knew  \t15\r\n",
      "knife  \t3\r\n",
      "knock  \t1\r\n",
      "knocked  \t1\r\n",
      "knocking  \t3\r\n",
      "knot  \t2\r\n",
      "know  \t88\r\n",
      "knowing  \t2\r\n",
      "knowledge  \t3\r\n",
      "known  \t1\r\n",
      "knows  \t2\r\n",
      "knuckles  \t1\r\n",
      "label  \t2\r\n",
      "labelled  \t1\r\n",
      "lacie  \t1\r\n",
      "lad  \t1\r\n",
      "ladder  \t1\r\n",
      "lady  \t3\r\n",
      "laid  \t2\r\n",
      "lake  \t1\r\n",
      "lamps  \t1\r\n",
      "land  \t1\r\n",
      "language  \t1\r\n",
      "languid  \t1\r\n",
      "lap  \t2\r\n",
      "large  \t33\r\n",
      "larger  \t7\r\n",
      "largest  \t1\r\n",
      "lark  \t1\r\n",
      "last  \t34\r\n",
      "lasted  \t2\r\n",
      "lastly  \t1\r\n",
      "late  \t6\r\n",
      "lately  \t1\r\n",
      "later  \t3\r\n",
      "latin  \t1\r\n",
      "latitude  \t2\r\n",
      "laugh  \t1\r\n",
      "laughed  \t2\r\n",
      "laughing  \t2\r\n",
      "laughter  \t1\r\n",
      "law  \t4\r\n",
      "laws  \t8\r\n",
      "lay  \t4\r\n",
      "lazily  \t1\r\n",
      "lazy  \t1\r\n",
      "leaders  \t1\r\n",
      "leading  \t1\r\n",
      "leaning  \t2\r\n",
      "leant  \t1\r\n",
      "leap  \t1\r\n",
      "learn  \t8\r\n",
      "learned  \t1\r\n",
      "learning  \t2\r\n",
      "learnt  \t2\r\n",
      "least  \t9\r\n",
      "leave  \t9\r\n",
      "leaves  \t6\r\n",
      "leaving  \t1\r\n",
      "led  \t4\r\n",
      "ledge  \t1\r\n",
      "left  \t14\r\n",
      "lefthand  \t2\r\n",
      "legal  \t2\r\n",
      "legally  \t1\r\n",
      "legged  \t2\r\n",
      "legs  \t3\r\n",
      "length  \t1\r\n",
      "less  \t4\r\n",
      "lessen  \t1\r\n",
      "lesson  \t3\r\n",
      "lessons  \t10\r\n",
      "lest  \t1\r\n",
      "let  \t22\r\n",
      "letter  \t4\r\n",
      "letters  \t1\r\n",
      "lewis  \t4\r\n",
      "liability  \t3\r\n",
      "liable  \t1\r\n",
      "library  \t1\r\n",
      "license  \t16\r\n",
      "licensed  \t1\r\n",
      "licking  \t1\r\n",
      "lie  \t2\r\n",
      "lieu  \t2\r\n",
      "life  \t13\r\n",
      "lifted  \t1\r\n",
      "like  \t85\r\n",
      "liked  \t6\r\n",
      "likely  \t5\r\n",
      "likes  \t1\r\n",
      "limbs  \t1\r\n",
      "limitation  \t3\r\n",
      "limited  \t5\r\n",
      "line  \t2\r\n",
      "lines  \t1\r\n",
      "linked  \t2\r\n",
      "links  \t3\r\n",
      "lips  \t1\r\n",
      "list  \t3\r\n",
      "listen  \t7\r\n",
      "listened  \t1\r\n",
      "listeners  \t1\r\n",
      "listening  \t3\r\n",
      "lit  \t1\r\n",
      "literary  \t13\r\n",
      "little  \t128\r\n",
      "live  \t8\r\n",
      "lived  \t3\r\n",
      "livery  \t3\r\n",
      "lives  \t4\r\n",
      "living  \t2\r\n",
      "lizard  \t6\r\n",
      "ll  \t57\r\n",
      "lobster  \t7\r\n",
      "lobsters  \t7\r\n",
      "located  \t4\r\n",
      "locations  \t2\r\n",
      "lock  \t1\r\n",
      "locked  \t1\r\n",
      "locks  \t2\r\n",
      "lodging  \t1\r\n",
      "london  \t1\r\n",
      "lonely  \t2\r\n",
      "long  \t33\r\n",
      "longed  \t2\r\n",
      "longer  \t3\r\n",
      "longitude  \t2\r\n",
      "look  \t29\r\n",
      "looked  \t45\r\n",
      "looking  \t32\r\n",
      "loose  \t2\r\n",
      "lory  \t7\r\n",
      "lose  \t1\r\n",
      "losing  \t1\r\n",
      "lost  \t3\r\n",
      "lot  \t1\r\n",
      "loud  \t6\r\n",
      "louder  \t1\r\n",
      "loudly  \t3\r\n",
      "love  \t3\r\n",
      "loveliest  \t1\r\n",
      "lovely  \t2\r\n",
      "loving  \t1\r\n",
      "low  \t15\r\n",
      "lower  \t1\r\n",
      "lowing  \t1\r\n",
      "luckily  \t2\r\n",
      "lullaby  \t1\r\n",
      "lying  \t8\r\n",
      "m  \t63\r\n",
      "ma  \t3\r\n",
      "mabel  \t4\r\n",
      "machine  \t1\r\n",
      "machines  \t1\r\n",
      "mad  \t15\r\n",
      "made  \t30\r\n",
      "magic  \t1\r\n",
      "magpie  \t1\r\n",
      "mail  \t1\r\n",
      "main  \t1\r\n",
      "maintaining  \t1\r\n",
      "majesty  \t12\r\n",
      "make  \t30\r\n",
      "makes  \t12\r\n",
      "making  \t8\r\n",
      "mallets  \t1\r\n",
      "man  \t5\r\n",
      "manage  \t7\r\n",
      "managed  \t4\r\n",
      "managing  \t1\r\n",
      "manner  \t2\r\n",
      "manners  \t1\r\n",
      "many  \t14\r\n",
      "maps  \t1\r\n",
      "march  \t35\r\n",
      "marched  \t1\r\n",
      "mark  \t3\r\n",
      "marked  \t8\r\n",
      "marmalade  \t1\r\n",
      "mary  \t4\r\n",
      "master  \t4\r\n",
      "matter  \t9\r\n",
      "matters  \t2\r\n",
      "maximum  \t1\r\n",
      "may  \t28\r\n",
      "maybe  \t2\r\n",
      "mayn  \t1\r\n",
      "me  \t68\r\n",
      "meal  \t1\r\n",
      "mean  \t10\r\n",
      "meaning  \t8\r\n",
      "means  \t8\r\n",
      "meant  \t5\r\n",
      "meanwhile  \t1\r\n",
      "measure  \t1\r\n",
      "meat  \t1\r\n",
      "medium  \t5\r\n",
      "meekly  \t2\r\n",
      "meet  \t3\r\n",
      "meeting  \t1\r\n",
      "melan  \t1\r\n",
      "melancholy  \t6\r\n",
      "memorandum  \t1\r\n",
      "memory  \t1\r\n",
      "men  \t1\r\n",
      "mentioned  \t3\r\n",
      "merchantibility  \t1\r\n",
      "mercia  \t2\r\n",
      "merely  \t2\r\n",
      "merrily  \t1\r\n",
      "messages  \t2\r\n",
      "met  \t4\r\n",
      "method  \t1\r\n",
      "methods  \t1\r\n",
      "mice  \t4\r\n",
      "michael  \t2\r\n",
      "middle  \t8\r\n",
      "might  \t28\r\n",
      "mile  \t2\r\n",
      "miles  \t3\r\n",
      "milk  \t2\r\n",
      "millennium  \t1\r\n",
      "mind  \t11\r\n",
      "minded  \t1\r\n",
      "minding  \t1\r\n",
      "mine  \t10\r\n",
      "mineral  \t1\r\n",
      "minute  \t21\r\n",
      "minutes  \t11\r\n",
      "mischief  \t1\r\n",
      "miserable  \t2\r\n",
      "miss  \t4\r\n",
      "missed  \t2\r\n",
      "mission  \t4\r\n",
      "mississippi  \t1\r\n",
      "mistake  \t3\r\n",
      "mixed  \t2\r\n",
      "mock  \t56\r\n",
      "moderate  \t1\r\n",
      "modern  \t1\r\n",
      "modification  \t1\r\n",
      "modified  \t1\r\n",
      "moment  \t31\r\n",
      "money  \t3\r\n",
      "month  \t2\r\n",
      "moon  \t1\r\n",
      "moral  \t8\r\n",
      "morals  \t1\r\n",
      "morcar  \t2\r\n",
      "more  \t50\r\n",
      "morning  \t5\r\n",
      "morsel  \t1\r\n",
      "most  \t11\r\n",
      "mostly  \t2\r\n",
      "mournful  \t1\r\n",
      "mournfully  \t1\r\n",
      "mouse  \t44\r\n",
      "mouth  \t10\r\n",
      "mouths  \t4\r\n",
      "move  \t3\r\n",
      "moved  \t5\r\n",
      "moving  \t3\r\n",
      "much  \t52\r\n",
      "muchness  \t3\r\n",
      "muddle  \t1\r\n",
      "multiplication  \t1\r\n",
      "murder  \t1\r\n",
      "murdering  \t1\r\n",
      "muscular  \t1\r\n",
      "mushroom  \t8\r\n",
      "music  \t3\r\n",
      "must  \t54\r\n",
      "mustard  \t3\r\n",
      "muttered  \t2\r\n",
      "muttering  \t3\r\n",
      "my  \t58\r\n",
      "myself  \t7\r\n",
      "mystery  \t2\r\n",
      "name  \t11\r\n",
      "named  \t1\r\n",
      "names  \t2\r\n",
      "narrow  \t2\r\n",
      "nasty  \t1\r\n",
      "natural  \t4\r\n",
      "natured  \t1\r\n",
      "naturedly  \t1\r\n",
      "nay  \t1\r\n",
      "near  \t15\r\n",
      "nearer  \t5\r\n",
      "nearly  \t13\r\n",
      "neat  \t1\r\n",
      "neatly  \t2\r\n",
      "necessarily  \t1\r\n",
      "neck  \t7\r\n",
      "need  \t1\r\n",
      "needn  \t3\r\n",
      "needs  \t1\r\n",
      "negligence  \t1\r\n",
      "neighbour  \t1\r\n",
      "neighbouring  \t1\r\n",
      "neither  \t2\r\n",
      "nervous  \t5\r\n",
      "nest  \t1\r\n",
      "network  \t1\r\n",
      "never  \t48\r\n",
      "nevertheless  \t1\r\n",
      "new  \t8\r\n",
      "newby  \t1\r\n",
      "newsletter  \t1\r\n",
      "newspapers  \t1\r\n",
      "next  \t30\r\n",
      "nibbled  \t2\r\n",
      "nibbling  \t3\r\n",
      "nice  \t6\r\n",
      "nicely  \t2\r\n",
      "night  \t5\r\n",
      "nile  \t1\r\n",
      "nine  \t5\r\n",
      "no  \t100\r\n",
      "nobody  \t8\r\n",
      "nodded  \t1\r\n",
      "noise  \t3\r\n",
      "noises  \t1\r\n",
      "non  \t1\r\n",
      "none  \t4\r\n",
      "nonproprietary  \t1\r\n",
      "nonsense  \t7\r\n",
      "nor  \t3\r\n",
      "normans  \t1\r\n",
      "north  \t1\r\n",
      "northumbria  \t2\r\n",
      "nose  \t8\r\n",
      "not  \t166\r\n",
      "note  \t2\r\n",
      "nothing  \t34\r\n",
      "notice  \t8\r\n",
      "noticed  \t8\r\n",
      "noticing  \t1\r\n",
      "notifies  \t1\r\n",
      "notion  \t3\r\n",
      "now  \t60\r\n",
      "nowhere  \t2\r\n",
      "number  \t8\r\n",
      "numerous  \t1\r\n",
      "nurse  \t3\r\n",
      "nursing  \t3\r\n",
      "o  \t6\r\n",
      "obliged  \t3\r\n",
      "oblong  \t1\r\n",
      "obsolete  \t1\r\n",
      "obstacle  \t1\r\n",
      "obtain  \t3\r\n",
      "obtaining  \t2\r\n",
      "occasional  \t1\r\n",
      "occasionally  \t1\r\n",
      "occur  \t1\r\n",
      "occurred  \t2\r\n",
      "october  \t1\r\n",
      "odd  \t1\r\n",
      "of  \t631\r\n",
      "off  \t73\r\n",
      "offend  \t1\r\n",
      "offended  \t10\r\n",
      "offer  \t2\r\n",
      "offers  \t1\r\n",
      "office  \t2\r\n",
      "officer  \t1\r\n",
      "officers  \t4\r\n",
      "official  \t3\r\n",
      "often  \t6\r\n",
      "oh  \t45\r\n",
      "ointment  \t1\r\n",
      "old  \t21\r\n",
      "older  \t2\r\n",
      "oldest  \t1\r\n",
      "on  \t204\r\n",
      "once  \t34\r\n",
      "one  \t106\r\n",
      "ones  \t1\r\n",
      "oneself  \t1\r\n",
      "onions  \t1\r\n",
      "online  \t4\r\n",
      "only  \t52\r\n",
      "oop  \t7\r\n",
      "ootiful  \t4\r\n",
      "open  \t7\r\n",
      "opened  \t10\r\n",
      "opening  \t3\r\n",
      "opinion  \t1\r\n",
      "opportunities  \t1\r\n",
      "opportunity  \t9\r\n",
      "opposite  \t1\r\n",
      "or  \t155\r\n",
      "orange  \t1\r\n",
      "order  \t3\r\n",
      "ordered  \t4\r\n",
      "ordering  \t2\r\n",
      "org  \t13\r\n",
      "organized  \t1\r\n",
      "original  \t1\r\n",
      "originator  \t1\r\n",
      "ornamented  \t2\r\n",
      "other  \t54\r\n",
      "others  \t8\r\n",
      "otherwise  \t4\r\n",
      "ou  \t1\r\n",
      "ought  \t14\r\n",
      "our  \t12\r\n",
      "ours  \t1\r\n",
      "ourselves  \t1\r\n",
      "out  \t118\r\n",
      "outdated  \t1\r\n",
      "outside  \t7\r\n",
      "over  \t40\r\n",
      "overcome  \t1\r\n",
      "overhead  \t1\r\n",
      "owed  \t1\r\n",
      "owl  \t3\r\n",
      "own  \t10\r\n",
      "owner  \t5\r\n",
      "owns  \t2\r\n",
      "oyster  \t1\r\n",
      "pace  \t1\r\n",
      "pack  \t5\r\n",
      "page  \t2\r\n",
      "pages  \t1\r\n",
      "paid  \t6\r\n",
      "paint  \t1\r\n",
      "painting  \t2\r\n",
      "pair  \t5\r\n",
      "pairs  \t1\r\n",
      "pale  \t4\r\n",
      "pan  \t1\r\n",
      "panted  \t1\r\n",
      "panther  \t3\r\n",
      "panting  \t2\r\n",
      "paper  \t5\r\n",
      "paperwork  \t1\r\n",
      "paragraph  \t11\r\n",
      "paragraphs  \t3\r\n",
      "parchment  \t2\r\n",
      "pardon  \t6\r\n",
      "pardoned  \t1\r\n",
      "paris  \t2\r\n",
      "part  \t6\r\n",
      "particular  \t6\r\n",
      "particularly  \t1\r\n",
      "partner  \t1\r\n",
      "partners  \t1\r\n",
      "parts  \t1\r\n",
      "party  \t11\r\n",
      "pass  \t1\r\n",
      "passage  \t4\r\n",
      "passed  \t5\r\n",
      "passing  \t1\r\n",
      "passion  \t3\r\n",
      "passionate  \t1\r\n",
      "past  \t3\r\n",
      "pat  \t3\r\n",
      "patience  \t1\r\n",
      "patiently  \t2\r\n",
      "patriotic  \t1\r\n",
      "patted  \t1\r\n",
      "pattering  \t3\r\n",
      "pattern  \t1\r\n",
      "pause  \t2\r\n",
      "paused  \t1\r\n",
      "paw  \t3\r\n",
      "paws  \t4\r\n",
      "pay  \t1\r\n",
      "paying  \t2\r\n",
      "payments  \t3\r\n",
      "pebbles  \t2\r\n",
      "peeped  \t3\r\n",
      "peeping  \t1\r\n",
      "peering  \t1\r\n",
      "pegs  \t1\r\n",
      "pence  \t1\r\n",
      "pencil  \t2\r\n",
      "pencils  \t1\r\n",
      "pennyworth  \t2\r\n",
      "people  \t16\r\n",
      "pepper  \t8\r\n",
      "perfectly  \t4\r\n",
      "perform  \t1\r\n",
      "performances  \t1\r\n",
      "performed  \t1\r\n",
      "performing  \t3\r\n",
      "perhaps  \t17\r\n",
      "periodic  \t1\r\n",
      "permanent  \t1\r\n",
      "permission  \t7\r\n",
      "permitted  \t3\r\n",
      "persisted  \t2\r\n",
      "person  \t8\r\n",
      "personal  \t2\r\n",
      "persons  \t1\r\n",
      "pet  \t1\r\n",
      "pg  \t1\r\n",
      "pglaf  \t8\r\n",
      "phrase  \t4\r\n",
      "physical  \t2\r\n",
      "picked  \t3\r\n",
      "picking  \t2\r\n",
      "picture  \t1\r\n",
      "pictured  \t1\r\n",
      "pictures  \t4\r\n",
      "pie  \t3\r\n",
      "piece  \t6\r\n",
      "pieces  \t3\r\n",
      "pig  \t11\r\n",
      "pigeon  \t12\r\n",
      "pigs  \t6\r\n",
      "pinch  \t2\r\n",
      "pinched  \t2\r\n",
      "pine  \t1\r\n",
      "pink  \t1\r\n",
      "piteous  \t1\r\n",
      "pitied  \t1\r\n",
      "pity  \t3\r\n",
      "place  \t9\r\n",
      "placed  \t1\r\n",
      "places  \t2\r\n",
      "plain  \t2\r\n",
      "plainly  \t1\r\n",
      "plan  \t4\r\n",
      "planning  \t1\r\n",
      "plate  \t3\r\n",
      "plates  \t2\r\n",
      "play  \t8\r\n",
      "played  \t1\r\n",
      "players  \t4\r\n",
      "playing  \t2\r\n",
      "pleaded  \t3\r\n",
      "pleasant  \t1\r\n",
      "pleasanter  \t1\r\n",
      "please  \t22\r\n",
      "pleased  \t7\r\n",
      "pleases  \t1\r\n",
      "pleasing  \t1\r\n",
      "pleasure  \t2\r\n",
      "plenty  \t2\r\n",
      "pocket  \t7\r\n",
      "pointed  \t1\r\n",
      "pointing  \t4\r\n",
      "poison  \t3\r\n",
      "poker  \t1\r\n",
      "poky  \t1\r\n",
      "politely  \t6\r\n",
      "pool  \t11\r\n",
      "poor  \t27\r\n",
      "pop  \t1\r\n",
      "pope  \t1\r\n",
      "porpoise  \t4\r\n",
      "position  \t2\r\n",
      "positively  \t1\r\n",
      "possessed  \t1\r\n",
      "possession  \t1\r\n",
      "possibility  \t1\r\n",
      "possible  \t1\r\n",
      "possibly  \t3\r\n",
      "posted  \t5\r\n",
      "posting  \t1\r\n",
      "pot  \t1\r\n",
      "pounds  \t1\r\n",
      "pour  \t1\r\n",
      "poured  \t1\r\n",
      "powdered  \t1\r\n",
      "practically  \t1\r\n",
      "practice  \t1\r\n",
      "pray  \t3\r\n",
      "precious  \t1\r\n",
      "prepare  \t2\r\n",
      "present  \t3\r\n",
      "presented  \t1\r\n",
      "presently  \t2\r\n",
      "presents  \t2\r\n",
      "preserve  \t1\r\n",
      "pressed  \t3\r\n",
      "pressing  \t1\r\n",
      "pretend  \t1\r\n",
      "pretending  \t1\r\n",
      "pretexts  \t1\r\n",
      "prettier  \t1\r\n",
      "pretty  \t1\r\n",
      "prevent  \t2\r\n",
      "previous  \t1\r\n",
      "principal  \t1\r\n",
      "print  \t1\r\n",
      "printed  \t3\r\n",
      "prison  \t1\r\n",
      "prisoner  \t2\r\n",
      "prize  \t1\r\n",
      "prizes  \t5\r\n",
      "problem  \t1\r\n",
      "proceed  \t2\r\n",
      "processing  \t1\r\n",
      "procession  \t5\r\n",
      "processions  \t1\r\n",
      "produce  \t1\r\n",
      "produced  \t2\r\n",
      "producing  \t1\r\n",
      "production  \t1\r\n",
      "professor  \t1\r\n",
      "profit  \t1\r\n",
      "profits  \t1\r\n",
      "prohibition  \t1\r\n",
      "project  \t87\r\n",
      "prominently  \t2\r\n",
      "promise  \t1\r\n",
      "promised  \t1\r\n",
      "promising  \t1\r\n",
      "promoting  \t2\r\n",
      "promotion  \t1\r\n",
      "pronounced  \t1\r\n",
      "proofread  \t1\r\n",
      "proper  \t3\r\n",
      "property  \t2\r\n",
      "proposal  \t1\r\n",
      "proprietary  \t1\r\n",
      "prosecute  \t1\r\n",
      "protect  \t2\r\n",
      "protection  \t1\r\n",
      "proud  \t2\r\n",
      "prove  \t1\r\n",
      "proved  \t2\r\n",
      "proves  \t2\r\n",
      "provide  \t7\r\n",
      "provided  \t4\r\n",
      "providing  \t4\r\n",
      "provision  \t1\r\n",
      "provisions  \t1\r\n",
      "provoking  \t1\r\n",
      "public  \t9\r\n",
      "puffed  \t1\r\n",
      "pulled  \t1\r\n",
      "pulling  \t1\r\n",
      "pun  \t1\r\n",
      "punching  \t1\r\n",
      "punished  \t1\r\n",
      "punitive  \t1\r\n",
      "puppy  \t7\r\n",
      "purple  \t1\r\n",
      "purpose  \t3\r\n",
      "purring  \t2\r\n",
      "push  \t1\r\n",
      "puss  \t1\r\n",
      "put  \t31\r\n",
      "putting  \t3\r\n",
      "puzzle  \t1\r\n",
      "puzzled  \t9\r\n",
      "puzzling  \t4\r\n",
      "quadrille  \t4\r\n",
      "quarrel  \t1\r\n",
      "quarrelled  \t1\r\n",
      "quarrelling  \t2\r\n",
      "queen  \t75\r\n",
      "queens  \t1\r\n",
      "queer  \t12\r\n",
      "queerest  \t1\r\n",
      "question  \t17\r\n",
      "questions  \t4\r\n",
      "quick  \t2\r\n",
      "quicker  \t1\r\n",
      "quickly  \t2\r\n",
      "quiet  \t2\r\n",
      "quietly  \t5\r\n",
      "quite  \t55\r\n",
      "quiver  \t1\r\n",
      "rabbit  \t51\r\n",
      "rabbits  \t1\r\n",
      "race  \t6\r\n",
      "railway  \t2\r\n",
      "raised  \t2\r\n",
      "raising  \t1\r\n",
      "ran  \t16\r\n",
      "rapidly  \t2\r\n",
      "rapped  \t1\r\n",
      "rat  \t1\r\n",
      "rate  \t9\r\n",
      "rather  \t25\r\n",
      "rats  \t1\r\n",
      "rattle  \t1\r\n",
      "rattling  \t2\r\n",
      "raven  \t1\r\n",
      "ravens  \t1\r\n",
      "raving  \t2\r\n",
      "raw  \t1\r\n",
      "re  \t40\r\n",
      "reach  \t4\r\n",
      "reaching  \t2\r\n",
      "read  \t14\r\n",
      "readable  \t2\r\n",
      "readily  \t1\r\n",
      "reading  \t4\r\n",
      "ready  \t8\r\n",
      "real  \t3\r\n",
      "reality  \t1\r\n",
      "really  \t13\r\n",
      "rearing  \t1\r\n",
      "reason  \t9\r\n",
      "reasonable  \t2\r\n",
      "reasons  \t1\r\n",
      "receipt  \t2\r\n",
      "receive  \t3\r\n",
      "received  \t6\r\n",
      "receiving  \t1\r\n",
      "recognised  \t1\r\n",
      "recovered  \t2\r\n",
      "red  \t3\r\n",
      "redistribute  \t1\r\n",
      "redistributing  \t2\r\n",
      "redistribution  \t2\r\n",
      "reduced  \t1\r\n",
      "reeds  \t1\r\n",
      "reeling  \t1\r\n",
      "references  \t2\r\n",
      "refreshments  \t1\r\n",
      "refund  \t10\r\n",
      "refused  \t1\r\n",
      "registered  \t2\r\n",
      "regular  \t2\r\n",
      "regulating  \t1\r\n",
      "release  \t1\r\n",
      "relief  \t2\r\n",
      "relieved  \t1\r\n",
      "remain  \t2\r\n",
      "remained  \t3\r\n",
      "remaining  \t2\r\n",
      "remark  \t10\r\n",
      "remarkable  \t2\r\n",
      "remarked  \t10\r\n",
      "remarking  \t3\r\n",
      "remarks  \t3\r\n",
      "remedies  \t2\r\n",
      "remember  \t14\r\n",
      "remembered  \t5\r\n",
      "remembering  \t1\r\n",
      "reminding  \t1\r\n",
      "remove  \t1\r\n",
      "removed  \t4\r\n",
      "renamed  \t1\r\n",
      "repeat  \t7\r\n",
      "repeated  \t10\r\n",
      "repeating  \t3\r\n",
      "replace  \t1\r\n",
      "replacement  \t5\r\n",
      "replied  \t29\r\n",
      "reply  \t5\r\n",
      "reported  \t1\r\n",
      "reports  \t1\r\n",
      "representations  \t1\r\n",
      "request  \t1\r\n",
      "require  \t1\r\n",
      "required  \t1\r\n",
      "requirements  \t4\r\n",
      "research  \t2\r\n",
      "resource  \t1\r\n",
      "respect  \t1\r\n",
      "respectable  \t1\r\n",
      "respectful  \t1\r\n",
      "rest  \t10\r\n",
      "resting  \t2\r\n",
      "restrictions  \t2\r\n",
      "result  \t1\r\n",
      "retire  \t1\r\n",
      "return  \t3\r\n",
      "returned  \t2\r\n",
      "returning  \t1\r\n",
      "returns  \t1\r\n",
      "revenue  \t1\r\n",
      "rich  \t1\r\n",
      "riddle  \t1\r\n",
      "riddles  \t2\r\n",
      "ridge  \t1\r\n",
      "ridges  \t1\r\n",
      "ridiculous  \t1\r\n",
      "right  \t36\r\n",
      "righthand  \t1\r\n",
      "rightly  \t1\r\n",
      "ring  \t2\r\n",
      "ringlets  \t2\r\n",
      "riper  \t1\r\n",
      "rippling  \t1\r\n",
      "rise  \t1\r\n",
      "rises  \t1\r\n",
      "rising  \t1\r\n",
      "roared  \t1\r\n",
      "roast  \t1\r\n",
      "rock  \t1\r\n",
      "rocket  \t1\r\n",
      "rome  \t2\r\n",
      "roof  \t6\r\n",
      "room  \t13\r\n",
      "roots  \t2\r\n",
      "rope  \t1\r\n",
      "rose  \t4\r\n",
      "roses  \t3\r\n",
      "rosetree  \t1\r\n",
      "roughly  \t1\r\n",
      "round  \t41\r\n",
      "row  \t2\r\n",
      "royal  \t2\r\n",
      "royalties  \t2\r\n",
      "royalty  \t3\r\n",
      "rubbed  \t1\r\n",
      "rubbing  \t2\r\n",
      "rude  \t2\r\n",
      "rudeness  \t1\r\n",
      "rule  \t5\r\n",
      "rules  \t5\r\n",
      "rumbling  \t1\r\n",
      "run  \t4\r\n",
      "running  \t8\r\n",
      "rush  \t2\r\n",
      "rushed  \t1\r\n",
      "rustled  \t1\r\n",
      "rustling  \t1\r\n",
      "s  \t219\r\n",
      "sad  \t3\r\n",
      "sadly  \t5\r\n",
      "safe  \t2\r\n",
      "sage  \t1\r\n",
      "said  \t462\r\n",
      "salmon  \t1\r\n",
      "salt  \t3\r\n",
      "same  \t25\r\n",
      "sand  \t1\r\n",
      "sands  \t1\r\n",
      "sang  \t2\r\n",
      "sat  \t17\r\n",
      "saucepan  \t1\r\n",
      "saucepans  \t1\r\n",
      "saucer  \t1\r\n",
      "savage  \t4\r\n",
      "save  \t1\r\n",
      "saves  \t1\r\n",
      "saw  \t14\r\n",
      "say  \t51\r\n",
      "saying  \t15\r\n",
      "says  \t4\r\n",
      "scale  \t1\r\n",
      "scaly  \t1\r\n",
      "scattered  \t1\r\n",
      "school  \t6\r\n",
      "schoolroom  \t1\r\n",
      "scolded  \t1\r\n",
      "scrambling  \t1\r\n",
      "scratching  \t1\r\n",
      "scream  \t2\r\n",
      "screamed  \t4\r\n",
      "screaming  \t1\r\n",
      "scroll  \t2\r\n",
      "sea  \t14\r\n",
      "seals  \t1\r\n",
      "seaography  \t1\r\n",
      "search  \t2\r\n",
      "seaside  \t1\r\n",
      "seated  \t1\r\n",
      "second  \t6\r\n",
      "secondly  \t2\r\n",
      "secret  \t1\r\n",
      "section  \t7\r\n",
      "sections  \t1\r\n",
      "secure  \t1\r\n",
      "see  \t70\r\n",
      "seeing  \t1\r\n",
      "seem  \t8\r\n",
      "seemed  \t27\r\n",
      "seems  \t5\r\n",
      "seen  \t15\r\n",
      "seldom  \t1\r\n",
      "sell  \t2\r\n",
      "send  \t2\r\n",
      "sending  \t3\r\n",
      "sends  \t1\r\n",
      "sensation  \t2\r\n",
      "sense  \t3\r\n",
      "sent  \t3\r\n",
      "sentence  \t8\r\n",
      "sentenced  \t1\r\n",
      "series  \t1\r\n",
      "seriously  \t1\r\n",
      "serpent  \t9\r\n",
      "serpents  \t3\r\n",
      "service  \t1\r\n",
      "set  \t23\r\n",
      "setting  \t1\r\n",
      "settle  \t1\r\n",
      "settled  \t3\r\n",
      "settling  \t1\r\n",
      "seven  \t6\r\n",
      "several  \t5\r\n",
      "severely  \t4\r\n",
      "severity  \t1\r\n",
      "sh  \t2\r\n",
      "shade  \t1\r\n",
      "shake  \t1\r\n",
      "shakespeare  \t1\r\n",
      "shaking  \t3\r\n",
      "shall  \t27\r\n",
      "shan  \t6\r\n",
      "shape  \t1\r\n",
      "shaped  \t3\r\n",
      "share  \t2\r\n",
      "shared  \t2\r\n",
      "sharing  \t2\r\n",
      "shark  \t1\r\n",
      "sharks  \t1\r\n",
      "sharp  \t6\r\n",
      "sharply  \t4\r\n",
      "she  \t553\r\n",
      "shedding  \t1\r\n",
      "sheep  \t1\r\n",
      "shelves  \t2\r\n",
      "shepherd  \t1\r\n",
      "shifting  \t1\r\n",
      "shilling  \t1\r\n",
      "shillings  \t1\r\n",
      "shingle  \t1\r\n",
      "shining  \t1\r\n",
      "shiny  \t1\r\n",
      "shiver  \t1\r\n",
      "shock  \t1\r\n",
      "shoes  \t7\r\n",
      "shook  \t9\r\n",
      "shore  \t4\r\n",
      "short  \t4\r\n",
      "shorter  \t2\r\n",
      "should  \t29\r\n",
      "shoulder  \t4\r\n",
      "shoulders  \t4\r\n",
      "shouldn  \t5\r\n",
      "shouted  \t9\r\n",
      "shouting  \t2\r\n",
      "show  \t3\r\n",
      "shower  \t2\r\n",
      "showing  \t2\r\n",
      "shriek  \t5\r\n",
      "shrieked  \t1\r\n",
      "shrieks  \t1\r\n",
      "shrill  \t5\r\n",
      "shrimp  \t1\r\n",
      "shrink  \t1\r\n",
      "shrinking  \t4\r\n",
      "shut  \t5\r\n",
      "shutting  \t2\r\n",
      "shy  \t1\r\n",
      "shyly  \t1\r\n",
      "side  \t17\r\n",
      "sides  \t4\r\n",
      "sigh  \t4\r\n",
      "sighed  \t5\r\n",
      "sighing  \t3\r\n",
      "sight  \t10\r\n",
      "sign  \t1\r\n",
      "signed  \t2\r\n",
      "signifies  \t1\r\n",
      "signify  \t1\r\n",
      "silence  \t14\r\n",
      "silent  \t7\r\n",
      "simple  \t5\r\n",
      "simpleton  \t1\r\n",
      "simply  \t3\r\n",
      "since  \t4\r\n",
      "sing  \t6\r\n",
      "singers  \t2\r\n",
      "singing  \t2\r\n",
      "sink  \t1\r\n",
      "sir  \t7\r\n",
      "sister  \t9\r\n",
      "sisters  \t2\r\n",
      "sit  \t8\r\n",
      "site  \t4\r\n",
      "sits  \t1\r\n",
      "sitting  \t10\r\n",
      "six  \t2\r\n",
      "sixpence  \t1\r\n",
      "sixteenth  \t1\r\n",
      "size  \t13\r\n",
      "sizes  \t1\r\n",
      "skimming  \t1\r\n",
      "skirt  \t1\r\n",
      "skurried  \t1\r\n",
      "sky  \t5\r\n",
      "slate  \t4\r\n",
      "slates  \t8\r\n",
      "sleep  \t6\r\n",
      "sleepy  \t5\r\n",
      "slightest  \t1\r\n",
      "slipped  \t3\r\n",
      "slippery  \t1\r\n",
      "slowly  \t8\r\n",
      "sluggard  \t1\r\n",
      "small  \t12\r\n",
      "smaller  \t3\r\n",
      "smallest  \t2\r\n",
      "smile  \t2\r\n",
      "smiled  \t2\r\n",
      "smiling  \t2\r\n",
      "smoke  \t1\r\n",
      "smoking  \t2\r\n",
      "snail  \t3\r\n",
      "snappishly  \t1\r\n",
      "snatch  \t2\r\n",
      "sneeze  \t2\r\n",
      "sneezed  \t1\r\n",
      "sneezes  \t2\r\n",
      "sneezing  \t6\r\n",
      "snorting  \t1\r\n",
      "snout  \t1\r\n",
      "so  \t152\r\n",
      "sob  \t1\r\n",
      "sobbed  \t1\r\n",
      "sobbing  \t3\r\n",
      "sobs  \t4\r\n",
      "soft  \t1\r\n",
      "softly  \t1\r\n",
      "soldier  \t1\r\n",
      "soldiers  \t10\r\n",
      "solemn  \t3\r\n",
      "solemnly  \t4\r\n",
      "soles  \t1\r\n",
      "solicit  \t2\r\n",
      "solicitation  \t1\r\n",
      "solid  \t1\r\n",
      "some  \t52\r\n",
      "somebody  \t7\r\n",
      "somehow  \t1\r\n",
      "someone  \t1\r\n",
      "somersault  \t2\r\n",
      "something  \t18\r\n",
      "sometimes  \t5\r\n",
      "somewhere  \t3\r\n",
      "son  \t1\r\n",
      "song  \t7\r\n",
      "soo  \t7\r\n",
      "soon  \t25\r\n",
      "sooner  \t2\r\n",
      "soothing  \t1\r\n",
      "sorrow  \t2\r\n",
      "sorrowful  \t2\r\n",
      "sorrows  \t1\r\n",
      "sorry  \t1\r\n",
      "sort  \t20\r\n",
      "sorts  \t3\r\n",
      "sound  \t4\r\n",
      "sounded  \t5\r\n",
      "sounds  \t4\r\n",
      "soup  \t18\r\n",
      "sour  \t1\r\n",
      "spades  \t1\r\n",
      "speak  \t15\r\n",
      "speaker  \t1\r\n",
      "speaking  \t5\r\n",
      "special  \t1\r\n",
      "specific  \t1\r\n",
      "specified  \t2\r\n",
      "spectacles  \t3\r\n",
      "speech  \t3\r\n",
      "speed  \t1\r\n",
      "spell  \t1\r\n",
      "spirited  \t1\r\n",
      "spite  \t1\r\n",
      "splash  \t1\r\n",
      "splashed  \t1\r\n",
      "splashing  \t2\r\n",
      "splendidly  \t1\r\n",
      "spoke  \t17\r\n",
      "spoken  \t1\r\n",
      "spoon  \t2\r\n",
      "spot  \t1\r\n",
      "sprawling  \t1\r\n",
      "spread  \t4\r\n",
      "spreading  \t1\r\n",
      "squeaked  \t1\r\n",
      "squeaking  \t2\r\n",
      "squeeze  \t1\r\n",
      "squeezed  \t1\r\n",
      "staff  \t1\r\n",
      "stairs  \t3\r\n",
      "stalk  \t1\r\n",
      "stamping  \t2\r\n",
      "stand  \t6\r\n",
      "standing  \t1\r\n",
      "star  \t1\r\n",
      "staring  \t3\r\n",
      "start  \t3\r\n",
      "started  \t2\r\n",
      "startled  \t2\r\n",
      "state  \t7\r\n",
      "statements  \t1\r\n",
      "states  \t14\r\n",
      "station  \t1\r\n",
      "status  \t4\r\n",
      "stay  \t5\r\n",
      "stays  \t1\r\n",
      "steady  \t1\r\n",
      "steam  \t1\r\n",
      "sternly  \t1\r\n",
      "stick  \t4\r\n",
      "sticks  \t1\r\n",
      "stiff  \t1\r\n",
      "stigand  \t1\r\n",
      "still  \t13\r\n",
      "stingy  \t1\r\n",
      "stirring  \t2\r\n",
      "stockings  \t1\r\n",
      "stole  \t2\r\n",
      "stolen  \t1\r\n",
      "stood  \t7\r\n",
      "stool  \t1\r\n",
      "stoop  \t2\r\n",
      "stop  \t6\r\n",
      "stopped  \t3\r\n",
      "stopping  \t1\r\n",
      "stored  \t1\r\n",
      "story  \t8\r\n",
      "straight  \t2\r\n",
      "straightened  \t1\r\n",
      "straightening  \t1\r\n",
      "strange  \t5\r\n",
      "strength  \t1\r\n",
      "stretched  \t2\r\n",
      "stretching  \t2\r\n",
      "strict  \t1\r\n",
      "strings  \t1\r\n",
      "struck  \t2\r\n",
      "stuff  \t4\r\n",
      "stupid  \t6\r\n",
      "stupidest  \t1\r\n",
      "stupidly  \t1\r\n",
      "subdued  \t1\r\n",
      "subject  \t7\r\n",
      "subjects  \t1\r\n",
      "submitted  \t1\r\n",
      "subscribe  \t1\r\n",
      "succeeded  \t3\r\n",
      "such  \t47\r\n",
      "sudden  \t5\r\n",
      "suddenly  \t13\r\n",
      "suet  \t1\r\n",
      "sugar  \t2\r\n",
      "suit  \t3\r\n",
      "sulkily  \t2\r\n",
      "sulky  \t3\r\n",
      "summer  \t2\r\n",
      "sun  \t2\r\n",
      "supple  \t1\r\n",
      "support  \t4\r\n",
      "suppose  \t14\r\n",
      "suppress  \t1\r\n",
      "suppressed  \t4\r\n",
      "sure  \t24\r\n",
      "surprise  \t5\r\n",
      "surprised  \t7\r\n",
      "survive  \t1\r\n",
      "swallow  \t1\r\n",
      "swallowed  \t1\r\n",
      "swallowing  \t1\r\n",
      "swam  \t5\r\n",
      "swamp  \t1\r\n",
      "sweet  \t1\r\n",
      "swim  \t5\r\n",
      "swimming  \t2\r\n",
      "synonymous  \t1\r\n",
      "t  \t218\r\n",
      "table  \t18\r\n",
      "tail  \t9\r\n",
      "tails  \t3\r\n",
      "take  \t22\r\n",
      "taken  \t4\r\n",
      "takes  \t3\r\n",
      "taking  \t5\r\n",
      "tale  \t4\r\n",
      "tales  \t1\r\n",
      "talk  \t14\r\n",
      "talking  \t17\r\n",
      "taller  \t2\r\n",
      "tart  \t1\r\n",
      "tarts  \t7\r\n",
      "taste  \t2\r\n",
      "tasted  \t3\r\n",
      "tastes  \t1\r\n",
      "taught  \t4\r\n",
      "tax  \t6\r\n",
      "taxes  \t1\r\n",
      "tea  \t19\r\n",
      "teaching  \t1\r\n",
      "teacup  \t3\r\n",
      "teacups  \t2\r\n",
      "teapot  \t1\r\n",
      "tears  \t11\r\n",
      "teases  \t1\r\n",
      "teeth  \t1\r\n",
      "telescope  \t3\r\n",
      "telescopes  \t1\r\n",
      "tell  \t32\r\n",
      "telling  \t2\r\n",
      "tells  \t2\r\n",
      "temper  \t5\r\n",
      "tempered  \t2\r\n",
      "ten  \t6\r\n",
      "terms  \t22\r\n",
      "terribly  \t1\r\n",
      "terrier  \t1\r\n",
      "terror  \t1\r\n",
      "than  \t26\r\n",
      "thank  \t4\r\n",
      "thanked  \t1\r\n",
      "that  \t330\r\n",
      "thatched  \t1\r\n",
      "the  \t1818\r\n",
      "their  \t52\r\n",
      "theirs  \t1\r\n",
      "them  \t88\r\n",
      "themselves  \t3\r\n",
      "then  \t94\r\n",
      "there  \t101\r\n",
      "therefore  \t1\r\n",
      "these  \t17\r\n",
      "they  \t155\r\n",
      "thick  \t1\r\n",
      "thimble  \t4\r\n",
      "thin  \t1\r\n",
      "thing  \t49\r\n",
      "things  \t33\r\n",
      "think  \t53\r\n",
      "thinking  \t11\r\n",
      "thirteen  \t1\r\n",
      "thirty  \t1\r\n",
      "this  \t181\r\n",
      "thistle  \t2\r\n",
      "thoroughly  \t2\r\n",
      "those  \t11\r\n",
      "though  \t11\r\n",
      "thought  \t74\r\n",
      "thoughtfully  \t4\r\n",
      "thoughts  \t2\r\n",
      "thousand  \t2\r\n",
      "three  \t28\r\n",
      "threw  \t2\r\n",
      "throat  \t2\r\n",
      "throne  \t1\r\n",
      "through  \t16\r\n",
      "throughout  \t1\r\n",
      "throw  \t3\r\n",
      "throwing  \t2\r\n",
      "thrown  \t1\r\n",
      "thump  \t2\r\n",
      "thunder  \t1\r\n",
      "thunderstorm  \t1\r\n",
      "thus  \t1\r\n",
      "tide  \t1\r\n",
      "tidy  \t1\r\n",
      "tie  \t1\r\n",
      "tied  \t1\r\n",
      "tight  \t1\r\n",
      "till  \t21\r\n",
      "tillie  \t1\r\n",
      "time  \t71\r\n",
      "times  \t6\r\n",
      "timid  \t3\r\n",
      "timidly  \t9\r\n",
      "tinkling  \t1\r\n",
      "tiny  \t4\r\n",
      "tipped  \t1\r\n",
      "tiptoe  \t2\r\n",
      "tired  \t7\r\n",
      "tis  \t5\r\n",
      "title  \t1\r\n",
      "tittered  \t1\r\n",
      "tm  \t57\r\n",
      "to  \t809\r\n",
      "toast  \t1\r\n",
      "today  \t1\r\n",
      "toes  \t3\r\n",
      "toffee  \t1\r\n",
      "together  \t9\r\n",
      "told  \t6\r\n",
      "tomorrow  \t1\r\n",
      "tone  \t40\r\n",
      "tones  \t2\r\n",
      "tongue  \t4\r\n",
      "too  \t26\r\n",
      "took  \t24\r\n",
      "top  \t8\r\n",
      "tops  \t1\r\n",
      "tortoise  \t3\r\n",
      "toss  \t1\r\n",
      "tossing  \t3\r\n",
      "touch  \t1\r\n",
      "tougher  \t1\r\n",
      "towards  \t1\r\n",
      "toys  \t1\r\n",
      "trademark  \t11\r\n",
      "trampled  \t1\r\n",
      "transcribe  \t1\r\n",
      "transcription  \t1\r\n",
      "traps  \t1\r\n",
      "tray  \t1\r\n",
      "treacle  \t7\r\n",
      "treading  \t2\r\n",
      "treat  \t1\r\n",
      "treated  \t1\r\n",
      "treatment  \t1\r\n",
      "tree  \t8\r\n",
      "trees  \t7\r\n",
      "tremble  \t1\r\n",
      "trembled  \t2\r\n",
      "trembling  \t6\r\n",
      "tremulous  \t1\r\n",
      "trial  \t10\r\n",
      "trials  \t1\r\n",
      "trickling  \t1\r\n",
      "tricks  \t1\r\n",
      "tried  \t19\r\n",
      "trims  \t1\r\n",
      "triumphantly  \t2\r\n",
      "trot  \t1\r\n",
      "trotting  \t2\r\n",
      "trouble  \t6\r\n",
      "true  \t4\r\n",
      "trumpet  \t3\r\n",
      "trusts  \t1\r\n",
      "truth  \t1\r\n",
      "truthful  \t1\r\n",
      "try  \t12\r\n",
      "trying  \t14\r\n",
      "tucked  \t3\r\n",
      "tulip  \t1\r\n",
      "tumbled  \t1\r\n",
      "tumbling  \t2\r\n",
      "tunnel  \t1\r\n",
      "tureen  \t1\r\n",
      "turkey  \t1\r\n",
      "turn  \t11\r\n",
      "turned  \t16\r\n",
      "turning  \t12\r\n",
      "turns  \t3\r\n",
      "turtle  \t59\r\n",
      "turtles  \t2\r\n",
      "tut  \t2\r\n",
      "twelfth  \t1\r\n",
      "twelve  \t4\r\n",
      "twentieth  \t1\r\n",
      "twenty  \t3\r\n",
      "twice  \t5\r\n",
      "twinkle  \t8\r\n",
      "twinkled  \t1\r\n",
      "twinkling  \t4\r\n",
      "twist  \t2\r\n",
      "two  \t40\r\n",
      "txt  \t1\r\n",
      "types  \t1\r\n",
      "u  \t3\r\n",
      "ugh  \t2\r\n",
      "uglification  \t2\r\n",
      "uglify  \t1\r\n",
      "uglifying  \t1\r\n",
      "ugly  \t2\r\n",
      "unable  \t1\r\n",
      "uncivil  \t1\r\n",
      "uncomfortable  \t4\r\n",
      "uncomfortably  \t1\r\n",
      "uncommon  \t1\r\n",
      "uncommonly  \t1\r\n",
      "uncorked  \t1\r\n",
      "under  \t22\r\n",
      "underneath  \t1\r\n",
      "understand  \t7\r\n",
      "understood  \t1\r\n",
      "undertone  \t2\r\n",
      "undo  \t1\r\n",
      "undoing  \t1\r\n",
      "uneasily  \t2\r\n",
      "uneasy  \t1\r\n",
      "unenforceability  \t1\r\n",
      "unfolded  \t2\r\n",
      "unfortunate  \t3\r\n",
      "unhappy  \t2\r\n",
      "uniform  \t1\r\n",
      "unimportant  \t5\r\n",
      "united  \t10\r\n",
      "unjust  \t1\r\n",
      "unless  \t6\r\n",
      "unlink  \t1\r\n",
      "unlocking  \t1\r\n",
      "unpleasant  \t2\r\n",
      "unrolled  \t2\r\n",
      "unsolicited  \t1\r\n",
      "until  \t5\r\n",
      "untwist  \t1\r\n",
      "unusually  \t1\r\n",
      "unwillingly  \t1\r\n",
      "up  \t103\r\n",
      "updated  \t2\r\n",
      "upon  \t28\r\n",
      "upright  \t1\r\n",
      "upset  \t3\r\n",
      "upsetting  \t1\r\n",
      "upstairs  \t1\r\n",
      "us  \t15\r\n",
      "use  \t31\r\n",
      "used  \t16\r\n",
      "useful  \t2\r\n",
      "user  \t3\r\n",
      "using  \t6\r\n",
      "usual  \t5\r\n",
      "usually  \t2\r\n",
      "usurpation  \t1\r\n",
      "ut  \t1\r\n",
      "utf  \t1\r\n",
      "v  \t1\r\n",
      "vague  \t1\r\n",
      "vanilla  \t2\r\n",
      "vanished  \t4\r\n",
      "vanishing  \t1\r\n",
      "variations  \t1\r\n",
      "variety  \t1\r\n",
      "various  \t2\r\n",
      "ve  \t44\r\n",
      "vegetable  \t1\r\n",
      "velvet  \t1\r\n",
      "venture  \t3\r\n",
      "ventured  \t4\r\n",
      "verdict  \t4\r\n",
      "verse  \t4\r\n",
      "verses  \t4\r\n",
      "version  \t1\r\n",
      "very  \t145\r\n",
      "vi  \t1\r\n",
      "viewed  \t1\r\n",
      "viewing  \t1\r\n",
      "vii  \t1\r\n",
      "viii  \t1\r\n",
      "vinegar  \t1\r\n",
      "violates  \t1\r\n",
      "violence  \t1\r\n",
      "violent  \t2\r\n",
      "violently  \t4\r\n",
      "virus  \t1\r\n",
      "visit  \t3\r\n",
      "voice  \t48\r\n",
      "voices  \t3\r\n",
      "void  \t1\r\n",
      "volunteer  \t1\r\n",
      "volunteers  \t6\r\n",
      "vote  \t1\r\n",
      "vulgar  \t1\r\n",
      "w  \t1\r\n",
      "wag  \t1\r\n",
      "wags  \t1\r\n",
      "waist  \t1\r\n",
      "waistcoat  \t2\r\n",
      "wait  \t1\r\n",
      "waited  \t11\r\n",
      "waiting  \t9\r\n",
      "wake  \t2\r\n",
      "walk  \t5\r\n",
      "walked  \t10\r\n",
      "walking  \t5\r\n",
      "walks  \t1\r\n",
      "walrus  \t1\r\n",
      "wander  \t1\r\n",
      "wandered  \t2\r\n",
      "wandering  \t2\r\n",
      "want  \t9\r\n",
      "wanted  \t4\r\n",
      "wants  \t2\r\n",
      "warning  \t1\r\n",
      "warranties  \t3\r\n",
      "warranty  \t2\r\n",
      "was  \t358\r\n",
      "wash  \t2\r\n",
      "washing  \t3\r\n",
      "wasn  \t11\r\n",
      "waste  \t1\r\n",
      "wasting  \t2\r\n",
      "watch  \t8\r\n",
      "watched  \t2\r\n",
      "watching  \t3\r\n",
      "water  \t5\r\n",
      "waters  \t1\r\n",
      "waving  \t5\r\n",
      "way  \t58\r\n",
      "ways  \t2\r\n",
      "we  \t43\r\n",
      "weak  \t2\r\n",
      "wearily  \t1\r\n",
      "web  \t6\r\n",
      "week  \t3\r\n",
      "weeks  \t1\r\n",
      "welcome  \t1\r\n",
      "well  \t63\r\n",
      "went  \t83\r\n",
      "wept  \t1\r\n",
      "were  \t85\r\n",
      "weren  \t1\r\n",
      "west  \t1\r\n",
      "wet  \t2\r\n",
      "what  \t142\r\n",
      "whatever  \t3\r\n",
      "whatsoever  \t2\r\n",
      "when  \t80\r\n",
      "whenever  \t2\r\n",
      "where  \t18\r\n",
      "whereupon  \t1\r\n",
      "wherever  \t2\r\n",
      "whether  \t11\r\n",
      "which  \t56\r\n",
      "while  \t26\r\n",
      "whiles  \t1\r\n",
      "whiskers  \t3\r\n",
      "whisper  \t3\r\n",
      "whispered  \t5\r\n",
      "whispers  \t1\r\n",
      "whistle  \t1\r\n",
      "whistling  \t1\r\n",
      "white  \t30\r\n",
      "whiting  \t8\r\n",
      "who  \t66\r\n",
      "whoever  \t1\r\n",
      "whole  \t13\r\n",
      "whom  \t2\r\n",
      "whose  \t2\r\n",
      "why  \t40\r\n",
      "wide  \t3\r\n",
      "wider  \t1\r\n",
      "widest  \t2\r\n",
      "wife  \t1\r\n",
      "wig  \t2\r\n",
      "wild  \t2\r\n",
      "wildly  \t2\r\n",
      "will  \t40\r\n",
      "william  \t8\r\n",
      "win  \t1\r\n",
      "wind  \t2\r\n",
      "window  \t8\r\n",
      "wine  \t2\r\n",
      "wings  \t1\r\n",
      "wink  \t2\r\n",
      "winter  \t1\r\n",
      "wise  \t2\r\n",
      "wish  \t22\r\n",
      "with  \t228\r\n",
      "within  \t6\r\n",
      "without  \t34\r\n",
      "witness  \t10\r\n",
      "wits  \t1\r\n",
      "woke  \t1\r\n",
      "woman  \t2\r\n",
      "won  \t26\r\n",
      "wonder  \t18\r\n",
      "wondered  \t1\r\n",
      "wonderful  \t2\r\n",
      "wondering  \t7\r\n",
      "wonderland  \t8\r\n",
      "wood  \t8\r\n",
      "wooden  \t1\r\n",
      "word  \t11\r\n",
      "words  \t21\r\n",
      "wore  \t1\r\n",
      "work  \t53\r\n",
      "works  \t33\r\n",
      "world  \t7\r\n",
      "worm  \t1\r\n",
      "worried  \t1\r\n",
      "worry  \t1\r\n",
      "worse  \t3\r\n",
      "worth  \t4\r\n",
      "would  \t83\r\n",
      "wouldn  \t13\r\n",
      "wow  \t6\r\n",
      "wrapping  \t1\r\n",
      "wretched  \t2\r\n",
      "wriggling  \t1\r\n",
      "write  \t6\r\n",
      "writhing  \t1\r\n",
      "writing  \t9\r\n",
      "written  \t9\r\n",
      "wrong  \t5\r\n",
      "wrote  \t3\r\n",
      "www  \t6\r\n",
      "x  \t1\r\n",
      "xi  \t1\r\n",
      "xii  \t1\r\n",
      "yard  \t1\r\n",
      "yards  \t1\r\n",
      "yawned  \t2\r\n",
      "yawning  \t2\r\n",
      "ye  \t1\r\n",
      "year  \t2\r\n",
      "years  \t2\r\n",
      "yelled  \t1\r\n",
      "yelp  \t1\r\n",
      "yer  \t4\r\n",
      "yes  \t13\r\n",
      "yesterday  \t3\r\n",
      "yet  \t25\r\n",
      "you  \t481\r\n",
      "young  \t5\r\n",
      "your  \t71\r\n",
      "yours  \t3\r\n",
      "yourself  \t10\r\n",
      "youth  \t6\r\n",
      "zealand  \t1\r\n",
      "zigzag  \t1\r\n",
      "zip  \t1\r\n"
     ]
    }
   ],
   "source": [
    "!./pWordCount.sh 4 '*' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4 (OPTIONAL) - Count words staring with uppercase and words starting with lowercase\n",
    "\n",
    "Change the mapper.py/reducer.py combination so that you get only the number of words starting with an uppercase letter, and the number of words starting with a lowercase letter for Alice in Wonderland available [here](http://www.gutenberg.org/cache/epub/11/pg11.txt). In other words, you need an output file with only 2 lines, one giving you the number of words staring with a lowercase ('a' to 'z'), and the other line indicating the number of words starting with an uppercase letter ('A' to 'Z'). In the pWordCount.sh, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE HW1.4\n",
    "\n",
    "# END STUDENT CODE HW1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.5 (OPTIONAL) - Bias-Variance \n",
    "\n",
    "Provide an example of bias variance in action for a similated function y = f(x). E.g., y = sin(x+x^2). Provide code, data, and graphs. \n",
    "\n",
    "Using a bias-variance decomposition analsysis on your choosen problem, describe how you would decide which model to choose when you dont know the true function and how does this choice compare to the choice you made using the true function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE HW1.5\n",
    "\n",
    "# END STUDENT CODE HW1.5"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "297px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "951px",
    "left": "0px",
    "right": "1561px",
    "top": "106px",
    "width": "600px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
