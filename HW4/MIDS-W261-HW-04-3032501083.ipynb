{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#MIDS---w261-Machine-Learning-At-Scale\" data-toc-modified-id=\"MIDS---w261-Machine-Learning-At-Scale-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MIDS - w261 Machine Learning At Scale</a></div><div class=\"lev2 toc-item\"><a href=\"#Assignment---HW4\" data-toc-modified-id=\"Assignment---HW4-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Assignment - HW4</a></div><div class=\"lev3 toc-item\"><a href=\"#INSTRUCTIONS-for-SUBMISSION\" data-toc-modified-id=\"INSTRUCTIONS-for-SUBMISSION-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>INSTRUCTIONS for SUBMISSION</a></div><div class=\"lev3 toc-item\"><a href=\"#CONFIGURATION\" data-toc-modified-id=\"CONFIGURATION-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>CONFIGURATION</a></div><div class=\"lev3 toc-item\"><a href=\"#DATASETS\" data-toc-modified-id=\"DATASETS-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>DATASETS</a></div><div class=\"lev1 toc-item\"><a href=\"#HW-Problems\" data-toc-modified-id=\"HW-Problems-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>HW Problems</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.0\" data-toc-modified-id=\"HW4.0-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>HW4.0</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.1\" data-toc-modified-id=\"HW4.1-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>HW4.1</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.2----Preprocess-log-file-data\" data-toc-modified-id=\"HW4.2----Preprocess-log-file-data-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>HW4.2  - Preprocess log file data</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.3---Find-the-most-frequent-pages\" data-toc-modified-id=\"HW4.3---Find-the-most-frequent-pages-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>HW4.3 - Find the most frequent pages</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.4----Find-the-most-frequent-visitor\" data-toc-modified-id=\"HW4.4----Find-the-most-frequent-visitor-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>HW4.4  - Find the most frequent visitor</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.5---Clustering-Tweet-Dataset\" data-toc-modified-id=\"HW4.5---Clustering-Tweet-Dataset-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>HW4.5 - Clustering Tweet Dataset</a></div><div class=\"lev2 toc-item\"><a href=\"#K-Means\" data-toc-modified-id=\"K-Means-27\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>K-Means</a></div><div class=\"lev2 toc-item\"><a href=\"#K-means-algorithm\" data-toc-modified-id=\"K-means-algorithm-28\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>K-means algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Calculating-purity\" data-toc-modified-id=\"Calculating-purity-29\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Calculating purity</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.6----(OPTIONAL)-Scaleable-K-MEANS++\" data-toc-modified-id=\"HW4.6----(OPTIONAL)-Scaleable-K-MEANS++-210\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>HW4.6  - (OPTIONAL) Scaleable K-MEANS++</a></div><div class=\"lev3 toc-item\"><a href=\"#4.6.1-(OPTIONAL)-Apply-K-MEANS||\" data-toc-modified-id=\"4.6.1-(OPTIONAL)-Apply-K-MEANS||-2101\"><span class=\"toc-item-num\">2.10.1&nbsp;&nbsp;</span>4.6.1 (OPTIONAL) Apply K-MEANS||</a></div><div class=\"lev2 toc-item\"><a href=\"#HW4.7---(OPTIONAL)-Canopy-Clustering\" data-toc-modified-id=\"HW4.7---(OPTIONAL)-Canopy-Clustering-211\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>HW4.7 - (OPTIONAL) Canopy Clustering</a></div><div class=\"lev3 toc-item\"><a href=\"#4.7.1-(OPTIONAL)-Apply-Canopy-Clustering-based-K-MEANS\" data-toc-modified-id=\"4.7.1-(OPTIONAL)-Apply-Canopy-Clustering-based-K-MEANS-2111\"><span class=\"toc-item-num\">2.11.1&nbsp;&nbsp;</span>4.7.1 (OPTIONAL) Apply Canopy Clustering based K-MEANS</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale \n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW4\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Victoria Baker\n",
    "__Class:__ MIDS w261 (Section 2)     \n",
    "__Email:__  victoria.baker@iSchool.Berkeley.edu     \n",
    "__StudentId__  3032501083    __End of StudentId__     \n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "\n",
    "### INSTRUCTIONS for SUBMISSION\n",
    "\n",
    "This homework can be completed locally on your computer. __Please submit your notebook to your classroom github repository 24 hours prior to the next live session.__ \n",
    "\n",
    "### CONFIGURATION\n",
    "Before starting your homework run the following cells to confirm your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mrjobstep\n",
      "\u001b[31m  Could not find a version that satisfies the requirement mrjobstep (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for mrjobstep\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 2.7.13 \n",
      "HDFS filesystem running at: \n",
      "\t hdfs://quickstart.cloudera:8020\n"
     ]
    }
   ],
   "source": [
    "# print some configuration details for future replicability.\n",
    "print 'Python Version: %s' % (sys.version.split('|')[0])\n",
    "hdfs_conf = !hdfs getconf -confKey fs.defaultFS ### UNCOMMENT ON DOCKER\n",
    "#hdfs_conf = !hdfs getconf -confKey fs.default.name ### UNCOMMENT ON ALTISCALE\n",
    "print 'HDFS filesystem running at: \\n\\t %s' % (hdfs_conf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an HDFS directory for this assignment\n",
    "!hdfs dfs -mkdir hw4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[OPTIONAL]:__ Save yourself some typing by defining global variables for paths we'll reuse frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HDFS_DIR = \"\" # eg. /user/root/hw4 \n",
    "HOME_DIR = os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[OPTIONAL]:__ Fix chrome formatting. _The cell below implements a quick hack based on [this stackoverflow thread](http://stackoverflow.com/questions/34277967/chrome-rendering-mathjax-equations-with-a-trailing-vertical-line) to fix [this known issue](https://github.com/mathjax/MathJax/issues/1300) with Mathjax formatting in Chrome (a rounding issue adds a border to the right of mathjax markup)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.math>span').css(\"border-left-color\",\"transparent\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.math>span').css(\"border-left-color\",\"transparent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASETS\n",
    "For this homework we be using two different datasets:\n",
    "* __Microsoft log files data__ (available from the [UC Irvine KDD Archive](https://kdd.ics.uci.edu/databases/msweb/msweb.html) at [this url](http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/) - _This data, referenced in the asynch lectures, captures which areas (Vroots) of www.microsoft.com each user visited in a one-week timeframe in Feburary 1998. We'll perform preprocessing on the data in HW 4.2 and find the most frequently visited pages and visitors in HW 4.3 and 4.4_\n",
    "* __Tweets data__ (from [this publication](https://arxiv.org/abs/1505.04342) in the Journal of Computation Science and available at [this url] - _This data, comes from a corpus of Tweets that were hand coded to reflect whether the tweet was written by a human,cyborg,robot or spammer. The data are in two files: the primary [topUsers file](https://www.dropbox.com/s/6129k2urvbvobkr/topUsers_Apr-Jul_2014_1000-words.txt?dl=0), and an auxilary [word summaries](https://www.dropbox.com/s/w4oklbsoqefou3b/topUsers_Apr-Jul_2014_1000-words_summaries.txt?dl=0) file (more details below). We'll perform a KMeans clustering analysis on this data in HW 4.5._\n",
    "\n",
    "Follow the directions below to load each of these datasets. You may want to familiarize yourself with their contents before proceeding to the homework questions.\n",
    "\n",
    "__`anonymous-msweb.data`__  \n",
    "Notes on the data format:\n",
    "> The data is in an ASCII-based sparse-data format called \"DST\". Each line of the data file starts with a letter which tells the line's type. The three line types of interest are:\n",
    "\n",
    ">__Attribute lines__:\n",
    "e.g. `A,1277,1,\"NetShow for PowerPoint\",\"/stream\"`\n",
    "Where:\n",
    "  'A' marks this as an attribute line, \n",
    "  '1277' is the attribute ID number for an area of the website (called a Vroot),\n",
    "  '1' may be ignored, \n",
    "  '\"NetShow for PowerPoint\"' is the title of the Vroot, \n",
    "  '\"/stream\"' is the URL relative to \"http://www.microsoft.com\"\n",
    "\n",
    ">__Case and Vote Lines__:\n",
    "For each user, there is a case line followed by zero or more vote lines.\n",
    "For example:\n",
    "  C,\"10164\",10164\n",
    "  V,1123,1\n",
    "  V,1009,1\n",
    "  V,1052,1\n",
    "Where:\n",
    "  'C' marks this as a case line, \n",
    "  '10164' is the case ID number of a user, \n",
    "  'V' marks the vote lines for this case, \n",
    "  '1123', 1009', 1052' are the attributes ID's of Vroots that a user visited. \n",
    "  '1' may be ignored.\n",
    "  \n",
    "Run the cells below to download and examine the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1389k  100 1389k    0     0   152k      0  0:00:09  0:00:09 --:--:--  239k\n"
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "!curl -L http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/anonymous-msweb.data -o anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,4,\"www.microsoft.com\",\"created by getlog.pl\"\r\n",
      "T,1,\"VRoot\",0,0,\"VRoot\"\r\n",
      "N,0,\"0\"\r\n",
      "N,1,\"1\"\r\n",
      "T,2,\"Hide1\",0,0,\"Hide\"\r\n",
      "N,0,\"0\"\r\n",
      "N,1,\"1\"\r\n",
      "A,1287,1,\"International AutoRoute\",\"/autoroute\"\r\n",
      "A,1288,1,\"library\",\"/library\"\r\n",
      "A,1289,1,\"Master Chef Product Information\",\"/masterchef\"\r\n"
     ]
    }
   ],
   "source": [
    "# take a look\n",
    "!head -n 10 anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`topUsers_Apr-Jul_2014_1000-words.txt`__  \n",
    "Notes about the data coding:  \n",
    "> This file consists of word frequency distributions for 1,000 twitter users. These Twitter users use language in very different ways,and were classified by hand according to the criteria:  \n",
    "\n",
    ">__0__: Human, _where only basic human-human communication is observed._  \n",
    "\n",
    ">__1__: Cyborg, _where language is primarily borrowed from other sources. (e.g., jobs listings, classifieds postings, advertisements, etc...)._  \n",
    "\n",
    "> __2__: Robot, _where language is formulaically derived from unrelated sources(e.g., weather/seismology, police/fire event logs, etc...)._  \n",
    "\n",
    ">__3__: Spammer, _where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc...)_\n",
    "\n",
    "Data format:\n",
    "> `USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...`  \n",
    "where   \n",
    "USERID = unique user identifier  \n",
    "CODE = 0/1/2/3 class code  \n",
    "TOTAL = sum of the word counts  \n",
    "\n",
    "Run the cells below to load and preview the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2493k  100 2493k    0     0   108k      0  0:00:22  0:00:22 --:--:--  196k\n"
     ]
    }
   ],
   "source": [
    "# download the main Twitter data\n",
    "!curl -L -O https://www.dropbox.com/s/6129k2urvbvobkr/topUsers_Apr-Jul_2014_1000-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180025371,2,1724608,75552,827,57603,7128,4282,45674,66811,27632,0,8,23783,2,42853,0,62335,22349,21428,19801,4125,0,0,2,1585,21118,1,1,1,16079,19676,1587,0,19695,0,0,0,0,0,0,2,20216,60,4278,0,16,46,788,2,0,0,3,0,3,0,0,111122,0,12,0,0,0,2,739,0,176,0,0,0,38,626,0,0,0,6,1584,0,19672,510,0,0,0,12,0,1675,0,0,0,0,5,2,0,0,1,9,0,0,31,0,0,2,0,0,0,0,4,64,476,0,1,0,617,0,0,15672,70315,70317,0,2997,0,0,0,665,0,0,12,0,0,0,3135,1,2,39,0,0,0,0,23,0,1,0,179,667,0,0,32,0,0,224,5,0,0,66,0,3,450,96,0,0,0,0,8,15,15,0,115,0,0,19672,0,46,15,0,0,2,0,51,0,0,0,298,0,0,5,2,165,3,0,0,46497,0,19675,0,4,0,42036,0,0,40035,84,0,103,0,2,12,1924,7,0,0,0,0,3,0,42629,197,15490,0,0,45,0,0,0,0,0,0,301,0,0,0,0,134,3300,0,422,386,0,19826,2,0,0,46,9,354,175,71,165,20338,0,109,0,1,44376,0,1370,0,0,0,0,0,0,0,0,0,0,2,0,0,4462,0,0,5,0,202,436,408,0,61,0,0,39888,74,0,19672,0,0,0,0,0,19672,19672,2,2,349,0,13,0,30,0,0,8,0,40,0,23,0,12,337,0,12,19952,26,0,0,15489,0,0,0,0,39,0,0,26,0,0,19,144,161,0,0,0,5558,0,23,1561,52,0,0,0,9,0,0,35319,0,0,68,0,0,0,0,0,0,0,8,0,0,222,463,60,0,77,0,20219,0,1,4581,0,0,0,297,0,0,0,0,0,68,0,17942,0,38,226,0,0,0,0,9,19,0,0,0,0,0,217,12,261,0,25052,263,0,0,0,1,0,59,27,14,133,76,234,24966,0,0,1,2,11,44,3,0,0,43,0,3,3,2,0,0,0,2,0,0,7,47,0,0,0,0,2,0,0,1,0,0,0,0,175,0,0,5,1,0,0,0,7,0,0,104,53,0,0,16,13,26,0,11,0,6,77,0,17,0,360,0,0,1693,0,147,0,10,0,0,0,61,1,0,0,113,0,0,1,0,305,14,23,0,42,0,0,0,1,14,2391,6,0,21,0,0,911,3,0,0,0,0,0,0,0,0,39,0,25088,0,0,0,34,134,59,35,45,1584,40,2,8,0,249,0,72,0,0,0,0,0,2,0,0,0,0,0,25,0,13,0,0,4223,30,0,0,0,0,0,0,184,1,5558,0,0,24,0,61,7,38,0,309,0,25,0,0,0,0,0,0,0,0,0,3,258,0,0,0,0,0,710,0,62,0,21,0,0,0,0,820,0,0,19672,0,1,0,0,8,74,0,0,0,87,15390,12,20216,1,0,2,10810,11,0,0,47,0,0,797,95,19826,143,0,2,772,0,0,0,117,90,0,56,1,0,0,86,382,807,0,0,0,77,0,97,0,169,282,0,0,0,0,0,0,14,1,0,0,0,0,202,825,1,10,0,803,98,0,167,113,0,263,18506,0,18521,0,243,4,88,0,46,0,0,0,0,15,0,718,1,0,0,0,0,261,0,0,0,454,3028,0,0,0,48,0,0,0,48,0,112,0,0,140,0,1,0,0,0,0,0,2701,0,0,13,0,0,178,741,0,0,1,0,0,0,0,0,352,5,0,0,42,0,0,94,0,0,0,9,0,0,0,0,2,15489,0,11,225,0,5,0,811,0,5,0,43,0,16,277,26,0,11,0,0,0,0,0,0,0,0,0,0,0,0,15489,0,0,0,0,0,0,0,0,0,0,0,95,61,9,0,70,0,28,0,0,135,0,0,0,31,12,0,0,0,0,1,0,0,1,202,0,0,0,39,0,0,125,0,0,48,0,0,24,0,13,272,48,22,0,74,0,0,0,23,0,5,0,2,21,0,0,0,69,12512,0,0,38,0,0,16,0,0,0,0,0,7,2,1,0,17,1,0,0,0,0,18,14,0,0,0,90,0,0,0,128,45,0,1,0,0,0,2,8,0,30,11,15,28,0,0,0,0,0,0,0,0,0,113,0,0,0,50,0,0,0,5,0,118,0,6,85,56,15,12,0,0,0,176,10,57,12,289,0,27,0,0,0,0,0,23,89,0,221,0,16,0,0,0,0,0,14,33,126,11,32,1,137,13,0,0,0,0,0,0,0,0,0,1,0,98,0,0,0,45,0,215,0,0,0,0,71,76,0,0,0,15,108,0,0,176,0,0,0,0,121,0,0,0,0\r\n"
     ]
    }
   ],
   "source": [
    "# take a look at the first row\n",
    "!head -n 1 topUsers_Apr-Jul_2014_1000-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`topUsers_Apr-Jul_2014_1000-words_summaries.txt`__\n",
    "This file contains 5 special word-frequency distributions.\n",
    "Notes about the format of this auxillary information:  \n",
    "> Row 1: Words  \n",
    "Row 2: 1000-user-wide aggregated distribution across all classes  \n",
    "Row 3-6 class-aggregated distributions for clases 0-3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 31952  100 31952    0     0   8130      0  0:00:03  0:00:03 --:--:-- 45450\n"
     ]
    }
   ],
   "source": [
    "# download auxillary file\n",
    "!curl -L -O https://www.dropbox.com/s/w4oklbsoqefou3b/topUsers_Apr-Jul_2014_1000-words_summaries.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ID\",\"CODE\",\"TOTAL_WORDS\",\"http\",\"I\",\"the\",\"to\",\"you\"\r\n",
      "ALL_CODES,NA,61819567,2488393,1989622,1329663,1259298,1181631\r\n",
      "CODE,0,35130977,449927,1668694,914155,957278,916553\r\n",
      "CODE,1,11423284,1239122,28497,117272,104367,10209\r\n",
      "CODE,2,9373246,613561,42672,191091,60120,31309\r\n",
      "CODE,3,5892060,185783,249759,107145,137533,223560\r\n"
     ]
    }
   ],
   "source": [
    "# take a look at the first few columns\n",
    "!cut -d ',' -f 1-8 topUsers_Apr-Jul_2014_1000-words_summaries.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.0 \n",
    "\n",
    "What is MrJob? How is it different to Hadoop MapReduce? \n",
    "What are the mapper_init, mapper_final(), combiner_final(), reducer_final() methods? When are they called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answers\n",
    "\n",
    "Mrjob is a Python MapReduce package that helps you write and run Hadoop Streaming jobs. MRJob uses Hadoop MapReduce, but it's specifically a Python implementation that allows Hadoop jobs to be run on EMR clusters. The function descriptions are as follows:\n",
    "\n",
    "mapper_init - This defines an action to run before the mapper processes any input. For example, you could use this function to initialize mapper-specific helpers. It's called before the mapper starts processing data.\n",
    "\n",
    "mapper_final - This defines an action to run after the mapper reaches the end of input. This is called after reading all input data. \n",
    "\n",
    "combiner_final - This defines an action to run after the combiner reaches the end of input. It's called after the combiner has processed all data.\n",
    "\n",
    "reducer_final - This defines an action to run after the reducer reaches the end of input. It's called at the end of the reducer process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.1\n",
    "- What is serialization in the context of MrJob or Hadoop? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRJob assumes that all data is newline-delimited bytes. It automatically serializes and deserializes these bytes using built in protocols. In Hadoop you have to define how you serialize or deserialize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When it used in these frameworks? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRJob automatically serializes and deserializes data going into and coming out of each task. The input/output/internal protocol will serialize/deserialize the data according to how you define it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the default serialization mode for input and outputs for MrJob? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default input protocal is RawValueProtocol. The default output and internal protocols are both JSONProtocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.2  - Preprocess log file data\n",
    "\n",
    "For this homework question we'll work with the Microsoft log files we downloaded to `anonymous-msweb.data`. Your job is to  transform/preprocess the data on a single node (i.e., not on a cluster of nodes) from the following format:\n",
    "\n",
    ">C,\"10001\",10001   #Visitor id 10001  \n",
    "V,1000,1          #Visit by Visitor 10001 to page id 1000  \n",
    "V,1001,1          #Visit by Visitor 10001 to page id 1001  \n",
    "V,1002,1          #Visit by Visitor 10001 to page id 1002  \n",
    "C,\"10002\",10002   #Visitor id 10001  \n",
    "V  \n",
    "Note: #denotes comments  \n",
    "\n",
    "\n",
    "to the following format (V, PageID, 1, C, Visitor):\n",
    "\n",
    ">V,1000,1,C, 10001  \n",
    "V,1001,1,C, 10001  \n",
    "V,1002,1,C, 10001  \n",
    "\n",
    "Write the python code to accomplish this transformation. Save your output to a file called `anonymous-msweb-preprocessed.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transformation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transformation.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "pathToFile = sys.argv[1]\n",
    "wordCounts = defaultdict(int)\n",
    "\n",
    "def hw42(pathToFile):\n",
    "    # takes the path to the file as command line argument\n",
    "    # prints sorted tab separated list of words and counts\n",
    "    # ex) print word,'\\t',count\n",
    "    # returns sorted list of tuples of words and counts: wordList\n",
    "    # ex) wordList = [('a', 690),('abide', 2),...]\n",
    "  \n",
    "    wordList = {}\n",
    "\n",
    "    # START STUDENT CODE HW1.1\n",
    "    with open(pathToFile, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "            cols = line.split(\",\")\n",
    "            if(cols[0] == \"A\"):\n",
    "                attributeId = cols[1]\n",
    "                #col[2] can be ignored\n",
    "                VrootTitle = cols[3]\n",
    "                url = cols[4]\n",
    "                \n",
    "            if(cols[0] == \"C\"):\n",
    "                caseId = cols[1]\n",
    "                userNo = cols[2]\n",
    "            if(cols[0] == \"V\"):\n",
    "                string = \"V,\"+str(cols[1])+\",1,C,\"+str(userNo)\n",
    "                string = string.strip('\\n')\n",
    "                print(string)\n",
    "    \n",
    "    \n",
    "    #line = text_file.read().lower()\n",
    "    \n",
    "    #for word in re.findall(r'[a-z]+', text_string):\n",
    "        #wordCounts[word] += 1\n",
    "        \n",
    "    #for key in sorted(wordCounts):\n",
    "        #print key,'\\t', wordCounts[key]\n",
    "\n",
    "    # END STUDENT CODE HW1.1\n",
    "  \n",
    "    return\n",
    "\n",
    "hw42(pathToFile)\n",
    "\n",
    "#END STUDENT CODE42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python transformation.py 'anonymous-msweb.data' > anonymous-msweb-preprocessed.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,1000,1,C,10001\n",
      "V,1001,1,C,10001\n",
      "V,1002,1,C,10001\n",
      "V,1001,1,C,10002\n",
      "V,1003,1,C,10002\n",
      "V,1001,1,C,10003\n",
      "V,1003,1,C,10003\n",
      "V,1004,1,C,10003\n",
      "V,1005,1,C,10004\n",
      "V,1006,1,C,10005\n",
      "98654 anonymous-msweb-preprocessed.data\n"
     ]
    }
   ],
   "source": [
    "# Take a look at your results\n",
    "!head -10 anonymous-msweb-preprocessed.data\n",
    "!wc -l anonymous-msweb-preprocessed.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3 - Find the most frequent pages\n",
    "\n",
    "Find the 5 most frequently visited pages using MrJob from the output of 4.2 (i.e., transfromed log file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MostFrequentVisits.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MostFrequentVisits.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE43\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    " \n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        words = line.split(\",\")\n",
    "        yield words[1].lower(), 1\n",
    "     \n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    #hello, (1,1,1,1,1,1): using a combiner? NO and YEs\n",
    "    def reducer(self, word, counts):\n",
    "        yield None, (sum(counts), word)\n",
    "        \n",
    "    def reducer_final_sort_clip(self, _, page_count_pairs):\n",
    "        for (count, page) in sorted(page_count_pairs, reverse=True)[0:5]:\n",
    "            yield page, count\n",
    "        \n",
    "    def steps(self):\n",
    "        return [self.mr(\n",
    "                    mapper=self.mapper,\n",
    "                    combiner = self.combiner,\n",
    "                    reducer=self.reducer),\n",
    "                self.mr(reducer=self.reducer_final_sort_clip)\n",
    "                ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n",
    "\n",
    "\n",
    "#END STUDENT CODE43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x MostFrequentVisits.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/MostFrequentVisits.root.20170924.152746.640326\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Running step 1 of 2...\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Running step 2 of 2...\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Streaming final output from /tmp/MostFrequentVisits.root.20170924.152746.640326/output...\n",
      "Removing temp directory /tmp/MostFrequentVisits.root.20170924.152746.640326...\n"
     ]
    }
   ],
   "source": [
    "!python MostFrequentVisits.py anonymous-msweb-preprocessed.data > 43_sorted_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1008\"\t10836\r\n",
      "\"1034\"\t9383\r\n",
      "\"1004\"\t8463\r\n",
      "\"1018\"\t5330\r\n",
      "\"1017\"\t5108\r\n"
     ]
    }
   ],
   "source": [
    "!cat 43_sorted_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4  - Find the most frequent visitor\n",
    "\n",
    "Find the most frequent visitor of each page using MrJob and the output of 4.2  (i.e., transfromed log file). In this output please include the webpage URL, webpageID and Visitor ID.  You may get a weird result.  HINT: The maximum visits by any visitor to any given webpage is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAADQCAYAAAFdDMvvAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5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\nIAiCOCX/PwD2h+6Lr7Jp0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('ms-data.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp anonymous-msweb.data /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mostFrequentVisitors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentVisitors.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE44\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "from collections import defaultdict\n",
    "\n",
    "class MRLeftJoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\",\")\n",
    "        for line in open(\"/tmp/anonymous-msweb.data\").readlines():\n",
    "            #A,1287,1,\"International AutoRoute\",\"/autoroute\"\n",
    "            parts = line.split(\",\")\n",
    "            if(parts[0] == 'A'):\n",
    "                if(str(parts[1]) == str(splits[1])):\n",
    "                    webpageurl = parts[4]\n",
    "                    break\n",
    "                else:\n",
    "                    webpageurl = 'no url'\n",
    "        webpageId = splits[1]\n",
    "        yield webpageId, (webpageurl, splits[4], 1)\n",
    "    \n",
    "    def reducer(self, key, value):\n",
    "        sumCount = 0\n",
    "        for webpageurl, visitorId, count in value:\n",
    "            sumCount += count\n",
    "        yield webpageId, webpageurl, visitorId, sumCount\n",
    "        \n",
    "    def steps(self):\n",
    "        return [self.mr(\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer)\n",
    "                ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRLeftJoin.run()\n",
    "\n",
    "#END STUDENT CODE44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mostFrequentVisitors.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostFrequentVisitors.root.20170928.151442.592491\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Running step 1 of 1...\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n"
     ]
    }
   ],
   "source": [
    "!python mostFrequentVisitors.py anonymous-msweb-preprocessed.data > 441_sorted_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat 441_sorted_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5 - Clustering Tweet Dataset\n",
    "\n",
    "For this question use the Tweet data in `topUsers_Apr-Jul_2014_1000-words.txt`, you will implement a 1000-dimensional K-means algorithm in MrJob on the users by their 1000-dimensional word stripes/vectors using several centroid initializations and values of K.\n",
    "\n",
    "Note that each \"point\" is a user as represented by 1000 words, and thatword-frequency distributions are generally heavy-tailed power-laws(often called Zipf distributions), and are very rare in the larger class of discrete, random distributions. For each user you will have to normalize by its \"TOTAL\" column. __Try several parameterizations and initializations__ :\n",
    "\n",
    "* (A) K=4 uniform random centroid-distributions over the 1000 words (generate 1000 random numbers and normalize the vectors)\n",
    "* (B) K=2 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "* (C) K=4 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "* (D) K=4 \"trained\" centroids, determined by the sums across the classes. Use use the \n",
    "(row-normalized) class-level aggregates as 'trained' starting centroids (i.e., the training is already done for you!).\n",
    "\n",
    "Note that you do not have to compute the aggregated distribution or the class-aggregated distributions, which are rows in the auxiliary file `topUsers_Apr-Jul_2014_1000-words_summaries.txt`. \n",
    "\n",
    "For (A),  we select 4 users randomly from a uniform distribution [1,...,1,000]. For (B), (C), and (D)  you will have to use data from the auxiliary file. In parts (B) and (C), you will have to perturb the 1000-user aggregate (after initially normalizing by its sum, which is also provided). So if in (B) you want to create 2 perturbations of the aggregate, startwith (1), normalize, and generate 1000 random numbers uniformly from the unit interval (0,1) twice (for two centroids), using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes from office hours\n",
    "\n",
    "frequency of user using word, normalized--so greatest it can be is one (100%); to do this, divide all wordcounts by total wordcount\n",
    "\n",
    "a - 4 random centroids\n",
    "b/c. normal distribution \n",
    "d. get mean for each class -- use auxiliary file with sums or words; divide by total and you get a distribution that dist. is  the vector for class \n",
    "\n",
    "\n",
    "sorts in mrjob:\n",
    "1. example in slides. slide 62 and 63\n",
    "jobconf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "numbers = random.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take these 1000 numbers and add them (component-wise) to the 1000-user aggregate,\n",
    "and then renormalize to obtain one of your aggregate-perturbed initial centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "##Geneate random initial centroids around the global aggregate\n",
    "##Part (B) and (C) of this question\n",
    "###################################################################################\n",
    "def startCentroidsBC(k):\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    #perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids\n",
    "\n",
    "cent = startCentroidsBC(4)\n",
    "print len(cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For experiments A, B, C and D and iterate until a threshold (try 0.001) is reached.\n",
    "After convergence, print out a summary of the classes present in each cluster.\n",
    "In particular, report the composition as measured by the total\n",
    "portion of each class type (0-3) contained in each cluster,\n",
    "and discuss your findings and any differences in outcomes across parts A-D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### copy files to temporary mr job directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp topUsers_Apr-Jul_2014_1000-words_summaries.txt /tmp\n",
    "!cp topUsers_Apr-Jul_2014_1000-words.txt /tmp\n",
    "!cp Centroids.txt /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working example that outputs tweet id and cluster assignment\n",
    "\n",
    "Using Unit test ipynb referenced in slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting KMeansCluster.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile KMeansCluster.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE43\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "numbers = random.sample(1000)\n",
    "\n",
    "class KMeans(MRJob):\n",
    "    \n",
    "    def startCentroidsBC(self, k):\n",
    "        counter = 0\n",
    "        for line in open(\"/tmp/topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "            if counter == 2:        \n",
    "                data = re.split(\",\",line)\n",
    "                globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "            counter += 1\n",
    "        #perturb the global aggregate for the four initializations    \n",
    "        centroids = []\n",
    "        for i in range(k):\n",
    "            rndpoints = random.sample(1000)\n",
    "            peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "            centroids.append(peturpoints)\n",
    "            total = 0\n",
    "            for j in range(len(centroids[i])):\n",
    "                total += centroids[i][j]\n",
    "            for j in range(len(centroids[i])):\n",
    "                centroids[i][j] = centroids[i][j]/total\n",
    "        return centroids\n",
    "    \n",
    "    def initialize_centroids(self):\n",
    "        self.centroids = np.random.uniform(low=0.0, high=10.0, size=(self.num_clusters, self.num_features))\n",
    "        return\n",
    "\n",
    "    def get_nearest_centroid(self, centroids, X):\n",
    "        #centroids = np.array(self.centroids)\n",
    "        self.cluster_assignments = []\n",
    "        for i in range(len(X)):\n",
    "            data_point = np.array(X[i])\n",
    "            # Calculate the distance of this data point from each centroid\n",
    "            distances = np.sqrt(np.sum(np.square(np.subtract(data_point, centroids)), axis=1))  \n",
    "            print distances\n",
    "            # Get the nearest centroid for this data point\n",
    "            nearest_centroid_index = np.argmin(distances)\n",
    "            self.cluster_assignments.append(nearest_centroid_index)\n",
    "        #print len(self.cluster_assignments)\n",
    "        return \n",
    "    \n",
    "    def calc_new_centroids(self, X):\n",
    "        sums = np.array([[0.0]*self.num_features]*self.num_clusters)\n",
    "        counts = np.array([0]*self.num_clusters)\n",
    "        for i in range(len(X)):\n",
    "            data_point = np.array(X[i])\n",
    "            sums[self.cluster_assignments[i]] += data_point\n",
    "            counts[self.cluster_assignments[i]] += 1\n",
    "        for i in range(self.num_clusters):\n",
    "            if counts[i] != 0:\n",
    "                self.centroids[i] = 1.0*sums[i]/counts[i]\n",
    "            else:\n",
    "                pass  # If no data points were assigned to the cluster, keep old centroid\n",
    "        return\n",
    "                \n",
    "    def time_to_stop(self, old_centroids, iteration):\n",
    "        flag = True\n",
    "        if iteration >= self.max_iterations:\n",
    "            flag = True\n",
    "            print 'Maximum number of iterations reached.'\n",
    "            return flag\n",
    "        old_centroids = np.array(old_centroids)\n",
    "        new_centroids = np.array(self.centroids)\n",
    "        diffs = np.absolute(np.subtract(old_centroids, new_centroids))\n",
    "        if np.amax(diffs) < 0.001:\n",
    "            flag = True\n",
    "            print 'Stopping threshold reached.  Number of iterations = %d.' %(iteration)\n",
    "        else:\n",
    "            flag = False\n",
    "        return flag\n",
    "    \n",
    "    def assign_clusters(self, X, y=None, num_clusters=1):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.num_features = len(X[0])\n",
    "        # Step 0:  Initialize Centroids    \n",
    "        self.initialize_centroids()\n",
    "        # Iterate until termination criterion is reached:\n",
    "        iteration = 1\n",
    "        while(1):\n",
    "            # Keep starting centroids to check for convergence\n",
    "            old_centroids = copy.deepcopy(self.centroids[:])\n",
    "            # Step 1: Get nearest centroids\n",
    "            self.get_nearest_centroid(X)\n",
    "            # Step 2: Calculate New Centroids\n",
    "            self.calc_new_centroids(X)\n",
    "            # Check termination criteria\n",
    "            if iteration%100 == 0:\n",
    "                print 'Iteration %d complete.' %(iteration)\n",
    "            if self.time_to_stop(old_centroids, iteration):\n",
    "                break\n",
    "            # Increment number of iterations\n",
    "            iteration += 1\n",
    "        return\n",
    "    \n",
    "    def centroids(self):\n",
    "        return self.centroids\n",
    "    \n",
    "    def cluster_assignments(self):\n",
    "        return cluster_assignments\n",
    "\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        self.num_clusters = 4\n",
    "        centroids = np.array(self.startCentroidsBC(self.num_clusters))\n",
    "        words = line.split(\",\")\n",
    "        #first word is id\n",
    "        #second word is total\n",
    "        #rest is counts\n",
    "        points = np.array(words[3:])\n",
    "        points = [ int(x) for x in points ]\n",
    "        #get centroid closest to points\n",
    "        index = self.get_nearest_centroid(centroids, points)\n",
    "        yield words[0], index\n",
    "\n",
    "    def reducer(self, userid, cluster):\n",
    "        yield userid, cluster\n",
    "        \n",
    "    def steps(self):\n",
    "        return [self.mr(\n",
    "                    mapper = self.mapper,\n",
    "                    reducer=self.reducer)\n",
    "                ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    KMeans.run()\n",
    "\n",
    "\n",
    "#END STUDENT CODE43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/KMeansCluster.root.20170928.142842.152695\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Running step 1 of 1...\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"KMeansCluster.py\", line 134, in <module>\n",
      "    KMeans.run()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 452, in run\n",
      "    mr_job.execute()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 473, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 156, in execute\n",
      "    self.run_job()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 226, in run_job\n",
      "    runner.run()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/runner.py\", line 416, in run\n",
      "    self._run()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.py\", line 184, in _run\n",
      "    self._invoke_step(step_num, 'mapper')\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.py\", line 271, in _invoke_step\n",
      "    working_dir, env)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/inline.py\", line 154, in _run_step\n",
      "    child_instance.execute()\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 461, in execute\n",
      "    self.run_mapper(self.options.step_num)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 539, in run_mapper\n",
      "    for out_key, out_value in mapper(key, value) or ():\n",
      "  File \"KMeansCluster.py\", line 121, in mapper\n",
      "    index = self.get_nearest_centroid(centroids, points)\n",
      "  File \"KMeansCluster.py\", line 44, in get_nearest_centroid\n",
      "    print distances\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/numeric.py\", line 1869, in array_str\n",
      "    return array2string(a, max_line_width, precision, suppress_small, ' ', \"\", str)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/arrayprint.py\", line 447, in array2string\n",
      "    separator, prefix, formatter=formatter)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/arrayprint.py\", line 264, in _array2string\n",
      "    suppress_small),\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/arrayprint.py\", line 699, in __init__\n",
      "    sign=True)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/arrayprint.py\", line 537, in __init__\n",
      "    self.fillFormat(data)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/arrayprint.py\", line 560, in fillFormat\n",
      "    self.exp_format = True\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/numeric.py\", line 2973, in __exit__\n",
      "    seterr(**self.oldstate)\n",
      "  File \"/opt/anaconda/lib/python2.7/site-packages/numpy/core/numeric.py\", line 2661, in seterr\n",
      "    if under is None:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python KMeansCluster.py topUsers_Apr-Jul_2014_1000-words.txt > 45_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat 45_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final attempt\n",
    "\n",
    "I couldn't quite get this working in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "import numpy as np\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from itertools import chain\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def startCentroidsA(k):\n",
    "    points = random.uniform(size=[k, 1000])\n",
    "    total = np.sum(points, axis = 1)\n",
    "    centroids = np.true_divide(points.T, total).T\n",
    "    return centroids\n",
    "    \n",
    "def startCentroidsBC(k):\n",
    "    counter = 0\n",
    "    for line in open(\"/tmp/topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    #perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids\n",
    "\n",
    "def startCentroidsD(k):\n",
    "    counter = 0\n",
    "    centroids = []\n",
    "    for line in open(\"/tmp/topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter >= 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            # normalize the class aggregates\n",
    "            centroids.append([float(data[i+3])/float(data[2]) for i in range(1000)])\n",
    "        counter += 1\n",
    "    return centroids\n",
    "\n",
    "def get_nearest_centroid(data_point, centroid_points):\n",
    "    centroids = np.array(centroid_points)\n",
    "    data = np.array(data_point)  \n",
    "    # Calculate the Euclidean distance between the data_point and each of the centroids\n",
    "    distances = np.sqrt(np.sum(np.square(np.subtract(data, centroids)), axis=1))  \n",
    "    # Return the index of the nearest centroid for this data point\n",
    "    nearest_centroid_index = np.argmin(distances)\n",
    "    return nearest_centroid_index\n",
    "\n",
    "def stop_criterion(centroid_points_old, centroid_points_new, T):\n",
    "    old_centroids = np.array(centroid_points_old)\n",
    "    new_centroids = np.array(centroid_points_new)\n",
    "    diffs = np.absolute(np.subtract(old_centroids, new_centroids))\n",
    "    if np.amax(diffs) < T:\n",
    "        flag = True\n",
    "        print 'Stopping threshold reached (%.3f): %.3f' %(T, np.amax(diffs))\n",
    "    else:\n",
    "        flag = False\n",
    "    return flag\n",
    "\n",
    "def dist(X, centroids):\n",
    "    centroids = np.array(centroids)\n",
    "    for i in range(len(X)):\n",
    "        data_point = np.array(X)\n",
    "        # Calculate the distance of this data point from each centroid\n",
    "        distances = np.sqrt(np.sum(np.square(np.subtract(data_point, centroids)), axis=1))              \n",
    "        # Get the nearest centroid for this data point\n",
    "        nearest_centroid_index = np.argmin(distances)\n",
    "    return nearest_centroid_index\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=3    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init = self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer=self.reducer)\n",
    "               ]\n",
    "    #load centroids info from file\n",
    "    def mapper_init(self):\n",
    "        print \"Current path:\", os.path.dirname(os.path.realpath(__file__))\n",
    "        \n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        #open('Centroids.txt', 'w').close()\n",
    "        \n",
    "        print \"Centroids: \", self.centroid_points\n",
    "        \n",
    "    #load data and output the nearest centroid index and data point \n",
    "    def mapper(self, _, line):\n",
    "        words = line.split(\",\")\n",
    "        #first word is id\n",
    "        userId = words[0]\n",
    "        #second word is code\n",
    "        code = words[1]\n",
    "        #third word is total\n",
    "        total = words[2]\n",
    "        #rest is counts\n",
    "        points = np.array(words[3:])\n",
    "        #normalize counts\n",
    "        points = [ float(x)/float(total) for x in points ]\n",
    "        yield int(dist(points,self.centroid_points)), (userId,code,points,1) #instead of d's send words\n",
    "    #Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata): #takes all the word frequency collections and summing them all up\n",
    "        #start with 1000 arry, and add word counts to each entry of array \n",
    "        #should end up with k arrays of word counts\n",
    "        #output centroid index and (1000 list word frequencies, dictionary)\n",
    "        codes = defaultdict(float)\n",
    "        words = defaultdict(float)\n",
    "        for userId,code,points,n in inputdata:\n",
    "            for x in range(len(points)):\n",
    "                codes[code] += float(points[x])\n",
    "                words[x] += float(points[x])\n",
    "        yield idx,(words,codes)\n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata):  #does same thing as combiner\n",
    "        #end up with dictionary of code counts, final word frequencies, and centroids\n",
    "        #average of word frequencies for each word--sum of word frequency/total words\n",
    "        codes = defaultdict(float)\n",
    "        words = defaultdict(float)\n",
    "        for points,codeCounts in inputdata:\n",
    "            for x in range(len(points)):\n",
    "                words[x] += float(points[x])\n",
    "            for x in range(len(codeCounts)):\n",
    "                codes[x] += float(codeCounts[x])\n",
    "        \n",
    "        yield idx,(words,codes)\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "Current path: /tmp/Kmeans.root.20170928.140909.699083/job_local_dir/0/mapper/0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: [ 0.88933829  0.66860719  0.19337596  0.64082528  0.43655146  0.99010747",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0650a38a8e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Iteration \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmr_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#MRJob bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m                         ' encoding issues\\n')\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ran_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mapper'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'reducer'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(self, step_num, step_type)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             self._run_step(step_num, step_type, input_path, output_path,\n\u001b[0;32m--> 271\u001b[0;31m                            working_dir, env)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_outfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/inline.pyc\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, step_num, step_type, input_path, output_path, working_dir, env, child_stdin)\u001b[0m\n\u001b[1;32m    152\u001b[0m                     child_instance.sandbox(stdin=child_stdin,\n\u001b[1;32m    153\u001b[0m                                            stdout=child_stdout)\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mchild_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mrun_mapper\u001b[0;34m(self, step_num)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmapper_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapper_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m                 \u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/notebooks/Kmeans.pyc\u001b[0m in \u001b[0;36mmapper_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Current path:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Centroids.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;31m#open('Centroids.txt', 'w').close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: [ 0.88933829  0.66860719  0.19337596  0.64082528  0.43655146  0.99010747"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import random\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['topUsers_Apr-Jul_2014_1000-words.txt', '--file=Centroids.txt'])\n",
    "\n",
    "#Initial centroids\n",
    "centroids = []\n",
    "k = 3\n",
    "#uniform\n",
    "for i in range(k):\n",
    "    centroids.append([random.uniform(0,1,1000)])\n",
    "with open('Centroids.txt', 'w+') as f:\n",
    "    f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroids)\n",
    "\n",
    "#check to see if centroids change\n",
    "i = 0\n",
    "while(1):\n",
    "    oldCentroids = centroids[:]\n",
    "    print \"Iteration \"+str(i)+\":\"\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        #MRJob bit \n",
    "        for line in runner.stream_output():\n",
    "            key,value =  mr_job.parse_output_line(line)\n",
    "            print key, value\n",
    "            centroids[key] = value\n",
    "            \n",
    "        # Update the centroids\n",
    "        with open('Centroids.txt', 'w') as f:\n",
    "            f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroids)\n",
    "        \n",
    "    print \"\"\n",
    "    i = i + 1\n",
    "    if(stop_criterion(oldCentroids,centroids,0.001)):\n",
    "        break\n",
    "print \"Centroids\"\n",
    "print \"----------\"\n",
    "print centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Means</h2>\n",
    "K-means is a clustering method that aims to find the positions μi,i=1...k of the clusters that minimize the distance from the data points to the cluster. K-means clustering solves:\n",
    "<br><br>\n",
    "$$\\arg\\min_{c} \\sum_{i=1}^k\\sum_{{x}\\in c_i} d({x},\\mu_i) = \\arg\\min_{c} \\sum_{i=1}^k\\sum_{{x}\\in c_i} \\left\\Vert {x}-\\mu_i \\right\\Vert_2^2$$\n",
    "<br><br>\n",
    "where ${c}_i$ is the set of points that belong to cluster i. The K-means clustering uses the square of the Euclidean distance $d({x},\\mu_i) = \\left\\Vert {x}-\\mu_i \\right\\Vert_2^2$. This problem is not trivial (in fact it is NP-hard), so the K-means algorithm only hopes to find the global minimum, possibly getting stuck in a different solution.\n",
    "\n",
    "<h2>K-means algorithm</h2>\n",
    "\n",
    "The Lloyd's algorithm, mostly known as k-means algorithm, is used to solve the k-means clustering problem and works as follows. First, decide the number of clusters k. Then:\n",
    "\n",
    "<table>\n",
    "<tbody><tr><td>1. Initialize the center of the clusters</td>\n",
    "<td>${\\mu}_i = $ some value $, i=1,...,k$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2. Attribute the closest cluster to each data point</td>\n",
    "<td>${c}_i = \\{j: d({x}_j, \\mu_i) \\le d({x}_j, \\mu_l),  l \\ne i, j=1,...,n\\}$ </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3. Set the position of each cluster to the mean of all data points belonging to that cluster</td>\n",
    "<td>$\\mu_i = \\frac{1}{|c_i|}\\sum_{j\\in c_i} {x}_j,\\forall i$</td>\n",
    "</tr>\n",
    "<tr><td>4. Repeat steps 2-3 until convergence</td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr><td>Notation</td><td>${|c|} = $ number of elements in  ${c}$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calculating purity</h2>\n",
    "![purity illustration](http://www.candpgeneration.com/images/purity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile Kmeans.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE45\n",
    "\n",
    "\n",
    "\n",
    "#END STUDENT CODE45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile kmeans_runner.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE45_RUNNER\n",
    "\n",
    "\n",
    "\n",
    "#END STUDENT CODE45_RUNNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.6  - (OPTIONAL) Scaleable K-MEANS++ \n",
    "\n",
    "Over half a century old and showing no signs of aging,\n",
    "k-means remains one of the most popular data processing\n",
    "algorithms. As is well-known, a proper initialization\n",
    "of k-means is crucial for obtaining a good final solution.\n",
    "The recently proposed k-means++ initialization algorithm\n",
    "achieves this, obtaining an initial set of centers that is provably\n",
    "close to the optimum solution. A major downside of the\n",
    "k-means++ is its inherent sequential nature, which limits its\n",
    "applicability to massive data: one must make k passes over\n",
    "the data to find a good initial set of centers. The paper listed below \n",
    "shows how to drastically reduce the number of passes needed\n",
    "to obtain, in parallel, a good initialization. This is unlike\n",
    "prevailing efforts on parallelizing k-means that have mostly\n",
    "focused on the post-initialization phases of k-means. The \n",
    "proposed initialization algorithm k-means||\n",
    "obtains a nearly optimal solution after a logarithmic number\n",
    "of passes; the paper also shows that in practice a constant\n",
    "number of passes suffices. Experimental evaluation on realworld\n",
    "large-scale data demonstrates that k-means|| outperforms\n",
    "k-means++ in both sequential and parallel settings.\n",
    "\n",
    "Read the following paper entitled \"Scaleable K-MEANS++\" located at:\n",
    "\n",
    "http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf \n",
    "\n",
    "In MrJob, implement K-MEANS|| and compare with a random initializtion when used in \n",
    "conjunction with the kmeans algorithm as an initialization step for the 2D  dataset \n",
    "generated using code in the following notebook:\n",
    "\n",
    "https://www.dropbox.com/s/lbzwmyv0d8rocfq/MrJobKmeans.ipynb?dl=0\n",
    "\n",
    "Plot the initialation centroids and the centroid trajectory as the K-MEANS|| algorithms iterates. \n",
    "Repeat this for a random initalization (i.e., pick a training vector at random for each inital centroid)\n",
    "of the kmeans algorithm. Comment on the trajectories of both algorithms.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms.\n",
    "Also report the rand index score for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 (OPTIONAL) Apply K-MEANS||\n",
    "\n",
    "Apply your implementation of K-MEANS|| to the dataset  in HW 4.5 and compare to the a random initalization (i.e., pick a training vector at random for each inital centroid)of the kmeans algorithm.\n",
    "Report on the number passes over the training data, and time required to run all  clustering algorithms. \n",
    "Also report the rand index score for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.7 - (OPTIONAL) Canopy Clustering\n",
    "\n",
    "An alternative way to intialize the k-means algorithm is the  canopy clustering. The canopy clustering \n",
    "algorithm is an unsupervised pre-clustering algorithm introduced by Andrew McCallum, Kamal Nigam and \n",
    "Lyle Ungar in 2000. It is often used as preprocessing step for the K-means algorithm or the \n",
    "Hierarchical clustering algorithm. It is intended to speed up clustering operations on large data sets, \n",
    "where using another algorithm directly may be impractical due to the size of the data set.\n",
    "\n",
    "For more details on the Canopy Clustering algorithm see:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Canopy_clustering_algorithm\n",
    "\n",
    "Plot the initialation centroids and the centroid trajectory as the Canopy Clustering based K-MEANS algorithm iterates. \n",
    "Repeat this for a random initalization (i.e., pick a training vector at random for each inital centroid)\n",
    "of the kmeans algorithm. Comment on the trajectories of both algorithms.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms.\n",
    "Also report the rand index score for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.1 (OPTIONAL) Apply Canopy Clustering based K-MEANS\n",
    "\n",
    "Apply your implementation Canopy Clustering based K-MEANS algorithm to the dataset  in HW 4.5 and compare to the a \n",
    "random initalization (i.e., pick a training vector at random for each inital centroid)of the kmeans algorithm.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms. \n",
    "Also report the rand index score for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "380px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "410px",
    "left": "458.76361083984375px",
    "right": "20px",
    "top": "120px",
    "width": "397px"
   },
   "toc_section_display": "none",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
