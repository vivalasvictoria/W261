{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#MIDS-w261-Machine-Learning-at-Scale\" data-toc-modified-id=\"MIDS-w261-Machine-Learning-at-Scale-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MIDS w261 Machine Learning at Scale</a></div><div class=\"lev2 toc-item\"><a href=\"#MidTerm-Exam\" data-toc-modified-id=\"MidTerm-Exam-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>MidTerm Exam</a></div><div class=\"lev3 toc-item\"><a href=\"#Please-insert-your-contact-information-here\" data-toc-modified-id=\"Please-insert-your-contact-information-here-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Please insert your contact information here</a></div><div class=\"lev1 toc-item\"><a href=\"#Exam-Instructions\" data-toc-modified-id=\"Exam-Instructions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exam Instructions</a></div><div class=\"lev1 toc-item\"><a href=\"#Exam-questions-begins-here\" data-toc-modified-id=\"Exam-questions-begins-here-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exam questions begins here</a></div><div class=\"lev2 toc-item\"><a href=\"#Data-and--Starter-code-for-questions-6-and-7\" data-toc-modified-id=\"Data-and--Starter-code-for-questions-6-and-7-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data and  Starter code for questions 6 and 7</a></div><div class=\"lev2 toc-item\"><a href=\"#Data-for-question-11\" data-toc-modified-id=\"Data-for-question-11-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Data for question 11</a></div><div class=\"lev2 toc-item\"><a href=\"#Starter-Code-for-question-17\" data-toc-modified-id=\"Starter-Code-for-question-17-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Starter Code for question 17</a></div><div class=\"lev2 toc-item\"><a href=\"#Starter-Code-for-question-18\" data-toc-modified-id=\"Starter-Code-for-question-18-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Starter Code for question 18</a></div><div class=\"lev2 toc-item\"><a href=\"#Starter-Code-for-question-19\" data-toc-modified-id=\"Starter-Code-for-question-19-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Starter Code for question 19</a></div><div class=\"lev1 toc-item\"><a href=\"#END-of-Exam\" data-toc-modified-id=\"END-of-Exam-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>END of Exam</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS w261 Machine Learning at Scale\n",
    "## MidTerm Exam  \n",
    "\n",
    "\n",
    "MIDS Machine Learning at Scale\n",
    "\n",
    "\n",
    "\n",
    "### Please insert your contact information here\n",
    "__Insert you name here__           : Victoria Baker  \n",
    "__Insert you email here__          : victoria.baker@ischool.berkeley.edu   \n",
    "__Insert your  UC Berkeley ID here__: 3032501083\n",
    "\n",
    "# Exam Instructions\n",
    "\n",
    "1. : Please insert Name and Email address in the first cell of this notebook\n",
    "2. : Please keep all your work and responses in ONE (1) notebook only \n",
    "3. : For the midterm you will need access to MrJob and Jupyter on your local machines (should be more than sufficient) or on Altiscale/AWS to complete some of the questions (like fill in the code to do X).\n",
    "4. : As for question types:\n",
    "    + Knowledge test Programmatic/doodle (take photos; embed the photos in your notebook, along with the photos directory in a zip file) \n",
    "    + All programmatic questions can be run locally on your laptop (using MrJob only) or on the cluster\n",
    "\n",
    "5. : This is an open book exam meaning you can consult webpages and textbooks, class notes, slides etc. but you can not discuss with each other or any other person/group. If any collusion, then this will result in a zero grade and will be grounds for dismissal from the entire program. Please complete this exam by yourself within the time limit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam questions begins here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and  Starter code for questions 6 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kltext.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile kltext.txt\n",
    "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\n",
    "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\r\n",
      "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
     ]
    }
   ],
   "source": [
    "!cat kltext.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kldivergence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence.py\n",
    "#coding: utf-8\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "import numpy as np\n",
    "class kldivergence(MRJob):\n",
    "    \n",
    "    # process each string character by character\n",
    "    # the relative frequency of each character emitting Pr(character|str)\n",
    "    # for input record 1.abcbe\n",
    "    # emit \"a\"    [1, 0.2]\n",
    "    # emit \"b\"    [1, 0.4] etc...\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            yield key, [index, count[key]*1.0/len(letter_list)]\n",
    "\n",
    "    # on a component i calculate (e.g., \"b\")\n",
    "    # Kullback–Leibler divergence of Q from P is defined\n",
    "    #  (P(i) log (P(i) / Q(i))\n",
    "    #\n",
    "    def reducer1(self, key, values):\n",
    "        p = 0\n",
    "        q = 0\n",
    "        for v in values:\n",
    "            if v[0] == 1:  #String 1\n",
    "                p = v[1]\n",
    "            else:          # String 2\n",
    "                q = v[1]\n",
    "                \n",
    "        ###### SOLUTION #############        \n",
    "        output = p*np.log(p/q)\n",
    "        yield None, output\n",
    "        #############################\n",
    "\n",
    "    #Aggegate components            \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield \"KLDivergence\", kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                \n",
    "                self.mr(reducer=self.reducer2)\n",
    "               \n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'KLDivergence', 0.0808827844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.job\"\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from mrjob.job import MRJob\n",
    "from kldivergence import kldivergence\n",
    "\n",
    "#dont forget to save kltext.txt (see earlier cell)\n",
    "mr_job = kldivergence(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kldivergence_smooth.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence_smooth.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "import numpy as np\n",
    "class kldivergence_smooth(MRJob):\n",
    "    \n",
    "    # process each string character by character\n",
    "    # the relative frequency of each character emitting Pr(character|str)\n",
    "    # for input record 1.abcbe\n",
    "    # emit \"a\"    [1, (1+1)/(5+24)]\n",
    "    # emit \"b\"    [1, (2+1)/(5+24) etc...\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        \n",
    "        # (ni+1)/(n+24)\n",
    "        \n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            ###### SOLUTION ############# \n",
    "            yield key, [index, (count[key] + 1)/(len(letter_list) + 24)]\n",
    "\n",
    "    \n",
    "    def reducer1(self, key, values):\n",
    "        p = 0\n",
    "        q = 0\n",
    "        for v in values:\n",
    "            if v[0] == 1:\n",
    "                p = v[1]\n",
    "            else:\n",
    "                q = v[1]\n",
    "        ###### SOLUTION #############         \n",
    "        output = p*np.log(p/q)\n",
    "        yield None, output\n",
    "\n",
    "    # Aggregate components             \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield \"KLDivergence\", kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                self.mr(reducer=self.reducer2)\n",
    "               \n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence_smooth.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'KLDivergence', 0.0672699729)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from kldivergence_smooth import kldivergence_smooth\n",
    "mr_job = kldivergence_smooth(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nbTrain.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile nbTrain.txt\n",
    "ham d1: “good.”\n",
    "ham d2: “very good.”\n",
    "spam d3: “bad.”\n",
    "spam d4: “very bad.”\n",
    "spam d5: “very bad, very BAD.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham d1: ���good.���\r\n",
      "ham d2: ���very good.���\r\n",
      "spam d3: ���bad.���\r\n",
      "spam d4: ���very bad.���\r\n",
      "spam d5: ���very bad, very BAD.���"
     ]
    }
   ],
   "source": [
    "!cat nbTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nbTest.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile nbTest.txt\n",
    "? d6: “good? bad! very Bad!” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? d6: ���good? bad! very Bad!��� "
     ]
    }
   ],
   "source": [
    "!cat nbTest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nb_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nb_train.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class nb_train(MRJob):\n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.docs = []\n",
    "        self.docCount = 0\n",
    "        self.spamDocs = []\n",
    "        self.hamDocs = []\n",
    "        self.spamWords = 0\n",
    "        self.hamWords = 0\n",
    "        self.allWordCount = 0\n",
    "        self.hamCounts = defaultdict(int)\n",
    "        self.spamCounts = defaultdict(int)\n",
    "        self.allWords = []\n",
    "\n",
    "    def mapperTrain(self, _, line):\n",
    "        line = line.strip()\n",
    "        words = re.sub(r\"[^a-z]+\", '', line).lower()\n",
    "\n",
    "        docClass, docId, text = line.split()[0:3]\n",
    "        \n",
    "        #if doc is spam, spamClass is 0, 1 for ham\n",
    "        if(docClass == 'spam'):\n",
    "            spamClass = 0\n",
    "        else:\n",
    "            spamClass = 1\n",
    "\n",
    "        #count of word\n",
    "        for word in re.findall(r'[a-z]+', text.strip().lower()):\n",
    "            yield docId, (spamClass, word, 1)\n",
    "\n",
    "\n",
    "    # Aggregate components             \n",
    "    def reducerTrain(self, key, values):\n",
    "        \n",
    "        docId = key\n",
    "        for x in values:\n",
    "            spamClass = x[0]\n",
    "            word = x[1]\n",
    "            count = int(x[2])\n",
    "\n",
    "        if(word not in self.allWords):\n",
    "            self.allWords.append(word)\n",
    "            self.allWordCount += 1\n",
    "\n",
    "        if(docId not in self.docs):\n",
    "            self.docs.append(docId)\n",
    "            self.docCount += 1\n",
    "            if(int(spamClass) == 0):\n",
    "                self.hamDocs.append(docId)\n",
    "            else:\n",
    "                self.spamDocs.append(docId)\n",
    "\n",
    "        if(int(spamClass) == 0):\n",
    "            self.hamWords += int(count)\n",
    "            self.hamCounts[word] += int(count)\n",
    "        else:\n",
    "            self.spamWords += int(count)\n",
    "            self.spamCounts[word] += int(count)       \n",
    "\n",
    "        for key in self.allWords:                                                                                                                                     \n",
    "            pr_Ham = (float(self.hamCounts[key])+1) / (float(self.hamWords) + len(self.allWords)-1)\n",
    "            pr_Spam = (float(self.spamCounts[key])+1)/ (float(self.hamWords) + len(self.allWords)-1)\n",
    "            string = str(self.hamCounts[key]) + ',' + str(self.spamCounts[key]) +',' + str(pr_Ham) + ',' + str(pr_Spam)\n",
    "            yield key, string\n",
    "\n",
    "        #hamFreq = str(len(hamDocs))\n",
    "        #spamFreq = str(len(spamDocs))\n",
    "        #pr_Ham = str(float(len(hamDocs))/(float(hamWords) + float(spamWords)))\n",
    "        #pr_Spam = str(float(len(spamDocs))/(float(hamWords) + float(spamWords)))                                  \n",
    "\n",
    "        #priorString = hamFreq + ',' + spamFreq +',' + pr_Ham + ','+ pr_Spam\n",
    "        #yield \"ClassPriors\", priorString   \n",
    "            \n",
    "    def steps(self):\n",
    "        return [\n",
    "                MRStep(\n",
    "                mapper = self.mapperTrain,\n",
    "                reducer_init = self.reducer_init,\n",
    "                reducer = self.reducerTrain,\n",
    "                jobconf = {'mapred.reduce.tasks' : 1 }\n",
    "                  )  \n",
    "               \n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nb_train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-df598f73be7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmr_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nbTrain.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmr_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# stream_output: get access of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m                         ' encoding issues\\n')\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ran_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;31m# run the reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reducer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# move final output to output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(self, step_num, step_type)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             self._run_step(step_num, step_type, input_path, output_path,\n\u001b[0;32m--> 271\u001b[0;31m                            working_dir, env)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_outfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/inline.pyc\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, step_num, step_type, input_path, output_path, working_dir, env, child_stdin)\u001b[0m\n\u001b[1;32m    152\u001b[0m                     child_instance.sandbox(stdin=child_stdin,\n\u001b[1;32m    153\u001b[0m                                            stdout=child_stdout)\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mchild_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_reducer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_reducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_spark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mrun_reducer\u001b[0;34m(self, step_num)\u001b[0m\n\u001b[1;32m    580\u001b[0m                                                key=lambda k_v: k_v[0]):\n\u001b[1;32m    581\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkv_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/notebooks/nb_train.pyc\u001b[0m in \u001b[0;36mreducerTrain\u001b[0;34m(self, key, values)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallWords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mpr_Ham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamWords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mpr_Spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspamCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamWords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspamCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_Ham\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_Spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nb_train import nb_train\n",
    "mr_job = nb_train(args=['nbTrain.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import numpy as np\n",
    "import pylab \n",
    "size1 = size2 = size3 = 10000\n",
    "samples1 = np.random.multivariate_normal([4, 0], [[1, 0],[0, 1]], size1)\n",
    "data = samples1\n",
    "samples2 = np.random.multivariate_normal([6, 6], [[1, 0],[0, 1]], size2)\n",
    "data = np.append(data,samples2, axis=0)\n",
    "samples3 = np.random.multivariate_normal([0, 4], [[1, 0],[0, 1]], size3)\n",
    "data = np.append(data,samples3, axis=0)\n",
    "# Randomlize data\n",
    "data = data[np.random.permutation(size1+size2+size3),]\n",
    "np.savetxt('Kmeandata.csv',data,delimiter = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMsSwC4IgVBli2AVBEKqM/w+1WtRu3P718AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27884b2890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(samples1[:, 0], samples1[:, 1],'*', color = 'red')\n",
    "pylab.plot(samples2[:, 0], samples2[:, 1],'o',color = 'blue')\n",
    "pylab.plot(samples3[:, 0], samples3[:, 1],'+',color = 'green')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from itertools import chain\n",
    "import os\n",
    "\n",
    "#Calculate find the nearest centroid for data point \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff*diff\n",
    "    # Get the nearest centroid for each instance\n",
    "    minidx = argmin(list(diffsq.sum(axis = 1)))\n",
    "    return minidx\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=3    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init = self.mapper_init, mapper=self.mapper,combiner = self.combiner,reducer=self.reducer)\n",
    "               ]\n",
    "    #load centroids info from file\n",
    "    def mapper_init(self):\n",
    "        print \"Current path:\", os.path.dirname(os.path.realpath(__file__))\n",
    "        \n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        #open('Centroids.txt', 'w').close()\n",
    "        \n",
    "        print \"Centroids: \", self.centroid_points\n",
    "        \n",
    "    #load data and output the nearest centroid index and data point \n",
    "    def mapper(self, _, line):\n",
    "        D = (map(float,line.split(',')))\n",
    "        yield int(MinDist(D,self.centroid_points)), (D[0],D[1],1)\n",
    "    #Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata):\n",
    "        sumx = sumy = num = 0\n",
    "        for x,y,n in inputdata:\n",
    "            num = num + n\n",
    "            sumx = sumx + x\n",
    "            sumy = sumy + y\n",
    "        yield idx,(sumx,sumy,num)\n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = []\n",
    "        num = [0]*self.k \n",
    "        for i in range(self.k):\n",
    "            centroids.append([0,0])\n",
    "        for x, y, n in inputdata:\n",
    "            num[idx] = num[idx] + n\n",
    "            #centroids[idx][0] = centroids[idx][0] + x\n",
    "            #centroids[idx][1] = centroids[idx][1] + y\n",
    "            x1 = self.centroid_points[idx][0]-x\n",
    "            x2 = self.centroid_points[idx][1]-y\n",
    "            weight = 1/(sqrt(x1**2+x2**2))\n",
    "            weight_total += weight\n",
    "\n",
    "            centroids[idx][0] = centroids[idx][0] + x*weight \n",
    "            centroids[idx][1] = centroids[idx][1] + y*weight\n",
    "            distance_total += sqrt((x*weight)**2+(y*weight)**2)\n",
    "            \n",
    "            \n",
    "        #centroids[idx][0] = centroids[idx][0]/num[idx]\n",
    "        #centroids[idx][1] = centroids[idx][1]/num[idx]\n",
    "        \n",
    "        print distance_total/weight_total\n",
    "        \n",
    "        #need to weight denominator too--otherwise, we'll get skewed results\n",
    "        weight_avg = running_weight_sum/num[idx]\n",
    "        centroids[idx][0] = centroids[idx][0]/num[idx] \n",
    "        centroids[idx][1] = centroids[idx][1]/num[idx]\n",
    "\n",
    "        yield idx,(centroids[idx][0],centroids[idx][1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1:\n",
      "Current path: /tmp/Kmeans.root.20171019.005158.936702/job_local_dir/0/mapper/0\n",
      "Centroids:  [[-0.439015435773, -2.8769007082], [-2.31902083471, -0.437603228662], [-0.771583783349, 0.943226534391]]\n",
      "Current path: /tmp/Kmeans.root.20171019.005158.936702/job_local_dir/0/mapper/1\n",
      "Centroids:  [[-0.439015435773, -2.8769007082], [-2.31902083471, -0.437603228662], [-0.771583783349, 0.943226534391]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-bd0f6f285e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmr_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# stream_output: get access of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m                         ' encoding issues\\n')\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ran_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;31m# run the reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reducer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# move final output to output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(self, step_num, step_type)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             self._run_step(step_num, step_type, input_path, output_path,\n\u001b[0;32m--> 271\u001b[0;31m                            working_dir, env)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_outfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/inline.pyc\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, step_num, step_type, input_path, output_path, working_dir, env, child_stdin)\u001b[0m\n\u001b[1;32m    152\u001b[0m                     child_instance.sandbox(stdin=child_stdin,\n\u001b[1;32m    153\u001b[0m                                            stdout=child_stdout)\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mchild_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_reducer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_reducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_spark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mrun_reducer\u001b[0;34m(self, step_num)\u001b[0m\n\u001b[1;32m    580\u001b[0m                                                key=lambda k_v: k_v[0]):\n\u001b[1;32m    581\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkv_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/notebooks/Kmeans.pyc\u001b[0m in \u001b[0;36mreducer\u001b[0;34m(self, idx, inputdata)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m#centroids[idx][0] = centroids[idx][0] + x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m#centroids[idx][1] = centroids[idx][1] + y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import random\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['Kmeandata.csv', '--file=Centroids.txt'])\n",
    "\n",
    "#Geneate initial centroids\n",
    "centroid_points = []\n",
    "k = 3\n",
    "for i in range(k):\n",
    "    centroid_points.append([random.uniform(-3,3),random.uniform(-3,3)])\n",
    "with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "# Update centroids iteratively\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "# Update centroids iteratively\n",
    "for i in range(10):\n",
    "    # save previous centoids to check convergency\n",
    "    centroid_points_old = centroid_points[:]\n",
    "    print \"iteration\"+str(i+1)+\":\"\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output \n",
    "        for line in runner.stream_output():\n",
    "            key,value =  mr_job.parse_output_line(line)\n",
    "            print key, value\n",
    "            centroid_points[key] = value\n",
    "    print \"\\n\"\n",
    "    i = i + 1\n",
    "print \"Centroids\\n\"\n",
    "for centroid in centroid_points:\n",
    "    print centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Starter Code for question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "W = np.array([6, -3, -2, 1])\n",
    "x = np.array([[1], \n",
    "              [2], \n",
    "              [3], \n",
    "              [4]])\n",
    "y = 2\n",
    "lam = 0.1\n",
    "total_loss = 22.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Starter Code for question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data artificially\n",
    "X = np.arange(1, 20)\n",
    "\n",
    "k, b = 1.5, 3\n",
    "\n",
    "y = k * X + b\n",
    "\n",
    "np.random.seed(21)\n",
    "y += np.random.normal(loc=0.0, scale=3.0, size=len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot([0, 20], [b, k * 20 + b], \"r\", linewidth=2, label=\"Real\")\n",
    "plt.xlim([0, 20])\n",
    "plt.ylim([0, 35])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicLinearRegressionHomegrown(object):\n",
    "    \n",
    "    def __init__(self, l1=0.0, l2=0.0):\n",
    "        self.coef_ = None       # weight vector\n",
    "        self.intercept_ = None  # bias term\n",
    "        self._theta = None      # augmented weight vector, i.e., bias + weights\n",
    "                                # this allows to treat all decision variables homogeneously\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        \n",
    "    # calculate gradient of objective function\n",
    "    def _grad(self, X, y):\n",
    "        pred = np.dot(X, self._theta)\n",
    "        error = pred - y\n",
    "        gradient = 2 * np.dot(error, X) / X.shape[0]\n",
    "        return gradient\n",
    "    \n",
    "    # full gradient descent, i.e., not stochastic gd\n",
    "    def _gd(self, X, y, max_iter, alpha=0.005):\n",
    "        for i in range(max_iter):\n",
    "            # calculate gradient\n",
    "            grad = self._grad(X, y)\n",
    "            # do gradient step\n",
    "            self._theta -= alpha * grad\n",
    "    \n",
    "    # public API for fitting a linear regression model\n",
    "    def fit(self, X, y, max_iter=1000):\n",
    "        # Augment the data with the bias term.\n",
    "        # So we can treat the the input variables and the bias term homogeneously \n",
    "        # from a vectorization perspective\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # initialize if the first step\n",
    "        if self._theta is None:\n",
    "            np.random.seed(21)\n",
    "            self._theta = np.random.rand(X.shape[1])\n",
    "        \n",
    "        # do full gradient descent\n",
    "        self._gd(X, y, max_iter)\n",
    "        \n",
    "        self.intercept_ = self._theta[0]\n",
    "        self.coef_ = self._theta[1:]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        error = pred - y\n",
    "        obj = np.sum(error ** 2) / X.shape[0]\n",
    "        return obj\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # check whether X has appended bias feature or not\n",
    "        if X.shape[1] == len(self._theta):\n",
    "            pred = np.dot(X, self._theta)\n",
    "        else:\n",
    "            pred = np.dot(X, self.coef_) + self.intercept_\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code for question 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicLinearRegressionHomegrown(object):\n",
    "    \n",
    "    def __init__(self, l=0.0, mu=0.0):\n",
    "        self.coef_ = None       # weight vector\n",
    "        self.intercept_ = None  # bias term\n",
    "        self._theta = None      # augmented weight vector, i.e., bias + weights\n",
    "                                # this allows to treat all decision variables homogeneously\n",
    "        self.l = l\n",
    "        self.mu = mu\n",
    "    \n",
    "    # calculate gradient of objective function\n",
    "    def _grad(self, X, y):\n",
    "        pred = np.dot(X, self._theta)\n",
    "        error = pred - y\n",
    "        gradient = 2 * np.dot(error, X) / X.shape[0]\n",
    "        return gradient\n",
    "    \n",
    "    # full gradient descent, i.e., not stochastic gd\n",
    "    def _gd(self, X, y, max_iter, alpha=0.005):\n",
    "        for i in range(max_iter):\n",
    "            # calculate gradient\n",
    "            grad = self._grad(X, y)\n",
    "            # do gradient step\n",
    "            self._theta -= alpha * grad\n",
    "    \n",
    "    # public API for fitting a linear regression model\n",
    "    def fit(self, X, y, max_iter=1000):\n",
    "        # Augment the data with the bias term.\n",
    "        # So we can treat the the input variables and the bias term homogeneously \n",
    "        # from a vectorization perspective\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # initialize if the first step\n",
    "        if self._theta is None:\n",
    "            np.random.seed(21)\n",
    "            self._theta = np.random.rand(X.shape[1])\n",
    "        \n",
    "        # do full gradient descent\n",
    "        self._gd(X, y, max_iter)\n",
    "        \n",
    "        self.intercept_ = self._theta[0]\n",
    "        self.coef_ = self._theta[1:]\n",
    "        \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        error = pred - y\n",
    "        obj = np.sum(error ** 2) / X.shape[0]\n",
    "        return obj\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # check whether X has appended bias feature or not\n",
    "        if X.shape[1] == len(self._theta):\n",
    "            pred = np.dot(X, self._theta)\n",
    "        else:\n",
    "            pred = np.dot(X, self.coef_) + self.intercept_\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# END of Exam"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
